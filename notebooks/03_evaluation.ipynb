{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ“Š 03 â€” Evaluation\n",
        "\n",
        "**Purpose:** Generate predictions and evaluate metrics for trained models.\n",
        "\n",
        "**Sections:**\n",
        "1. Inline Setup\n",
        "2. Copy Data to /content (if needed for prediction)\n",
        "3. Select Checkpoint\n",
        "4. Generate Predictions\n",
        "5. Evaluate Metrics\n",
        "6. Confusion Matrix Visualization\n",
        "\n",
        "**Prerequisites:** Trained checkpoint exists on Drive (from 02_training.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ”§ Section 1: Inline Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- INLINE SETUP ---\n",
        "import os, subprocess, sys\n",
        "\n",
        "REPO_URL       = \"https://github.com/ClaudiaCPach/CNNs-distracted-driving\"\n",
        "REPO_DIRNAME   = \"CNNs-distracted-driving\"\n",
        "BRANCH         = \"main\"\n",
        "PROJECT_ROOT   = f\"/content/{REPO_DIRNAME}\"\n",
        "DRIVE_PATH     = \"/content/drive/MyDrive/TFM\"\n",
        "DRIVE_DATA_ROOT = f\"{DRIVE_PATH}/data\"\n",
        "FAST_DATA      = \"/content/data\"\n",
        "DATASET_ROOT   = DRIVE_DATA_ROOT\n",
        "OUT_ROOT       = f\"{DRIVE_PATH}/outputs\"\n",
        "CKPT_ROOT      = f\"{DRIVE_PATH}/checkpoints\"\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "def sh(cmd):\n",
        "    rc = subprocess.call(cmd, shell=True, executable=\"/bin/bash\")\n",
        "    if rc != 0:\n",
        "        raise RuntimeError(f\"Command failed: {cmd}\")\n",
        "\n",
        "if os.path.isdir(PROJECT_ROOT):\n",
        "    sh(f\"cd {PROJECT_ROOT} && git pull --rebase origin {BRANCH}\")\n",
        "else:\n",
        "    sh(f\"git clone --branch {BRANCH} {REPO_URL} {PROJECT_ROOT}\")\n",
        "\n",
        "sh(f\"pip install -q -e {PROJECT_ROOT}\")\n",
        "!pip -q install timm\n",
        "\n",
        "os.environ[\"DRIVE_PATH\"] = DRIVE_PATH\n",
        "os.environ[\"DATASET_ROOT\"] = DATASET_ROOT\n",
        "os.environ[\"OUT_ROOT\"] = OUT_ROOT\n",
        "os.environ[\"CKPT_ROOT\"] = CKPT_ROOT\n",
        "os.environ[\"FAST_DATA\"] = FAST_DATA\n",
        "\n",
        "sys.path.insert(0, PROJECT_ROOT)\n",
        "sys.path.insert(0, os.path.join(PROJECT_ROOT, \"src\"))\n",
        "print(\"âœ… Inline setup complete\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âš¡ Section 2: Copy Data to /content (Optional)\n",
        "\n",
        "Run this if you need faster I/O for prediction. Skip if reading from Drive is acceptable.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# âš¡ Copy HYBRID CROPS to /content (run if needed)\n",
        "import os, shutil\n",
        "from pathlib import Path\n",
        "import importlib\n",
        "\n",
        "HYBRID_VARIANT = \"face\"  # face | face_hands â€” match what you trained on\n",
        "\n",
        "LOCAL_ROOT = Path(\"/content/data/hybrid\")\n",
        "DRIVE_ROOT = Path(OUT_ROOT) / \"hybrid\"\n",
        "LOCAL_VARIANT_DIR = LOCAL_ROOT / HYBRID_VARIANT\n",
        "DRIVE_VARIANT_DIR = DRIVE_ROOT / HYBRID_VARIANT\n",
        "\n",
        "def count_jpgs(p: Path) -> int:\n",
        "    return sum(1 for _ in p.rglob(\"*.jpg\")) if p.exists() else 0\n",
        "\n",
        "local_count = count_jpgs(LOCAL_VARIANT_DIR)\n",
        "drive_count = count_jpgs(DRIVE_VARIANT_DIR)\n",
        "\n",
        "print(f\"ðŸ”Ž Local: {local_count} jpgs | Drive: {drive_count} jpgs\")\n",
        "\n",
        "if local_count > 0:\n",
        "    print(f\"âœ… Already in /content\")\n",
        "elif drive_count > 0:\n",
        "    print(f\"ðŸ“¦ Copying from Drive...\")\n",
        "    LOCAL_VARIANT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    file_count = 0\n",
        "    for src_dir, _, files in os.walk(DRIVE_VARIANT_DIR):\n",
        "        rel_dir = Path(src_dir).relative_to(DRIVE_VARIANT_DIR)\n",
        "        dst_dir = LOCAL_VARIANT_DIR / rel_dir\n",
        "        dst_dir.mkdir(parents=True, exist_ok=True)\n",
        "        for fname in files:\n",
        "            if fname.lower().endswith(\".jpg\"):\n",
        "                shutil.copy2(Path(src_dir) / fname, dst_dir / fname)\n",
        "                file_count += 1\n",
        "    print(f\"   Copied {file_count} images\")\n",
        "    \n",
        "    for fname in [f\"manifest_{HYBRID_VARIANT}.csv\", f\"train_{HYBRID_VARIANT}.csv\",\n",
        "                  f\"val_{HYBRID_VARIANT}.csv\", f\"test_{HYBRID_VARIANT}.csv\"]:\n",
        "        src = DRIVE_ROOT / fname\n",
        "        if src.exists():\n",
        "            shutil.copy2(src, LOCAL_ROOT / fname)\n",
        "\n",
        "os.environ[\"HYBRID_ROOT_LOCAL\"] = str(LOCAL_ROOT)\n",
        "os.environ[\"DATASET_ROOT\"] = str(LOCAL_ROOT)\n",
        "from ddriver import config as _cfg\n",
        "importlib.reload(_cfg)\n",
        "print(f\"âœ… DATASET_ROOT = {os.environ['DATASET_ROOT']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“¦ Section 3: Select Checkpoint\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select checkpoint to evaluate\n",
        "from pathlib import Path\n",
        "\n",
        "RUN_TAG = \"effb0_face_v1\"  # <<<< CHANGE to match your training run\n",
        "\n",
        "run_base = Path(CKPT_ROOT) / \"runs\" / RUN_TAG\n",
        "runs = sorted(run_base.glob(\"*/\"))\n",
        "if not runs:\n",
        "    raise FileNotFoundError(f\"No run folders found under {run_base}\")\n",
        "\n",
        "print(\"Available runs:\")\n",
        "for idx, run_dir in enumerate(runs):\n",
        "    print(f\"  [{idx}] {run_dir.name}\")\n",
        "\n",
        "RUN_IDX = -1  # -1 = newest\n",
        "target_run = runs[RUN_IDX]\n",
        "print(f\"\\nSelected run: {target_run}\")\n",
        "\n",
        "# Choose checkpoint\n",
        "CHECKPOINT_NAME = \"best.pt\"  # or \"last.pt\"\n",
        "LATEST_CKPT = target_run / CHECKPOINT_NAME\n",
        "if not LATEST_CKPT.exists():\n",
        "    raise FileNotFoundError(LATEST_CKPT)\n",
        "\n",
        "print(f\"Using checkpoint: {LATEST_CKPT}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ”® Section 4: Generate Predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate predictions\n",
        "import os\n",
        "import subprocess\n",
        "import textwrap\n",
        "from pathlib import Path\n",
        "import importlib\n",
        "\n",
        "# Configuration\n",
        "PRED_SPLIT = \"test\"           # or \"val\"\n",
        "USE_HYBRID = True             # Match what model was trained on\n",
        "ROI_VARIANT = \"face\"          # face | face_hands\n",
        "MODEL_NAME = \"efficientnet_b0\"\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = 2\n",
        "IMAGE_SIZE = 224\n",
        "\n",
        "# Control split selection (for 5-run experimental plan)\n",
        "# Set to None for natural runs, or \"facesubset\" / \"fhsubset\" / \"both\" for control runs\n",
        "# NOTE: Control splits only work with full-frame (USE_HYBRID=False)\n",
        "USE_CONTROL_SPLIT = None      # None | \"facesubset\" | \"fhsubset\" | \"both\"\n",
        "\n",
        "# Validate settings\n",
        "if USE_CONTROL_SPLIT and USE_HYBRID:\n",
        "    raise ValueError(\"Control splits require full-frame evaluation. Set USE_HYBRID=False to use control splits.\")\n",
        "\n",
        "PRED_TAG = f\"{RUN_TAG}_{PRED_SPLIT}\"\n",
        "\n",
        "# Build paths\n",
        "if USE_HYBRID:\n",
        "    hybrid_root = Path(os.environ.get(\"HYBRID_ROOT_LOCAL\", Path(OUT_ROOT) / \"hybrid\"))\n",
        "    manifest_pred = hybrid_root / f\"manifest_{ROI_VARIANT}.csv\"\n",
        "    train_pred = hybrid_root / f\"train_{ROI_VARIANT}.csv\"\n",
        "    val_pred = hybrid_root / f\"val_{ROI_VARIANT}.csv\"\n",
        "    test_pred = hybrid_root / f\"test_{ROI_VARIANT}.csv\"\n",
        "    \n",
        "    # Ensure DATASET_ROOT points to hybrid\n",
        "    os.environ[\"DATASET_ROOT\"] = str(hybrid_root)\n",
        "    from ddriver import config as _cfg\n",
        "    importlib.reload(_cfg)\n",
        "    print(f\"ðŸ“¦ Using HYBRID crops: {ROI_VARIANT}\")\n",
        "else:\n",
        "    manifest_pred = Path(OUT_ROOT) / \"manifests\" / \"manifest.csv\"\n",
        "    # Handle control splits for 5-run experimental plan\n",
        "    if USE_CONTROL_SPLIT:\n",
        "        control_root = Path(OUT_ROOT) / \"splits\" / \"control\"\n",
        "        train_pred = control_root / f\"train_{USE_CONTROL_SPLIT}.csv\"\n",
        "        val_pred = control_root / f\"val_{USE_CONTROL_SPLIT}.csv\"\n",
        "        test_pred = control_root / f\"test_{USE_CONTROL_SPLIT}.csv\"\n",
        "        print(f\"ðŸ“¦ Using FULL images with CONTROL SPLIT: {USE_CONTROL_SPLIT}\")\n",
        "    else:\n",
        "        train_pred = Path(OUT_ROOT) / \"splits\" / \"train.csv\"\n",
        "        val_pred = Path(OUT_ROOT) / \"splits\" / \"val.csv\"\n",
        "        test_pred = Path(OUT_ROOT) / \"splits\" / \"test.csv\"\n",
        "        print(\"ðŸ“¦ Using FULL images\")\n",
        "\n",
        "predict_cmd = textwrap.dedent(f\"\"\"\n",
        "cd {PROJECT_ROOT}\n",
        "python -m src.ddriver.cli.predict \\\n",
        "    --model-name {MODEL_NAME} \\\n",
        "    --checkpoint {LATEST_CKPT} \\\n",
        "    --split {PRED_SPLIT} \\\n",
        "    --batch-size {BATCH_SIZE} \\\n",
        "    --num-workers {NUM_WORKERS} \\\n",
        "    --image-size {IMAGE_SIZE} \\\n",
        "    --out-tag {PRED_TAG} \\\n",
        "    --manifest-csv {manifest_pred} \\\n",
        "    --train-csv {train_pred} --val-csv {val_pred} --test-csv {test_pred}\n",
        "\"\"\")\n",
        "\n",
        "print(\"Running prediction:\\n\", predict_cmd)\n",
        "result = subprocess.run(predict_cmd, shell=True, text=True, capture_output=True)\n",
        "if result.returncode != 0:\n",
        "    print(\"STDOUT:\", result.stdout)\n",
        "    print(\"STDERR:\", result.stderr)\n",
        "    raise RuntimeError(\"Prediction failed\")\n",
        "print(result.stdout)\n",
        "print(\"\\nâœ… Predictions saved to OUT_ROOT/preds/\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“Š Section 5: Evaluate Metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate metrics\n",
        "import subprocess\n",
        "import textwrap\n",
        "from pathlib import Path\n",
        "\n",
        "if USE_HYBRID:\n",
        "    hybrid_root = Path(os.environ.get(\"HYBRID_ROOT_LOCAL\", Path(OUT_ROOT) / \"hybrid\"))\n",
        "    manifest_path = hybrid_root / f\"manifest_{ROI_VARIANT}.csv\"\n",
        "    split_csv_path = hybrid_root / f\"{PRED_SPLIT}_{ROI_VARIANT}.csv\"\n",
        "else:\n",
        "    manifest_path = Path(OUT_ROOT) / \"manifests\" / \"manifest.csv\"\n",
        "    # Handle control splits for 5-run experimental plan\n",
        "    if USE_CONTROL_SPLIT:\n",
        "        control_root = Path(OUT_ROOT) / \"splits\" / \"control\"\n",
        "        split_csv_path = control_root / f\"{PRED_SPLIT}_{USE_CONTROL_SPLIT}.csv\"\n",
        "    else:\n",
        "        split_csv_path = Path(OUT_ROOT) / \"splits\" / f\"{PRED_SPLIT}.csv\"\n",
        "\n",
        "preds_csv_path = Path(OUT_ROOT) / \"preds\" / PRED_SPLIT / f\"{PRED_TAG}.csv\"\n",
        "METRICS_TAG = PRED_TAG\n",
        "\n",
        "print(f\"ðŸ“Š Evaluating: {preds_csv_path}\")\n",
        "\n",
        "metrics_cmd = textwrap.dedent(f\"\"\"\n",
        "cd {PROJECT_ROOT}\n",
        "python -m src.ddriver.eval.metrics \\\n",
        "    --manifest {manifest_path} \\\n",
        "    --split-csv {split_csv_path} \\\n",
        "    --predictions {preds_csv_path} \\\n",
        "    --out-tag {METRICS_TAG} \\\n",
        "    --per-driver \\\n",
        "    --per-camera\n",
        "\"\"\")\n",
        "\n",
        "print(\"Running metrics:\\n\", metrics_cmd)\n",
        "result = subprocess.run(metrics_cmd, shell=True, text=True, capture_output=True)\n",
        "if result.returncode != 0:\n",
        "    print(\"STDOUT:\", result.stdout)\n",
        "    print(\"STDERR:\", result.stderr)\n",
        "    raise RuntimeError(\"Metrics failed\")\n",
        "print(result.stdout)\n",
        "print(\"\\nâœ… Metrics saved to OUT_ROOT/metrics/\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸŽ¯ Section 6: Confusion Matrix Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize confusion matrix\n",
        "import json\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "metrics_root = Path(OUT_ROOT) / \"metrics\" / METRICS_TAG\n",
        "runs = sorted(metrics_root.glob(\"*/\"))\n",
        "if not runs:\n",
        "    raise FileNotFoundError(f\"No metrics runs found under {metrics_root}\")\n",
        "latest_metrics = runs[-1]\n",
        "print(\"Reading from:\", latest_metrics)\n",
        "\n",
        "metrics = json.loads((latest_metrics / \"metrics.json\").read_text())\n",
        "cm_info = metrics.get(\"confusion_matrix\")\n",
        "if not cm_info:\n",
        "    raise ValueError(\"confusion_matrix missing from metrics.json\")\n",
        "\n",
        "labels = cm_info[\"rows_cols_labels\"]\n",
        "cm_df = pd.DataFrame(cm_info[\"matrix\"], index=labels, columns=labels)\n",
        "\n",
        "# Counts heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm_df, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.title(f\"Confusion Matrix â€” {METRICS_TAG}\")\n",
        "plt.ylabel(\"True class\")\n",
        "plt.xlabel(\"Predicted class\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(latest_metrics / \"confusion_matrix_counts.png\")\n",
        "plt.show()\n",
        "\n",
        "# Normalized heatmap\n",
        "cm_norm = cm_df.div(cm_df.sum(axis=1).replace(0, 1), axis=0)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm_norm, annot=True, fmt=\".2f\", cmap=\"Blues\")\n",
        "plt.title(f\"Normalized Confusion Matrix â€” {METRICS_TAG}\")\n",
        "plt.ylabel(\"True class\")\n",
        "plt.xlabel(\"Predicted class\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(latest_metrics / \"confusion_matrix_normalized.png\")\n",
        "plt.show()\n",
        "\n",
        "print(f\"âœ… Saved confusion matrices to {latest_metrics}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âœ… Evaluation Complete!\n",
        "\n",
        "**Outputs saved to Drive:**\n",
        "- `OUT_ROOT/preds/{split}/{PRED_TAG}.csv` â€” Predictions CSV\n",
        "- `OUT_ROOT/metrics/{METRICS_TAG}/{timestamp}/metrics.json` â€” All metrics\n",
        "- `OUT_ROOT/metrics/{METRICS_TAG}/{timestamp}/confusion_matrix_*.png` â€” Heatmaps\n",
        "\n",
        "**Next steps:**\n",
        "- Run **04_modality_analysis.ipynb** for per-class comparison across modalities\n",
        "- Run **05_gradcam.ipynb** for attention visualizations\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
