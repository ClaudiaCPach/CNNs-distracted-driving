{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸš‚ 02 â€” Training\n",
        "\n",
        "**Purpose:** Train models on full images or hybrid ROI crops.\n",
        "\n",
        "**Sections:**\n",
        "1. Inline Setup\n",
        "2. Copy Data to /content (full images OR hybrid crops)\n",
        "3. Register Models\n",
        "4. Training Configuration & Execution\n",
        "5. Learning Curves Visualization\n",
        "\n",
        "**Prerequisites:** Manifests and splits exist on Drive (from 01_data_preparation.ipynb or prior run)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ”§ Section 1: Inline Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- INLINE SETUP ---\n",
        "import os, subprocess, sys\n",
        "\n",
        "# Config\n",
        "REPO_URL       = \"https://github.com/ClaudiaCPach/CNNs-distracted-driving\"\n",
        "REPO_DIRNAME   = \"CNNs-distracted-driving\"\n",
        "BRANCH         = \"main\"\n",
        "PROJECT_ROOT   = f\"/content/{REPO_DIRNAME}\"\n",
        "DRIVE_PATH     = \"/content/drive/MyDrive/TFM\"\n",
        "DRIVE_DATA_ROOT = f\"{DRIVE_PATH}/data\"\n",
        "FAST_DATA      = \"/content/data\"\n",
        "DATASET_ROOT   = DRIVE_DATA_ROOT\n",
        "OUT_ROOT       = f\"{DRIVE_PATH}/outputs\"\n",
        "CKPT_ROOT      = f\"{DRIVE_PATH}/checkpoints\"\n",
        "\n",
        "# Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "# Clone/update repo\n",
        "def sh(cmd):\n",
        "    print(f\"$ {cmd}\")\n",
        "    rc = subprocess.call(cmd, shell=True, executable=\"/bin/bash\")\n",
        "    if rc != 0:\n",
        "        raise RuntimeError(f\"Command failed: {cmd}\")\n",
        "\n",
        "if os.path.isdir(PROJECT_ROOT):\n",
        "    sh(f\"cd {PROJECT_ROOT} && git pull --rebase origin {BRANCH}\")\n",
        "else:\n",
        "    sh(f\"git clone --branch {BRANCH} {REPO_URL} {PROJECT_ROOT}\")\n",
        "\n",
        "# Install\n",
        "sh(f\"pip install -q -e {PROJECT_ROOT}\")\n",
        "!pip -q install timm\n",
        "\n",
        "# Set env vars\n",
        "os.environ[\"DRIVE_PATH\"] = DRIVE_PATH\n",
        "os.environ[\"DATASET_ROOT\"] = DATASET_ROOT\n",
        "os.environ[\"OUT_ROOT\"] = OUT_ROOT\n",
        "os.environ[\"CKPT_ROOT\"] = CKPT_ROOT\n",
        "os.environ[\"FAST_DATA\"] = FAST_DATA\n",
        "\n",
        "sys.path.insert(0, PROJECT_ROOT)\n",
        "sys.path.insert(0, os.path.join(PROJECT_ROOT, \"src\"))\n",
        "\n",
        "# GPU check\n",
        "!nvidia-smi || echo \"No GPU\"\n",
        "print(\"âœ… Inline setup complete\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âš¡ Section 2: Fast Data Loading from Tar Archives\n",
        "\n",
        "Choose ONE of the options below based on what you're training on.\n",
        "\n",
        "**âš¡ Speed Boost:** These cells use tar archives for fast loading (~5 min instead of ~2 hours).\n",
        "Tar archives must be created first using 01_data_preparation.ipynb (Section 4).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# âš¡ OPTION A: Extract HYBRID CROPS from tar archive (for face/face_hands training)\n",
        "# Uses tar archive for fast loading (~5 min vs 2+ hours)\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "import importlib\n",
        "from ddriver.data.fastcopy import fast_copy_from_tar\n",
        "\n",
        "HYBRID_VARIANT = \"face\"  # face | face_hands\n",
        "\n",
        "LOCAL_ROOT = Path(\"/content/data/hybrid\")\n",
        "DRIVE_ROOT = Path(OUT_ROOT) / \"hybrid\"\n",
        "LOCAL_VARIANT_DIR = LOCAL_ROOT / HYBRID_VARIANT\n",
        "\n",
        "# Tar archive path (created in 01_data_preparation.ipynb)\n",
        "TAR_PATH = DRIVE_ROOT / f\"hybrid_{HYBRID_VARIANT}.tar\"\n",
        "\n",
        "# Check if already extracted\n",
        "if LOCAL_VARIANT_DIR.exists() and any(LOCAL_VARIANT_DIR.rglob(\"*.jpg\")):\n",
        "    jpg_count = sum(1 for _ in LOCAL_VARIANT_DIR.rglob(\"*.jpg\"))\n",
        "    print(f\"âœ… Hybrid crops already in /content ({jpg_count} jpgs). Skipping.\")\n",
        "elif not TAR_PATH.exists():\n",
        "    raise FileNotFoundError(\n",
        "        f\"Tar archive not found: {TAR_PATH}\\n\"\n",
        "        \"Run 01_data_preparation.ipynb Section 4 to create tar archives first.\"\n",
        "    )\n",
        "else:\n",
        "    print(f\"ðŸ“¦ Extracting {HYBRID_VARIANT} crops from tar archive...\")\n",
        "    result = fast_copy_from_tar(\n",
        "        tar_path_on_drive=TAR_PATH,\n",
        "        dest_dir=LOCAL_VARIANT_DIR,\n",
        "        remove_tar_after=True,\n",
        "        verbose=True,\n",
        "    )\n",
        "    print(f\"   âœ… Extracted {result.get('n_files', '?')} files\")\n",
        "    \n",
        "    # Copy CSVs (these are small, direct copy is fine)\n",
        "    for fname in [f\"manifest_{HYBRID_VARIANT}.csv\", f\"train_{HYBRID_VARIANT}.csv\", \n",
        "                  f\"val_{HYBRID_VARIANT}.csv\", f\"test_{HYBRID_VARIANT}.csv\"]:\n",
        "        src = DRIVE_ROOT / fname\n",
        "        if src.exists():\n",
        "            shutil.copy2(src, LOCAL_ROOT / fname)\n",
        "            print(f\"   Copied {fname}\")\n",
        "\n",
        "# Update env vars\n",
        "os.environ[\"HYBRID_ROOT_LOCAL\"] = str(LOCAL_ROOT)\n",
        "os.environ[\"DATASET_ROOT\"] = str(LOCAL_ROOT)\n",
        "from ddriver import config as _cfg\n",
        "importlib.reload(_cfg)\n",
        "print(f\"\\nâœ… DATASET_ROOT = {os.environ['DATASET_ROOT']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# âš¡ OPTION B: Extract FULL IMAGES from tar archive (for full-frame training)\n",
        "# Uses pre-compressed tar archive for fast loading (~5 min vs 2+ hours)\n",
        "# Skip this if using hybrid crops above\n",
        "\n",
        "import os\n",
        "import importlib\n",
        "from pathlib import Path\n",
        "from ddriver.data.fastcopy import fast_copy_from_tar\n",
        "\n",
        "# Tar archive path (created in 01_data_preparation.ipynb)\n",
        "TAR_PATH = Path(DRIVE_DATA_ROOT) / \"full_compressed.tar\"\n",
        "DST_ROOT = Path(FAST_DATA) / \"auc.distracted.driver.dataset_v2\"\n",
        "\n",
        "# Check if already extracted\n",
        "if DST_ROOT.exists() and any(DST_ROOT.rglob(\"*.jpg\")):\n",
        "    jpg_count = sum(1 for _ in DST_ROOT.rglob(\"*.jpg\"))\n",
        "    print(f\"âœ… Full images already in /content ({jpg_count} jpgs). Skipping.\")\n",
        "elif not TAR_PATH.exists():\n",
        "    raise FileNotFoundError(\n",
        "        f\"Tar archive not found: {TAR_PATH}\\n\"\n",
        "        \"Run 01_data_preparation.ipynb Section 4b to create the full-frame tar archive first.\"\n",
        "    )\n",
        "else:\n",
        "    print(\"ðŸ“¦ Extracting full-frame images from tar archive...\")\n",
        "    result = fast_copy_from_tar(\n",
        "        tar_path_on_drive=TAR_PATH,\n",
        "        dest_dir=DST_ROOT,\n",
        "        remove_tar_after=True,\n",
        "        verbose=True,\n",
        "    )\n",
        "    print(f\"   âœ… Extracted {result.get('n_files', '?')} files\")\n",
        "\n",
        "os.environ[\"DATASET_ROOT\"] = str(FAST_DATA)\n",
        "from ddriver import config as _cfg\n",
        "importlib.reload(_cfg)\n",
        "print(f\"âœ… DATASET_ROOT = {os.environ['DATASET_ROOT']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“¦ Section 3: Register Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Register models from timm\n",
        "from ddriver.models import registry\n",
        "\n",
        "registry.register_timm_backbone(\"efficientnet_b0\")\n",
        "# registry.register_timm_backbone(\"convnext_tiny\")\n",
        "# registry.register_timm_backbone(\"resnet50\")\n",
        "\n",
        "print(\"Available models:\", registry.available_models()[:10])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸš‚ Section 4: Training Configuration & Execution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ðŸš‚ TRAINING CONFIGURATION\n",
        "import os\n",
        "import subprocess, textwrap, json, time, threading\n",
        "from pathlib import Path\n",
        "\n",
        "# ============== EXPERIMENT CONFIG ==============\n",
        "RUN_TAG = \"effb0_face_v1\"           # <<<< CHANGE for each experiment\n",
        "MODEL_NAME = \"efficientnet_b0\"\n",
        "SEED = 42                           # <<<< CHANGE for stability runs (e.g., 42, 123, 456)\n",
        "\n",
        "# Training hyperparameters\n",
        "EPOCHS = 30\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = 2\n",
        "IMAGE_SIZE = 224\n",
        "LR = 3e-4\n",
        "LABEL_SMOOTHING = 0.05\n",
        "USE_TINY_SPLIT = False\n",
        "\n",
        "# Data source: choose ONE\n",
        "USE_HYBRID = True                   # True = use hybrid crops\n",
        "ROI_VARIANT = \"face\"                # face | face_hands (only if USE_HYBRID=True)\n",
        "\n",
        "# Control split selection (for 5-run experimental plan)\n",
        "# Set to None for natural runs, or \"facesubset\" / \"fhsubset\" / \"both\" for control runs\n",
        "# NOTE: Control splits only work with full-frame (USE_HYBRID=False)\n",
        "USE_CONTROL_SPLIT = None            # None | \"facesubset\" | \"fhsubset\" | \"both\"\n",
        "\n",
        "# Validate settings\n",
        "if USE_CONTROL_SPLIT and USE_HYBRID:\n",
        "    raise ValueError(\"Control splits require full-frame training. Set USE_HYBRID=False to use control splits.\")\n",
        "\n",
        "# ============== BUILD PATHS ==============\n",
        "if USE_HYBRID:\n",
        "    hybrid_root = Path(os.environ.get(\"HYBRID_ROOT_LOCAL\", Path(OUT_ROOT) / \"hybrid\"))\n",
        "    manifest_csv = hybrid_root / f\"manifest_{ROI_VARIANT}.csv\"\n",
        "    train_split = f\"train_{ROI_VARIANT}.csv\" if not USE_TINY_SPLIT else f\"train_small_{ROI_VARIANT}.csv\"\n",
        "    train_csv = hybrid_root / train_split\n",
        "    val_csv = hybrid_root / f\"val_{ROI_VARIANT}.csv\"\n",
        "    test_csv = hybrid_root / f\"test_{ROI_VARIANT}.csv\"\n",
        "    print(f\"ðŸ”€ Using Hybrid crops: {ROI_VARIANT}\")\n",
        "    print(f\"   hybrid_root = {hybrid_root}\")\n",
        "else:\n",
        "    manifest_csv = Path(OUT_ROOT) / \"manifests\" / \"manifest.csv\"\n",
        "    # Handle control splits for 5-run experimental plan\n",
        "    if USE_CONTROL_SPLIT:\n",
        "        control_root = Path(OUT_ROOT) / \"splits\" / \"control\"\n",
        "        train_csv = control_root / f\"train_{USE_CONTROL_SPLIT}.csv\"\n",
        "        val_csv = control_root / f\"val_{USE_CONTROL_SPLIT}.csv\"\n",
        "        test_csv = control_root / f\"test_{USE_CONTROL_SPLIT}.csv\"\n",
        "        print(f\"ðŸ“· Using full-frame images with CONTROL SPLIT: {USE_CONTROL_SPLIT}\")\n",
        "        print(f\"   (Filtered to {USE_CONTROL_SPLIT} IDs for fair comparison)\")\n",
        "    else:\n",
        "        train_split = \"train_small.csv\" if USE_TINY_SPLIT else \"train.csv\"\n",
        "        train_csv = Path(OUT_ROOT) / \"splits\" / train_split\n",
        "        val_csv = Path(OUT_ROOT) / \"splits\" / \"val.csv\"\n",
        "        test_csv = Path(OUT_ROOT) / \"splits\" / \"test.csv\"\n",
        "        print(\"ðŸ“· Using full-frame images\")\n",
        "\n",
        "# Update DATASET_ROOT for hybrid\n",
        "if USE_HYBRID:\n",
        "    _roi_root = hybrid_root\n",
        "    if str(_roi_root).startswith(\"/content/data\"):\n",
        "        import importlib\n",
        "        os.environ[\"DATASET_ROOT\"] = str(_roi_root)\n",
        "        from ddriver import config as _cfg\n",
        "        importlib.reload(_cfg)\n",
        "        print(f\"   âš¡ DATASET_ROOT = {os.environ['DATASET_ROOT']}\")\n",
        "\n",
        "print(f\"\\nðŸ“‹ Training config:\")\n",
        "print(f\"   RUN_TAG: {RUN_TAG}\")\n",
        "print(f\"   Model: {MODEL_NAME}\")\n",
        "print(f\"   Seed: {SEED}\")\n",
        "print(f\"   Epochs: {EPOCHS}, Batch: {BATCH_SIZE}, LR: {LR}\")\n",
        "if USE_CONTROL_SPLIT:\n",
        "    print(f\"   Control Split: {USE_CONTROL_SPLIT}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ðŸš‚ RUN TRAINING\n",
        "\n",
        "\n",
        "\n",
        "# ============== FIX: Convert absolute Drive paths to relative ==============\n",
        "# This ensures DATASET_ROOT is respected even if manifest has absolute paths\n",
        "import pandas as pd\n",
        "\n",
        "def _make_relative(path_str: str) -> str:\n",
        "    \"\"\"Convert absolute path to relative from dataset marker.\"\"\"\n",
        "    marker = \"auc.distracted.driver.dataset_v2\"\n",
        "    if marker in path_str:\n",
        "        idx = path_str.find(marker)\n",
        "        return path_str[idx:]  # Keep from mabrker onwards\n",
        "    return path_str\n",
        "\n",
        "# Patch the split CSVs to use relative paths\n",
        "for csv_path in [train_csv, val_csv, test_csv]:\n",
        "    if Path(csv_path).exists():\n",
        "        df = pd.read_csv(csv_path)\n",
        "        if \"path\" in df.columns:\n",
        "            sample_path = df[\"path\"].iloc[0] if len(df) > 0 else \"\"\n",
        "            if \"/content/drive\" in sample_path:\n",
        "                print(f\"âš ï¸  Converting {csv_path.name} paths to relative...\")\n",
        "                df[\"path\"] = df[\"path\"].apply(_make_relative)\n",
        "                # Write to local temp location\n",
        "                local_csv = Path(\"/content\") / csv_path.name\n",
        "                df.to_csv(local_csv, index=False)\n",
        "                if \"train\" in str(csv_path):\n",
        "                    train_csv = local_csv\n",
        "                elif \"val\" in str(csv_path):\n",
        "                    val_csv = local_csv\n",
        "                elif \"test\" in str(csv_path):\n",
        "                    test_csv = local_csv\n",
        "                print(f\"   âœ… Wrote {local_csv} with relative paths\")\n",
        "\n",
        "# Also verify DATASET_ROOT\n",
        "print(f\"\\nðŸ” DATASET_ROOT = {os.environ.get('DATASET_ROOT')}\")\n",
        "fast_images = Path(\"/content/data/auc.distracted.driver.dataset_v2\")\n",
        "if fast_images.exists():\n",
        "    print(f\"   âœ… Fast storage contains images\")\n",
        "else:\n",
        "    print(f\"   âŒ WARNING: {fast_images} does not exist!\")\n",
        "\n",
        "train_cmd = textwrap.dedent(f\"\"\"\n",
        "cd {PROJECT_ROOT}\n",
        "python -m src.ddriver.cli.train \\\n",
        "    --model-name {MODEL_NAME} \\\n",
        "    --epochs {EPOCHS} \\\n",
        "    --batch-size {BATCH_SIZE} \\\n",
        "    --num-workers {NUM_WORKERS} \\\n",
        "    --image-size {IMAGE_SIZE} \\\n",
        "    --lr {LR} \\\n",
        "    --weight-decay .01 \\\n",
        "    --optimizer adamw \\\n",
        "    --label-smoothing {LABEL_SMOOTHING} \\\n",
        "    --seed {SEED} \\\n",
        "    --out-tag {RUN_TAG} \\\n",
        "    --manifest-csv {manifest_csv} \\\n",
        "    --train-csv {train_csv} \\\n",
        "    --val-csv {val_csv} \\\n",
        "    --test-csv {test_csv}\n",
        "\"\"\")\n",
        "\n",
        "print(\"Running training command:\\n\", train_cmd)\n",
        "\n",
        "proc = subprocess.Popen(train_cmd, shell=True, text=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
        "\n",
        "# GPU monitor thread\n",
        "def _gpu_monitor():\n",
        "    while proc.poll() is None:\n",
        "        try:\n",
        "            stats = subprocess.check_output(\n",
        "                \"nvidia-smi --query-gpu=utilization.gpu,memory.used,memory.total --format=csv,nounits,noheader\",\n",
        "                shell=True,\n",
        "            ).decode(\"utf-8\").strip()\n",
        "            print(f\"[GPU] {stats}\")\n",
        "        except:\n",
        "            pass\n",
        "        time.sleep(5)\n",
        "\n",
        "monitor = threading.Thread(target=_gpu_monitor, daemon=True)\n",
        "monitor.start()\n",
        "\n",
        "for line in proc.stdout:\n",
        "    print(line, end=\"\")\n",
        "\n",
        "proc.wait()\n",
        "print(\"\\nâœ… Training complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“ˆ Section 5: Learning Curves Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ðŸ“ˆ Display training metrics and learning curves\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "run_base = Path(CKPT_ROOT) / \"runs\" / RUN_TAG\n",
        "all_runs = sorted(run_base.glob(\"*/\"))\n",
        "if not all_runs:\n",
        "    raise FileNotFoundError(f\"No run folders found under {run_base}\")\n",
        "latest_run = all_runs[-1]\n",
        "\n",
        "history_path = latest_run / \"history.json\"\n",
        "if not history_path.exists():\n",
        "    raise FileNotFoundError(f\"history.json not found in {latest_run}\")\n",
        "\n",
        "history = json.loads(history_path.read_text()).get(\"history\", [])\n",
        "\n",
        "print(f\"ðŸ“Š Epoch metrics for run: {latest_run.name}\")\n",
        "for record in history:\n",
        "    train_metrics = record.get(\"train\", {})\n",
        "    val_metrics = record.get(\"val\", {}) or {}\n",
        "    train_loss = train_metrics.get(\"loss\")\n",
        "    train_acc = train_metrics.get(\"accuracy\")\n",
        "    val_loss = val_metrics.get(\"loss\")\n",
        "    val_acc = val_metrics.get(\"accuracy\")\n",
        "    val_str = f\"val_loss={val_loss:.4f} acc={val_acc:.4f}\" if val_loss else \"val_loss=â€” val_acc=â€”\"\n",
        "    print(f\"  Epoch {record['epoch']:>2}: train_loss={train_loss:.4f} acc={train_acc:.4f}  {val_str}\")\n",
        "\n",
        "# Plot learning curves\n",
        "epochs = [r[\"epoch\"] for r in history]\n",
        "train_loss = [r[\"train\"][\"loss\"] for r in history]\n",
        "train_acc = [r[\"train\"][\"accuracy\"] for r in history]\n",
        "val_loss = [(r.get(\"val\") or {}).get(\"loss\") for r in history]\n",
        "val_acc = [(r.get(\"val\") or {}).get(\"accuracy\") for r in history]\n",
        "\n",
        "val_epochs = [e for e, v in zip(epochs, val_loss) if v is not None]\n",
        "val_loss_f = [v for v in val_loss if v is not None]\n",
        "val_acc_f = [v for v in val_acc if v is not None]\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4), dpi=140)\n",
        "\n",
        "axes[0].plot(epochs, train_acc, label=\"Training Accuracy\")\n",
        "if val_acc_f:\n",
        "    axes[0].plot(val_epochs, val_acc_f, label=\"Validation Accuracy\")\n",
        "axes[0].set_title(\"Accuracy Curves\")\n",
        "axes[0].set_xlabel(\"Epochs\")\n",
        "axes[0].set_ylabel(\"Accuracy\")\n",
        "axes[0].legend()\n",
        "\n",
        "axes[1].plot(epochs, train_loss, label=\"Training Loss\")\n",
        "if val_loss_f:\n",
        "    axes[1].plot(val_epochs, val_loss_f, label=\"Validation Loss\")\n",
        "axes[1].set_title(\"Loss Curves\")\n",
        "axes[1].set_xlabel(\"Epochs\")\n",
        "axes[1].set_ylabel(\"Loss\")\n",
        "axes[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "out_png = latest_run / \"learning_curves.png\"\n",
        "fig.savefig(out_png, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "print(\"âœ… Saved:\", out_png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âœ… Training Complete!\n",
        "\n",
        "**Outputs saved to Drive:**\n",
        "- `CKPT_ROOT/runs/{RUN_TAG}/{timestamp}/best.pt` â€” Best checkpoint\n",
        "- `CKPT_ROOT/runs/{RUN_TAG}/{timestamp}/history.json` â€” Training history\n",
        "- `CKPT_ROOT/runs/{RUN_TAG}/{timestamp}/learning_curves.png` â€” Curves figure\n",
        "\n",
        "**Next steps:**\n",
        "- Run **03_evaluation.ipynb** to generate predictions and metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ðŸ“ Training summary â†’ Google Sheet\n",
        "!pip -q install gspread\n",
        "\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "import gspread\n",
        "from google.colab import auth\n",
        "import google.auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "creds, _ = google.auth.default()\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "TRAIN_SHEET_NAME = \"TFM Train Logs\"   # create this sheet/tab ahead of time\n",
        "TRAIN_WORKSHEET = \"Sheet1\"\n",
        "\n",
        "run_base = Path(CKPT_ROOT) / \"runs\" / RUN_TAG\n",
        "all_runs = sorted(run_base.glob(\"*/\"))\n",
        "if not all_runs:\n",
        "    raise FileNotFoundError(f\"No run folders found under {run_base}\")\n",
        "latest_run = all_runs[-1]\n",
        "print(f\"Logging training summary for run folder: {latest_run}\")\n",
        "\n",
        "history_path = latest_run / \"history.json\"\n",
        "if not history_path.exists():\n",
        "    raise FileNotFoundError(f\"history.json not found under {latest_run}\")\n",
        "\n",
        "history_records = json.loads(history_path.read_text()).get(\"history\", [])\n",
        "if not history_records:\n",
        "    raise ValueError(f\"history.json under {latest_run} has no records.\")\n",
        "\n",
        "params_path = latest_run / \"params.json\"\n",
        "params = json.loads(params_path.read_text()) if params_path.exists() else {}\n",
        "\n",
        "model_name = params.get(\"model_name\", MODEL_NAME)\n",
        "epochs_cfg = params.get(\"epochs\", EPOCHS)\n",
        "batch_cfg = params.get(\"batch_size\", BATCH_SIZE)\n",
        "lr_cfg = params.get(\"lr\", LR)\n",
        "#lr_drop_epoch_cfg = params.get(\"lr_drop_epoch\", LR_DROP_EPOCH)\n",
        "#lr_drop_factor_cfg = params.get(\"lr_drop_factor\", LR_DROP_FACTOR)\n",
        "image_size_cfg = params.get(\"image_size\", IMAGE_SIZE)\n",
        "num_workers_cfg = params.get(\"num_workers\", NUM_WORKERS)\n",
        "use_tiny_cfg = params.get(\"use_tiny_split\", USE_TINY_SPLIT)\n",
        "\n",
        "\n",
        "def _best_metric(records, split: str) -> tuple[dict, float | None]:\n",
        "    best_epoch = None\n",
        "    best_acc = None\n",
        "    for rec in records:\n",
        "        split_metrics = rec.get(split) or {}\n",
        "        acc = split_metrics.get(\"accuracy\")\n",
        "        if acc is None:\n",
        "            continue\n",
        "        if best_acc is None or acc > best_acc:\n",
        "            best_acc = acc\n",
        "            best_epoch = rec.get(\"epoch\")\n",
        "    final_metrics = records[-1].get(split) or {}\n",
        "    final_acc = final_metrics.get(\"accuracy\")\n",
        "    return {\"epoch\": best_epoch, \"accuracy\": best_acc}, final_acc\n",
        "\n",
        "\n",
        "best_train, final_train = _best_metric(history_records, \"train\")\n",
        "best_val, final_val = _best_metric(history_records, \"val\")\n",
        "\n",
        "row = [\n",
        "    RUN_TAG,\n",
        "    latest_run.name,\n",
        "    model_name,\n",
        "    epochs_cfg,\n",
        "    batch_cfg,\n",
        "    lr_cfg,\n",
        "    #lr_drop_epoch_cfg,\n",
        "    #lr_drop_factor_cfg,\n",
        "    image_size_cfg,\n",
        "    num_workers_cfg,\n",
        "    use_tiny_cfg,\n",
        "    best_train[\"epoch\"] if best_train[\"epoch\"] is not None else \"\",\n",
        "    round(best_train[\"accuracy\"], 4) if best_train[\"accuracy\"] is not None else \"\",\n",
        "    best_val[\"epoch\"] if best_val[\"epoch\"] is not None else \"\",\n",
        "    round(best_val[\"accuracy\"], 4) if best_val[\"accuracy\"] is not None else \"\",\n",
        "    round(final_train, 4) if final_train is not None else \"\",\n",
        "    round(final_val, 4) if final_val is not None else \"\",\n",
        "]\n",
        "\n",
        "ws = gc.open(TRAIN_SHEET_NAME).worksheet(TRAIN_WORKSHEET)\n",
        "ws.append_row(row, value_input_option=\"USER_ENTERED\")\n",
        "print(f\"Appended training summary for {latest_run.name} âœ…\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
