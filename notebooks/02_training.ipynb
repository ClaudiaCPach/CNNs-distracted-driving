{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bu3VI_PP226G"
      },
      "source": [
        "# ðŸš‚ 02 â€” Training\n",
        "\n",
        "**Purpose:** Train models on full images or hybrid ROI crops.\n",
        "\n",
        "**Sections:**\n",
        "1. Inline Setup\n",
        "2. Copy Data to /content (full images OR hybrid crops)\n",
        "3. Register Models\n",
        "4. Training Configuration & Execution\n",
        "5. Learning Curves Visualization\n",
        "\n",
        "**Prerequisites:** Manifests and splits exist on Drive (from 01_data_preparation.ipynb or prior run)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig-RPFwb226I"
      },
      "source": [
        "## ðŸ”§ Section 1: Inline Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVtDHCga226J"
      },
      "outputs": [],
      "source": [
        "# --- INLINE SETUP ---\n",
        "import os, subprocess, sys\n",
        "\n",
        "# Config\n",
        "REPO_URL       = \"https://github.com/ClaudiaCPach/CNNs-distracted-driving\"\n",
        "REPO_DIRNAME   = \"CNNs-distracted-driving\"\n",
        "BRANCH         = \"main\"\n",
        "PROJECT_ROOT   = f\"/content/{REPO_DIRNAME}\"\n",
        "DRIVE_PATH     = \"/content/drive/MyDrive/TFM\"\n",
        "DRIVE_DATA_ROOT = f\"{DRIVE_PATH}/data\"\n",
        "FAST_DATA      = \"/content/data\"\n",
        "DATASET_ROOT   = DRIVE_DATA_ROOT\n",
        "OUT_ROOT       = f\"{DRIVE_PATH}/outputs\"\n",
        "CKPT_ROOT      = f\"{DRIVE_PATH}/checkpoints\"\n",
        "\n",
        "# Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "# Clone/update repo\n",
        "def sh(cmd):\n",
        "    print(f\"$ {cmd}\")\n",
        "    rc = subprocess.call(cmd, shell=True, executable=\"/bin/bash\")\n",
        "    if rc != 0:\n",
        "        raise RuntimeError(f\"Command failed: {cmd}\")\n",
        "\n",
        "if os.path.isdir(PROJECT_ROOT):\n",
        "    sh(f\"cd {PROJECT_ROOT} && git pull --rebase origin {BRANCH}\")\n",
        "else:\n",
        "    sh(f\"git clone --branch {BRANCH} {REPO_URL} {PROJECT_ROOT}\")\n",
        "\n",
        "# Install\n",
        "sh(f\"pip install -q -e {PROJECT_ROOT}\")\n",
        "!pip -q install timm\n",
        "\n",
        "# Set env vars\n",
        "os.environ[\"DRIVE_PATH\"] = DRIVE_PATH\n",
        "os.environ[\"DATASET_ROOT\"] = DATASET_ROOT\n",
        "os.environ[\"OUT_ROOT\"] = OUT_ROOT\n",
        "os.environ[\"CKPT_ROOT\"] = CKPT_ROOT\n",
        "os.environ[\"FAST_DATA\"] = FAST_DATA\n",
        "\n",
        "sys.path.insert(0, PROJECT_ROOT)\n",
        "sys.path.insert(0, os.path.join(PROJECT_ROOT, \"src\"))\n",
        "\n",
        "# GPU check\n",
        "!nvidia-smi || echo \"No GPU\"\n",
        "print(\"âœ… Inline setup complete\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEnFEmhn226K"
      },
      "source": [
        "## âš¡ Section 2: Fast Data Loading from Tar Archives\n",
        "\n",
        "Choose ONE of the options below based on what you're training on.\n",
        "\n",
        "**âš¡ Speed Boost:** These cells use tar archives for fast loading (~5 min instead of ~2 hours).\n",
        "Tar archives must be created first using 01_data_preparation.ipynb (Section 4).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TpORQQI226L"
      },
      "outputs": [],
      "source": [
        "# âš¡ OPTION A: Extract HYBRID CROPS from tar archive (for face/face_hands training)\n",
        "# Uses tar archive for fast loading (~5 min vs 2+ hours)\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "import importlib\n",
        "from ddriver.data.fastcopy import fast_copy_from_tar\n",
        "\n",
        "HYBRID_VARIANT = \"face\"  # face | face_hands\n",
        "\n",
        "LOCAL_ROOT = Path(\"/content/data/hybrid\")\n",
        "DRIVE_ROOT = Path(OUT_ROOT) / \"hybrid\"\n",
        "LOCAL_VARIANT_DIR = LOCAL_ROOT / HYBRID_VARIANT\n",
        "\n",
        "# Tar archive path (created in 01_data_preparation.ipynb)\n",
        "TAR_PATH = DRIVE_ROOT / f\"hybrid_{HYBRID_VARIANT}.tar\"\n",
        "\n",
        "# Check if already extracted\n",
        "if LOCAL_VARIANT_DIR.exists() and any(LOCAL_VARIANT_DIR.rglob(\"*.jpg\")):\n",
        "    jpg_count = sum(1 for _ in LOCAL_VARIANT_DIR.rglob(\"*.jpg\"))\n",
        "    print(f\"âœ… Hybrid crops already in /content ({jpg_count} jpgs). Skipping.\")\n",
        "elif not TAR_PATH.exists():\n",
        "    raise FileNotFoundError(\n",
        "        f\"Tar archive not found: {TAR_PATH}\\n\"\n",
        "        \"Run 01_data_preparation.ipynb Section 4 to create tar archives first.\"\n",
        "    )\n",
        "else:\n",
        "    print(f\"ðŸ“¦ Extracting {HYBRID_VARIANT} crops from tar archive...\")\n",
        "    result = fast_copy_from_tar(\n",
        "        tar_path_on_drive=TAR_PATH,\n",
        "        dest_dir=LOCAL_VARIANT_DIR,\n",
        "        remove_tar_after=True,\n",
        "        verbose=True,\n",
        "    )\n",
        "    print(f\"   âœ… Extracted {result.get('n_files', '?')} files\")\n",
        "\n",
        "    # Copy CSVs (these are small, direct copy is fine)\n",
        "    for fname in [f\"manifest_{HYBRID_VARIANT}.csv\", f\"train_{HYBRID_VARIANT}.csv\",\n",
        "                  f\"val_{HYBRID_VARIANT}.csv\", f\"test_{HYBRID_VARIANT}.csv\"]:\n",
        "        src = DRIVE_ROOT / fname\n",
        "        if src.exists():\n",
        "            shutil.copy2(src, LOCAL_ROOT / fname)\n",
        "            print(f\"   Copied {fname}\")\n",
        "\n",
        "# Update env vars\n",
        "os.environ[\"HYBRID_ROOT_LOCAL\"] = str(LOCAL_ROOT)\n",
        "os.environ[\"DATASET_ROOT\"] = str(LOCAL_ROOT)\n",
        "from ddriver import config as _cfg\n",
        "importlib.reload(_cfg)\n",
        "print(f\"\\nâœ… DATASET_ROOT = {os.environ['DATASET_ROOT']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pg8y-BYv226M"
      },
      "outputs": [],
      "source": [
        "# âš¡ OPTION B: Extract FULL IMAGES from tar archive (for full-frame training)\n",
        "# Uses pre-compressed tar archive for fast loading (~5 min vs 2+ hours)\n",
        "# Skip this if using hybrid crops above\n",
        "\n",
        "import os\n",
        "import importlib\n",
        "from pathlib import Path\n",
        "from ddriver.data.fastcopy import fast_copy_from_tar\n",
        "\n",
        "# Tar archive path (created in 01_data_preparation.ipynb)\n",
        "TAR_PATH = Path(DRIVE_DATA_ROOT) / \"full_compressed.tar\"\n",
        "DST_ROOT = Path(FAST_DATA) / \"auc.distracted.driver.dataset_v2\"\n",
        "\n",
        "# Check if already extracted\n",
        "if DST_ROOT.exists() and any(DST_ROOT.rglob(\"*.jpg\")):\n",
        "    jpg_count = sum(1 for _ in DST_ROOT.rglob(\"*.jpg\"))\n",
        "    print(f\"âœ… Full images already in /content ({jpg_count} jpgs). Skipping.\")\n",
        "elif not TAR_PATH.exists():\n",
        "    raise FileNotFoundError(\n",
        "        f\"Tar archive not found: {TAR_PATH}\\n\"\n",
        "        \"Run 01_data_preparation.ipynb Section 4b to create the full-frame tar archive first.\"\n",
        "    )\n",
        "else:\n",
        "    print(\"ðŸ“¦ Extracting full-frame images from tar archive...\")\n",
        "    result = fast_copy_from_tar(\n",
        "        tar_path_on_drive=TAR_PATH,\n",
        "        dest_dir=DST_ROOT,\n",
        "        remove_tar_after=True,\n",
        "        verbose=True,\n",
        "    )\n",
        "    print(f\"   âœ… Extracted {result.get('n_files', '?')} files\")\n",
        "\n",
        "os.environ[\"DATASET_ROOT\"] = str(FAST_DATA)\n",
        "from ddriver import config as _cfg\n",
        "importlib.reload(_cfg)\n",
        "print(f\"âœ… DATASET_ROOT = {os.environ['DATASET_ROOT']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlcPKQRz226N"
      },
      "source": [
        "## ðŸ“¦ Section 3: Register Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vj-TVAxI226N"
      },
      "outputs": [],
      "source": [
        "# Register models from timm\n",
        "from ddriver.models import registry\n",
        "\n",
        "registry.register_timm_backbone(\"efficientnet_b0\")\n",
        "# registry.register_timm_backbone(\"convnext_tiny\")\n",
        "# registry.register_timm_backbone(\"resnet50\")\n",
        "\n",
        "print(\"Available models:\", registry.available_models()[:10])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TF3KHZ1C226N"
      },
      "source": [
        "## ðŸš‚ Section 4: Training Configuration & Execution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9uKPv-A226N"
      },
      "outputs": [],
      "source": [
        "# ðŸš‚ TRAINING CONFIGURATION\n",
        "import os\n",
        "import subprocess, textwrap, json, time, threading\n",
        "from pathlib import Path\n",
        "\n",
        "# ============== EXPERIMENT CONFIG ==============\n",
        "RUN_TAG = \"effb0_face_v1\"           # <<<< CHANGE for each experiment\n",
        "MODEL_NAME = \"efficientnet_b0\"\n",
        "SEED = 42                           # <<<< CHANGE for stability runs (e.g., 42, 123, 456)\n",
        "\n",
        "# Training hyperparameters\n",
        "EPOCHS = 30\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = 2\n",
        "IMAGE_SIZE = 224\n",
        "LR = 3e-4\n",
        "LABEL_SMOOTHING = 0.05\n",
        "USE_TINY_SPLIT = False\n",
        "\n",
        "# Data source: choose ONE\n",
        "USE_HYBRID = True                   # True = use hybrid crops\n",
        "ROI_VARIANT = \"face\"                # face | face_hands (only if USE_HYBRID=True)\n",
        "\n",
        "# Control split selection (for 5-run experimental plan)\n",
        "# Set to None for natural runs, or \"facesubset\" / \"fhsubset\" / \"both\" for control runs\n",
        "# NOTE: Control splits only work with full-frame (USE_HYBRID=False)\n",
        "USE_CONTROL_SPLIT = None            # None | \"facesubset\" | \"fhsubset\" | \"both\"\n",
        "\n",
        "# Validate settings\n",
        "if USE_CONTROL_SPLIT and USE_HYBRID:\n",
        "    raise ValueError(\"Control splits require full-frame training. Set USE_HYBRID=False to use control splits.\")\n",
        "\n",
        "# ============== BUILD PATHS ==============\n",
        "if USE_HYBRID:\n",
        "    hybrid_root = Path(os.environ.get(\"HYBRID_ROOT_LOCAL\", Path(OUT_ROOT) / \"hybrid\"))\n",
        "    manifest_csv = hybrid_root / f\"manifest_{ROI_VARIANT}.csv\"\n",
        "    train_split = f\"train_{ROI_VARIANT}.csv\" if not USE_TINY_SPLIT else f\"train_small_{ROI_VARIANT}.csv\"\n",
        "    train_csv = hybrid_root / train_split\n",
        "    val_csv = hybrid_root / f\"val_{ROI_VARIANT}.csv\"\n",
        "    test_csv = hybrid_root / f\"test_{ROI_VARIANT}.csv\"\n",
        "    print(f\"ðŸ”€ Using Hybrid crops: {ROI_VARIANT}\")\n",
        "    print(f\"   hybrid_root = {hybrid_root}\")\n",
        "else:\n",
        "    manifest_csv = Path(OUT_ROOT) / \"manifests\" / \"manifest.csv\"\n",
        "    # Handle control splits for 5-run experimental plan\n",
        "    if USE_CONTROL_SPLIT:\n",
        "        control_root = Path(OUT_ROOT) / \"splits\" / \"control\"\n",
        "        train_csv = control_root / f\"train_{USE_CONTROL_SPLIT}.csv\"\n",
        "        val_csv = control_root / f\"val_{USE_CONTROL_SPLIT}.csv\"\n",
        "        test_csv = control_root / f\"test_{USE_CONTROL_SPLIT}.csv\"\n",
        "        print(f\"ðŸ“· Using full-frame images with CONTROL SPLIT: {USE_CONTROL_SPLIT}\")\n",
        "        print(f\"   (Filtered to {USE_CONTROL_SPLIT} IDs for fair comparison)\")\n",
        "    else:\n",
        "        train_split = \"train_small.csv\" if USE_TINY_SPLIT else \"train.csv\"\n",
        "        train_csv = Path(OUT_ROOT) / \"splits\" / train_split\n",
        "        val_csv = Path(OUT_ROOT) / \"splits\" / \"val.csv\"\n",
        "        test_csv = Path(OUT_ROOT) / \"splits\" / \"test.csv\"\n",
        "        print(\"ðŸ“· Using full-frame images\")\n",
        "\n",
        "# Update DATASET_ROOT for hybrid\n",
        "if USE_HYBRID:\n",
        "    _roi_root = hybrid_root\n",
        "    if str(_roi_root).startswith(\"/content/data\"):\n",
        "        import importlib\n",
        "        os.environ[\"DATASET_ROOT\"] = str(_roi_root)\n",
        "        from ddriver import config as _cfg\n",
        "        importlib.reload(_cfg)\n",
        "        print(f\"   âš¡ DATASET_ROOT = {os.environ['DATASET_ROOT']}\")\n",
        "\n",
        "print(f\"\\nðŸ“‹ Training config:\")\n",
        "print(f\"   RUN_TAG: {RUN_TAG}\")\n",
        "print(f\"   Model: {MODEL_NAME}\")\n",
        "print(f\"   Seed: {SEED}\")\n",
        "print(f\"   Epochs: {EPOCHS}, Batch: {BATCH_SIZE}, LR: {LR}\")\n",
        "if USE_CONTROL_SPLIT:\n",
        "    print(f\"   Control Split: {USE_CONTROL_SPLIT}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THth8uvp226O"
      },
      "outputs": [],
      "source": [
        "# ðŸš‚ RUN TRAINING\n",
        "\n",
        "\n",
        "\n",
        "# ============== FIX: Convert absolute Drive paths to relative ==============\n",
        "# This ensures DATASET_ROOT is respected even if manifest has absolute paths\n",
        "import pandas as pd\n",
        "\n",
        "def _make_relative(path_str: str) -> str:\n",
        "    \"\"\"Convert absolute path to relative from dataset marker.\"\"\"\n",
        "    marker = \"auc.distracted.driver.dataset_v2\"\n",
        "    if marker in path_str:\n",
        "        idx = path_str.find(marker)\n",
        "        return path_str[idx:]  # Keep from mabrker onwards\n",
        "    return path_str\n",
        "\n",
        "# Patch the split CSVs to use relative paths\n",
        "for csv_path in [train_csv, val_csv, test_csv]:\n",
        "    if Path(csv_path).exists():\n",
        "        df = pd.read_csv(csv_path)\n",
        "        if \"path\" in df.columns:\n",
        "            sample_path = df[\"path\"].iloc[0] if len(df) > 0 else \"\"\n",
        "            if \"/content/drive\" in sample_path:\n",
        "                print(f\"âš ï¸  Converting {csv_path.name} paths to relative...\")\n",
        "                df[\"path\"] = df[\"path\"].apply(_make_relative)\n",
        "                # Write to local temp location\n",
        "                local_csv = Path(\"/content\") / csv_path.name\n",
        "                df.to_csv(local_csv, index=False)\n",
        "                if \"train\" in str(csv_path):\n",
        "                    train_csv = local_csv\n",
        "                elif \"val\" in str(csv_path):\n",
        "                    val_csv = local_csv\n",
        "                elif \"test\" in str(csv_path):\n",
        "                    test_csv = local_csv\n",
        "                print(f\"   âœ… Wrote {local_csv} with relative paths\")\n",
        "\n",
        "# Also verify DATASET_ROOT\n",
        "print(f\"\\nðŸ” DATASET_ROOT = {os.environ.get('DATASET_ROOT')}\")\n",
        "fast_images = Path(\"/content/data/auc.distracted.driver.dataset_v2\")\n",
        "if fast_images.exists():\n",
        "    print(f\"   âœ… Fast storage contains images\")\n",
        "else:\n",
        "    print(f\"   âŒ WARNING: {fast_images} does not exist!\")\n",
        "\n",
        "train_cmd = textwrap.dedent(f\"\"\"\n",
        "cd {PROJECT_ROOT}\n",
        "python -m src.ddriver.cli.train \\\n",
        "    --model-name {MODEL_NAME} \\\n",
        "    --epochs {EPOCHS} \\\n",
        "    --batch-size {BATCH_SIZE} \\\n",
        "    --num-workers {NUM_WORKERS} \\\n",
        "    --image-size {IMAGE_SIZE} \\\n",
        "    --lr {LR} \\\n",
        "    --weight-decay .01 \\\n",
        "    --optimizer adamw \\\n",
        "    --label-smoothing {LABEL_SMOOTHING} \\\n",
        "    --seed {SEED} \\\n",
        "    --out-tag {RUN_TAG} \\\n",
        "    --manifest-csv {manifest_csv} \\\n",
        "    --train-csv {train_csv} \\\n",
        "    --val-csv {val_csv} \\\n",
        "    --test-csv {test_csv}\n",
        "\"\"\")\n",
        "\n",
        "print(\"Running training command:\\n\", train_cmd)\n",
        "\n",
        "proc = subprocess.Popen(train_cmd, shell=True, text=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
        "\n",
        "# GPU monitor thread\n",
        "def _gpu_monitor():\n",
        "    while proc.poll() is None:\n",
        "        try:\n",
        "            stats = subprocess.check_output(\n",
        "                \"nvidia-smi --query-gpu=utilization.gpu,memory.used,memory.total --format=csv,nounits,noheader\",\n",
        "                shell=True,\n",
        "            ).decode(\"utf-8\").strip()\n",
        "            print(f\"[GPU] {stats}\")\n",
        "        except:\n",
        "            pass\n",
        "        time.sleep(5)\n",
        "\n",
        "monitor = threading.Thread(target=_gpu_monitor, daemon=True)\n",
        "monitor.start()\n",
        "\n",
        "for line in proc.stdout:\n",
        "    print(line, end=\"\")\n",
        "\n",
        "proc.wait()\n",
        "print(\"\\nâœ… Training complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeKT0ZBf226O"
      },
      "source": [
        "## ðŸ“ˆ Section 5: Learning Curves Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0g4VQeb226O"
      },
      "outputs": [],
      "source": [
        "# ðŸ“ˆ Display training metrics and learning curves\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "run_base = Path(CKPT_ROOT) / \"runs\" / RUN_TAG\n",
        "all_runs = sorted(run_base.glob(\"*/\"))\n",
        "if not all_runs:\n",
        "    raise FileNotFoundError(f\"No run folders found under {run_base}\")\n",
        "latest_run = all_runs[-1]\n",
        "\n",
        "history_path = latest_run / \"history.json\"\n",
        "if not history_path.exists():\n",
        "    raise FileNotFoundError(f\"history.json not found in {latest_run}\")\n",
        "\n",
        "history = json.loads(history_path.read_text()).get(\"history\", [])\n",
        "\n",
        "print(f\"ðŸ“Š Epoch metrics for run: {latest_run.name}\")\n",
        "for record in history:\n",
        "    train_metrics = record.get(\"train\", {})\n",
        "    val_metrics = record.get(\"val\", {}) or {}\n",
        "    train_loss = train_metrics.get(\"loss\")\n",
        "    train_acc = train_metrics.get(\"accuracy\")\n",
        "    val_loss = val_metrics.get(\"loss\")\n",
        "    val_acc = val_metrics.get(\"accuracy\")\n",
        "    val_str = f\"val_loss={val_loss:.4f} acc={val_acc:.4f}\" if val_loss else \"val_loss=â€” val_acc=â€”\"\n",
        "    print(f\"  Epoch {record['epoch']:>2}: train_loss={train_loss:.4f} acc={train_acc:.4f}  {val_str}\")\n",
        "\n",
        "# Plot learning curves\n",
        "epochs = [r[\"epoch\"] for r in history]\n",
        "train_loss = [r[\"train\"][\"loss\"] for r in history]\n",
        "train_acc = [r[\"train\"][\"accuracy\"] for r in history]\n",
        "val_loss = [(r.get(\"val\") or {}).get(\"loss\") for r in history]\n",
        "val_acc = [(r.get(\"val\") or {}).get(\"accuracy\") for r in history]\n",
        "\n",
        "val_epochs = [e for e, v in zip(epochs, val_loss) if v is not None]\n",
        "val_loss_f = [v for v in val_loss if v is not None]\n",
        "val_acc_f = [v for v in val_acc if v is not None]\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4), dpi=140)\n",
        "\n",
        "axes[0].plot(epochs, train_acc, label=\"Training Accuracy\")\n",
        "if val_acc_f:\n",
        "    axes[0].plot(val_epochs, val_acc_f, label=\"Validation Accuracy\")\n",
        "axes[0].set_title(\"Accuracy Curves\")\n",
        "axes[0].set_xlabel(\"Epochs\")\n",
        "axes[0].set_ylabel(\"Accuracy\")\n",
        "axes[0].legend()\n",
        "\n",
        "axes[1].plot(epochs, train_loss, label=\"Training Loss\")\n",
        "if val_loss_f:\n",
        "    axes[1].plot(val_epochs, val_loss_f, label=\"Validation Loss\")\n",
        "axes[1].set_title(\"Loss Curves\")\n",
        "axes[1].set_xlabel(\"Epochs\")\n",
        "axes[1].set_ylabel(\"Loss\")\n",
        "axes[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "out_png = latest_run / \"learning_curves.png\"\n",
        "fig.savefig(out_png, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "print(\"âœ… Saved:\", out_png)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ“Š Annex Figures: Training Curves Comparison\n",
        "# Generates Figure A.1 (Face vs Full-frame FaceSubset) and Figure A.2 (Face+Hands vs Full-frame FHSubset)\n",
        "\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "\n",
        "# ============== CONFIGURATION ==============\n",
        "CKPT_ROOT = Path(\"/content/drive/MyDrive/TFM/checkpoints\")\n",
        "\n",
        "# Run tags for each experiment\n",
        "RUN_TAGS = {\n",
        "    \"face\": \"effb0_face_1_11\",\n",
        "    \"face_hands\": \"effb0_face_hands_1_11\",\n",
        "    \"full_facesubset\": \"effb0_full_image_facesubset_1_10\",\n",
        "    \"full_fhsubset\": \"effb0_full_image_fhsubset_1_10\",\n",
        "}\n",
        "\n",
        "# Color scheme (consistent across all figures)\n",
        "COLORS = {\n",
        "    \"face\": \"tab:blue\",\n",
        "    \"full_facesubset\": \"tab:orange\",\n",
        "    \"face_hands\": \"tab:green\",\n",
        "    \"full_fhsubset\": \"tab:red\",\n",
        "}\n",
        "\n",
        "# ============== HELPER FUNCTIONS ==============\n",
        "\n",
        "def load_history(run_tag: str) -> dict:\n",
        "    \"\"\"Load history.json for a given run tag, returning the latest run.\"\"\"\n",
        "    run_base = CKPT_ROOT / \"runs\" / run_tag\n",
        "    all_runs = sorted(run_base.glob(\"*/\"))\n",
        "    if not all_runs:\n",
        "        raise FileNotFoundError(f\"No run folders found under {run_base}\")\n",
        "    latest_run = all_runs[-1]\n",
        "\n",
        "    history_path = latest_run / \"history.json\"\n",
        "    if not history_path.exists():\n",
        "        raise FileNotFoundError(f\"history.json not found in {latest_run}\")\n",
        "\n",
        "    data = json.loads(history_path.read_text())\n",
        "    history = data.get(\"history\", [])\n",
        "\n",
        "    # Extract arrays\n",
        "    epochs = [r[\"epoch\"] for r in history]\n",
        "    train_acc = [r[\"train\"][\"accuracy\"] for r in history]\n",
        "    train_loss = [r[\"train\"][\"loss\"] for r in history]\n",
        "    val_acc = [(r.get(\"val\") or {}).get(\"accuracy\") for r in history]\n",
        "    val_loss = [(r.get(\"val\") or {}).get(\"loss\") for r in history]\n",
        "\n",
        "    # Filter out None values for validation (in case some epochs skipped validation)\n",
        "    val_epochs = [e for e, v in zip(epochs, val_acc) if v is not None]\n",
        "    val_acc_clean = [v for v in val_acc if v is not None]\n",
        "    val_loss_clean = [v for v in val_loss if v is not None]\n",
        "\n",
        "    return {\n",
        "        \"run_dir\": latest_run,\n",
        "        \"epochs\": epochs,\n",
        "        \"train_acc\": train_acc,\n",
        "        \"train_loss\": train_loss,\n",
        "        \"val_epochs\": val_epochs,\n",
        "        \"val_acc\": val_acc_clean,\n",
        "        \"val_loss\": val_loss_clean,\n",
        "    }\n",
        "\n",
        "\n",
        "def compute_axis_limits(histories: list, metric: str, padding: float = 0.05):\n",
        "    \"\"\"Compute shared y-axis limits across multiple histories for a given metric.\"\"\"\n",
        "    all_values = []\n",
        "    for h in histories:\n",
        "        if metric == \"acc\":\n",
        "            all_values.extend(h[\"train_acc\"])\n",
        "            all_values.extend(h[\"val_acc\"])\n",
        "        else:  # loss\n",
        "            all_values.extend(h[\"train_loss\"])\n",
        "            all_values.extend(h[\"val_loss\"])\n",
        "\n",
        "    ymin, ymax = min(all_values), max(all_values)\n",
        "    margin = (ymax - ymin) * padding\n",
        "    return (ymin - margin, ymax + margin)\n",
        "\n",
        "\n",
        "def create_comparison_figure(\n",
        "    hist_roi: dict,\n",
        "    hist_full: dict,\n",
        "    roi_key: str,\n",
        "    full_key: str,\n",
        "    roi_label: str,\n",
        "    full_label: str,\n",
        "    title_suffix: str,\n",
        "    acc_ylim: tuple,\n",
        "    loss_ylim: tuple,\n",
        "    output_path: Path,\n",
        "):\n",
        "    \"\"\"Create a 1x2 figure comparing ROI vs Full-frame training curves.\"\"\"\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 4.5), sharex=True, dpi=150)\n",
        "\n",
        "    # --- Left subplot: Accuracy ---\n",
        "    ax = axes[0]\n",
        "\n",
        "    # ROI model\n",
        "    ax.plot(hist_roi[\"epochs\"], hist_roi[\"train_acc\"],\n",
        "            color=COLORS[roi_key], linestyle='-', linewidth=1.5,\n",
        "            label=f\"{roi_label} â€“ train\")\n",
        "    ax.plot(hist_roi[\"val_epochs\"], hist_roi[\"val_acc\"],\n",
        "            color=COLORS[roi_key], linestyle='--', linewidth=1.5,\n",
        "            label=f\"{roi_label} â€“ val\")\n",
        "\n",
        "    # Full-frame model\n",
        "    ax.plot(hist_full[\"epochs\"], hist_full[\"train_acc\"],\n",
        "            color=COLORS[full_key], linestyle='-', linewidth=1.5,\n",
        "            label=f\"{full_label} â€“ train\")\n",
        "    ax.plot(hist_full[\"val_epochs\"], hist_full[\"val_acc\"],\n",
        "            color=COLORS[full_key], linestyle='--', linewidth=1.5,\n",
        "            label=f\"{full_label} â€“ val\")\n",
        "\n",
        "    ax.set_title(f\"{title_suffix} â€“ Accuracy\", fontsize=11, fontweight='bold')\n",
        "    ax.set_xlabel(\"Epoch\")\n",
        "    ax.set_ylabel(\"Accuracy\")\n",
        "    ax.set_ylim(acc_ylim)\n",
        "    ax.legend(loc='lower right', fontsize=8)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    # --- Right subplot: Loss ---\n",
        "    ax = axes[1]\n",
        "\n",
        "    # ROI model\n",
        "    ax.plot(hist_roi[\"epochs\"], hist_roi[\"train_loss\"],\n",
        "            color=COLORS[roi_key], linestyle='-', linewidth=1.5,\n",
        "            label=f\"{roi_label} â€“ train\")\n",
        "    ax.plot(hist_roi[\"val_epochs\"], hist_roi[\"val_loss\"],\n",
        "            color=COLORS[roi_key], linestyle='--', linewidth=1.5,\n",
        "            label=f\"{roi_label} â€“ val\")\n",
        "\n",
        "    # Full-frame model\n",
        "    ax.plot(hist_full[\"epochs\"], hist_full[\"train_loss\"],\n",
        "            color=COLORS[full_key], linestyle='-', linewidth=1.5,\n",
        "            label=f\"{full_label} â€“ train\")\n",
        "    ax.plot(hist_full[\"val_epochs\"], hist_full[\"val_loss\"],\n",
        "            color=COLORS[full_key], linestyle='--', linewidth=1.5,\n",
        "            label=f\"{full_label} â€“ val\")\n",
        "\n",
        "    ax.set_title(f\"{title_suffix} â€“ Loss\", fontsize=11, fontweight='bold')\n",
        "    ax.set_xlabel(\"Epoch\")\n",
        "    ax.set_ylabel(\"Cross-Entropy Loss\")\n",
        "    ax.set_ylim(loss_ylim)\n",
        "    ax.legend(loc='upper right', fontsize=8)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    fig.savefig(output_path, bbox_inches='tight', dpi=150)\n",
        "    plt.show()\n",
        "    print(f\"âœ… Saved: {output_path}\")\n",
        "    return fig\n",
        "\n",
        "\n",
        "# ============== MAIN EXECUTION ==============\n",
        "\n",
        "print(\"ðŸ“‚ Loading training histories...\")\n",
        "\n",
        "# Load all histories\n",
        "hist_face = load_history(RUN_TAGS[\"face\"])\n",
        "hist_face_hands = load_history(RUN_TAGS[\"face_hands\"])\n",
        "hist_full_facesubset = load_history(RUN_TAGS[\"full_facesubset\"])\n",
        "hist_full_fhsubset = load_history(RUN_TAGS[\"full_fhsubset\"])\n",
        "\n",
        "print(f\"   âœ“ Face ROI: {len(hist_face['epochs'])} epochs\")\n",
        "print(f\"   âœ“ Face+Hands ROI: {len(hist_face_hands['epochs'])} epochs\")\n",
        "print(f\"   âœ“ Full-frame (Face IDs): {len(hist_full_facesubset['epochs'])} epochs\")\n",
        "print(f\"   âœ“ Full-frame (FH IDs): {len(hist_full_fhsubset['epochs'])} epochs\")\n",
        "\n",
        "# Compute shared axis limits across ALL runs for fair visual comparison\n",
        "all_histories = [hist_face, hist_face_hands, hist_full_facesubset, hist_full_fhsubset]\n",
        "acc_ylim = compute_axis_limits(all_histories, \"acc\", padding=0.03)\n",
        "loss_ylim = compute_axis_limits(all_histories, \"loss\", padding=0.05)\n",
        "\n",
        "print(f\"\\nðŸ“ Shared axis limits:\")\n",
        "print(f\"   Accuracy: {acc_ylim[0]:.3f} â€“ {acc_ylim[1]:.3f}\")\n",
        "print(f\"   Loss: {loss_ylim[0]:.3f} â€“ {loss_ylim[1]:.3f}\")\n",
        "\n",
        "# ============== FIGURE A.1: Face vs Full-frame (Face IDs) ==============\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸ“Š Creating Annex Figure A.1: Face vs Full-frame (Face IDs)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "output_a1 = hist_face[\"run_dir\"] / \"annex_A1_face_vs_full_faceIDs_curves.png\"\n",
        "\n",
        "create_comparison_figure(\n",
        "    hist_roi=hist_face,\n",
        "    hist_full=hist_full_facesubset,\n",
        "    roi_key=\"face\",\n",
        "    full_key=\"full_facesubset\",\n",
        "    roi_label=\"Face ROI\",\n",
        "    full_label=\"Full-frame (Face IDs)\",\n",
        "    title_suffix=\"Face vs Full-frame (Face IDs)\",\n",
        "    acc_ylim=acc_ylim,\n",
        "    loss_ylim=loss_ylim,\n",
        "    output_path=output_a1,\n",
        ")\n",
        "\n",
        "# ============== FIGURE A.2: Face+Hands vs Full-frame (FH IDs) ==============\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸ“Š Creating Annex Figure A.2: Face+Hands vs Full-frame (FH IDs)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "output_a2 = hist_face_hands[\"run_dir\"] / \"annex_A2_fh_vs_full_fhIDs_curves.png\"\n",
        "\n",
        "create_comparison_figure(\n",
        "    hist_roi=hist_face_hands,\n",
        "    hist_full=hist_full_fhsubset,\n",
        "    roi_key=\"face_hands\",\n",
        "    full_key=\"full_fhsubset\",\n",
        "    roi_label=\"Face+Hands ROI\",\n",
        "    full_label=\"Full-frame (FH IDs)\",\n",
        "    title_suffix=\"Face+Hands vs Full-frame (FH IDs)\",\n",
        "    acc_ylim=acc_ylim,\n",
        "    loss_ylim=loss_ylim,\n",
        "    output_path=output_a2,\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"âœ… All Annex figures generated!\")\n",
        "print(f\"   A.1: {output_a1}\")\n",
        "print(f\"   A.2: {output_a2}\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "yCSKtzN86ml9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptAFz4xo226P"
      },
      "source": [
        "## âœ… Training Complete!\n",
        "\n",
        "**Outputs saved to Drive:**\n",
        "- `CKPT_ROOT/runs/{RUN_TAG}/{timestamp}/best.pt` â€” Best checkpoint\n",
        "- `CKPT_ROOT/runs/{RUN_TAG}/{timestamp}/history.json` â€” Training history\n",
        "- `CKPT_ROOT/runs/{RUN_TAG}/{timestamp}/learning_curves.png` â€” Curves figure\n",
        "\n",
        "**Next steps:**\n",
        "- Run **03_evaluation.ipynb** to generate predictions and metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWX5366h226P"
      },
      "outputs": [],
      "source": [
        "# ðŸ“ Training summary â†’ Google Sheet\n",
        "!pip -q install gspread\n",
        "\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "import gspread\n",
        "from google.colab import auth\n",
        "import google.auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "creds, _ = google.auth.default()\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "TRAIN_SHEET_NAME = \"TFM Train Logs\"   # create this sheet/tab ahead of time\n",
        "TRAIN_WORKSHEET = \"Sheet1\"\n",
        "\n",
        "run_base = Path(CKPT_ROOT) / \"runs\" / RUN_TAG\n",
        "all_runs = sorted(run_base.glob(\"*/\"))\n",
        "if not all_runs:\n",
        "    raise FileNotFoundError(f\"No run folders found under {run_base}\")\n",
        "latest_run = all_runs[-1]\n",
        "print(f\"Logging training summary for run folder: {latest_run}\")\n",
        "\n",
        "history_path = latest_run / \"history.json\"\n",
        "if not history_path.exists():\n",
        "    raise FileNotFoundError(f\"history.json not found under {latest_run}\")\n",
        "\n",
        "history_records = json.loads(history_path.read_text()).get(\"history\", [])\n",
        "if not history_records:\n",
        "    raise ValueError(f\"history.json under {latest_run} has no records.\")\n",
        "\n",
        "params_path = latest_run / \"params.json\"\n",
        "params = json.loads(params_path.read_text()) if params_path.exists() else {}\n",
        "\n",
        "model_name = params.get(\"model_name\", MODEL_NAME)\n",
        "epochs_cfg = params.get(\"epochs\", EPOCHS)\n",
        "batch_cfg = params.get(\"batch_size\", BATCH_SIZE)\n",
        "lr_cfg = params.get(\"lr\", LR)\n",
        "#lr_drop_epoch_cfg = params.get(\"lr_drop_epoch\", LR_DROP_EPOCH)\n",
        "#lr_drop_factor_cfg = params.get(\"lr_drop_factor\", LR_DROP_FACTOR)\n",
        "image_size_cfg = params.get(\"image_size\", IMAGE_SIZE)\n",
        "num_workers_cfg = params.get(\"num_workers\", NUM_WORKERS)\n",
        "use_tiny_cfg = params.get(\"use_tiny_split\", USE_TINY_SPLIT)\n",
        "\n",
        "\n",
        "def _best_metric(records, split: str) -> tuple[dict, float | None]:\n",
        "    best_epoch = None\n",
        "    best_acc = None\n",
        "    for rec in records:\n",
        "        split_metrics = rec.get(split) or {}\n",
        "        acc = split_metrics.get(\"accuracy\")\n",
        "        if acc is None:\n",
        "            continue\n",
        "        if best_acc is None or acc > best_acc:\n",
        "            best_acc = acc\n",
        "            best_epoch = rec.get(\"epoch\")\n",
        "    final_metrics = records[-1].get(split) or {}\n",
        "    final_acc = final_metrics.get(\"accuracy\")\n",
        "    return {\"epoch\": best_epoch, \"accuracy\": best_acc}, final_acc\n",
        "\n",
        "\n",
        "best_train, final_train = _best_metric(history_records, \"train\")\n",
        "best_val, final_val = _best_metric(history_records, \"val\")\n",
        "\n",
        "row = [\n",
        "    RUN_TAG,\n",
        "    latest_run.name,\n",
        "    model_name,\n",
        "    epochs_cfg,\n",
        "    batch_cfg,\n",
        "    lr_cfg,\n",
        "    #lr_drop_epoch_cfg,\n",
        "    #lr_drop_factor_cfg,\n",
        "    image_size_cfg,\n",
        "    num_workers_cfg,\n",
        "    use_tiny_cfg,\n",
        "    best_train[\"epoch\"] if best_train[\"epoch\"] is not None else \"\",\n",
        "    round(best_train[\"accuracy\"], 4) if best_train[\"accuracy\"] is not None else \"\",\n",
        "    best_val[\"epoch\"] if best_val[\"epoch\"] is not None else \"\",\n",
        "    round(best_val[\"accuracy\"], 4) if best_val[\"accuracy\"] is not None else \"\",\n",
        "    round(final_train, 4) if final_train is not None else \"\",\n",
        "    round(final_val, 4) if final_val is not None else \"\",\n",
        "]\n",
        "\n",
        "ws = gc.open(TRAIN_SHEET_NAME).worksheet(TRAIN_WORKSHEET)\n",
        "ws.append_row(row, value_input_option=\"USER_ENTERED\")\n",
        "print(f\"Appended training summary for {latest_run.name} âœ…\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}