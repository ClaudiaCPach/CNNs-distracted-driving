{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸš‚ 02 â€” Training\n",
        "\n",
        "**Purpose:** Train models on full images or hybrid ROI crops.\n",
        "\n",
        "**Sections:**\n",
        "1. Inline Setup\n",
        "2. Copy Data to /content (full images OR hybrid crops)\n",
        "3. Register Models\n",
        "4. Training Configuration & Execution\n",
        "5. Learning Curves Visualization\n",
        "\n",
        "**Prerequisites:** Manifests and splits exist on Drive (from 01_data_preparation.ipynb or prior run)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ”§ Section 1: Inline Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- INLINE SETUP ---\n",
        "import os, subprocess, sys\n",
        "\n",
        "# Config\n",
        "REPO_URL       = \"https://github.com/ClaudiaCPach/CNNs-distracted-driving\"\n",
        "REPO_DIRNAME   = \"CNNs-distracted-driving\"\n",
        "BRANCH         = \"main\"\n",
        "PROJECT_ROOT   = f\"/content/{REPO_DIRNAME}\"\n",
        "DRIVE_PATH     = \"/content/drive/MyDrive/TFM\"\n",
        "DRIVE_DATA_ROOT = f\"{DRIVE_PATH}/data\"\n",
        "FAST_DATA      = \"/content/data\"\n",
        "DATASET_ROOT   = DRIVE_DATA_ROOT\n",
        "OUT_ROOT       = f\"{DRIVE_PATH}/outputs\"\n",
        "CKPT_ROOT      = f\"{DRIVE_PATH}/checkpoints\"\n",
        "\n",
        "# Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "# Clone/update repo\n",
        "def sh(cmd):\n",
        "    print(f\"$ {cmd}\")\n",
        "    rc = subprocess.call(cmd, shell=True, executable=\"/bin/bash\")\n",
        "    if rc != 0:\n",
        "        raise RuntimeError(f\"Command failed: {cmd}\")\n",
        "\n",
        "if os.path.isdir(PROJECT_ROOT):\n",
        "    sh(f\"cd {PROJECT_ROOT} && git pull --rebase origin {BRANCH}\")\n",
        "else:\n",
        "    sh(f\"git clone --branch {BRANCH} {REPO_URL} {PROJECT_ROOT}\")\n",
        "\n",
        "# Install\n",
        "sh(f\"pip install -q -e {PROJECT_ROOT}\")\n",
        "!pip -q install timm\n",
        "\n",
        "# Set env vars\n",
        "os.environ[\"DRIVE_PATH\"] = DRIVE_PATH\n",
        "os.environ[\"DATASET_ROOT\"] = DATASET_ROOT\n",
        "os.environ[\"OUT_ROOT\"] = OUT_ROOT\n",
        "os.environ[\"CKPT_ROOT\"] = CKPT_ROOT\n",
        "os.environ[\"FAST_DATA\"] = FAST_DATA\n",
        "\n",
        "sys.path.insert(0, PROJECT_ROOT)\n",
        "sys.path.insert(0, os.path.join(PROJECT_ROOT, \"src\"))\n",
        "\n",
        "# GPU check\n",
        "!nvidia-smi || echo \"No GPU\"\n",
        "print(\"âœ… Inline setup complete\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âš¡ Section 2: Copy Data to /content\n",
        "\n",
        "Choose ONE of the options below based on what you're training on.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# âš¡ OPTION A: Copy HYBRID CROPS to /content (for face/face_hands training)\n",
        "import os, shutil\n",
        "from pathlib import Path\n",
        "import importlib\n",
        "\n",
        "HYBRID_VARIANT = \"face\"  # face | face_hands\n",
        "\n",
        "LOCAL_ROOT = Path(\"/content/data/hybrid\")\n",
        "DRIVE_ROOT = Path(OUT_ROOT) / \"hybrid\"\n",
        "\n",
        "LOCAL_VARIANT_DIR = LOCAL_ROOT / HYBRID_VARIANT\n",
        "DRIVE_VARIANT_DIR = DRIVE_ROOT / HYBRID_VARIANT\n",
        "\n",
        "def count_jpgs(p: Path) -> int:\n",
        "    return sum(1 for _ in p.rglob(\"*.jpg\")) if p.exists() else 0\n",
        "\n",
        "local_count = count_jpgs(LOCAL_VARIANT_DIR)\n",
        "drive_count = count_jpgs(DRIVE_VARIANT_DIR)\n",
        "\n",
        "print(f\"ðŸ”Ž Local: {local_count} jpgs | Drive: {drive_count} jpgs\")\n",
        "\n",
        "if local_count > 0:\n",
        "    print(f\"âœ… Hybrid crops already in /content. Skipping copy.\")\n",
        "elif drive_count == 0:\n",
        "    raise FileNotFoundError(f\"No crops on Drive at {DRIVE_VARIANT_DIR}\")\n",
        "else:\n",
        "    print(f\"ðŸ“¦ Copying {HYBRID_VARIANT} crops from Drive to /content...\")\n",
        "    LOCAL_VARIANT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    file_count = 0\n",
        "    for src_dir, _, files in os.walk(DRIVE_VARIANT_DIR):\n",
        "        rel_dir = Path(src_dir).relative_to(DRIVE_VARIANT_DIR)\n",
        "        dst_dir = LOCAL_VARIANT_DIR / rel_dir\n",
        "        dst_dir.mkdir(parents=True, exist_ok=True)\n",
        "        for fname in files:\n",
        "            if fname.lower().endswith(\".jpg\"):\n",
        "                shutil.copy2(Path(src_dir) / fname, dst_dir / fname)\n",
        "                file_count += 1\n",
        "    print(f\"   Copied {file_count} images\")\n",
        "    \n",
        "    # Copy CSVs\n",
        "    for fname in [f\"manifest_{HYBRID_VARIANT}.csv\", f\"train_{HYBRID_VARIANT}.csv\", \n",
        "                  f\"val_{HYBRID_VARIANT}.csv\", f\"test_{HYBRID_VARIANT}.csv\"]:\n",
        "        src = DRIVE_ROOT / fname\n",
        "        if src.exists():\n",
        "            shutil.copy2(src, LOCAL_ROOT / fname)\n",
        "            print(f\"   Copied {fname}\")\n",
        "\n",
        "# Update env vars\n",
        "os.environ[\"HYBRID_ROOT_LOCAL\"] = str(LOCAL_ROOT)\n",
        "os.environ[\"DATASET_ROOT\"] = str(LOCAL_ROOT)\n",
        "from ddriver import config as _cfg\n",
        "importlib.reload(_cfg)\n",
        "print(f\"\\nâœ… DATASET_ROOT = {os.environ['DATASET_ROOT']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# âš¡ OPTION B: Copy FULL IMAGES to /content (for full-frame training)\n",
        "# Skip this if using hybrid crops above\n",
        "\n",
        "import importlib\n",
        "from pathlib import Path\n",
        "from ddriver.data.fastcopy import CompressionSpec, copy_splits_with_compression\n",
        "\n",
        "SRC_ROOT = Path(DRIVE_DATA_ROOT) / \"auc.distracted.driver.dataset_v2\"\n",
        "DST_ROOT = Path(FAST_DATA) / \"auc.distracted.driver.dataset_v2\"\n",
        "\n",
        "split_csvs = {\n",
        "    \"train\": Path(OUT_ROOT) / \"splits\" / \"train.csv\",\n",
        "    \"val\": Path(OUT_ROOT) / \"splits\" / \"val.csv\",\n",
        "    \"test\": Path(OUT_ROOT) / \"splits\" / \"test.csv\",\n",
        "}\n",
        "\n",
        "compression_spec = CompressionSpec(target_short_side=320, jpeg_quality=80)\n",
        "\n",
        "summary = copy_splits_with_compression(\n",
        "    split_csvs=split_csvs, src_root=SRC_ROOT, dst_root=DST_ROOT,\n",
        "    compression=compression_spec, skip_existing=True,\n",
        ")\n",
        "\n",
        "print(f\"ðŸ“‰ Copied {summary['processed']} files (skipped {summary['skipped']})\")\n",
        "\n",
        "os.environ[\"DATASET_ROOT\"] = str(FAST_DATA)\n",
        "from ddriver import config as _cfg\n",
        "importlib.reload(_cfg)\n",
        "print(f\"âœ… DATASET_ROOT = {os.environ['DATASET_ROOT']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“¦ Section 3: Register Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Register models from timm\n",
        "from ddriver.models import registry\n",
        "\n",
        "registry.register_timm_backbone(\"efficientnet_b0\")\n",
        "# registry.register_timm_backbone(\"convnext_tiny\")\n",
        "# registry.register_timm_backbone(\"resnet50\")\n",
        "\n",
        "print(\"Available models:\", registry.available_models()[:10])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸš‚ Section 4: Training Configuration & Execution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ðŸš‚ TRAINING CONFIGURATION\n",
        "import os\n",
        "import subprocess, textwrap, json, time, threading\n",
        "from pathlib import Path\n",
        "\n",
        "# ============== EXPERIMENT CONFIG ==============\n",
        "RUN_TAG = \"effb0_face_v1\"           # <<<< CHANGE for each experiment\n",
        "MODEL_NAME = \"efficientnet_b0\"\n",
        "SEED = 42                           # <<<< CHANGE for stability runs (e.g., 42, 123, 456)\n",
        "\n",
        "# Training hyperparameters\n",
        "EPOCHS = 30\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = 2\n",
        "IMAGE_SIZE = 224\n",
        "LR = 3e-4\n",
        "LABEL_SMOOTHING = 0.05\n",
        "USE_TINY_SPLIT = False\n",
        "\n",
        "# Data source: choose ONE\n",
        "USE_HYBRID = True                   # True = use hybrid crops\n",
        "ROI_VARIANT = \"face\"                # face | face_hands (only if USE_HYBRID=True)\n",
        "\n",
        "# Control split selection (for 5-run experimental plan)\n",
        "# Set to None for natural runs, or \"facesubset\" / \"fhsubset\" / \"both\" for control runs\n",
        "# NOTE: Control splits only work with full-frame (USE_HYBRID=False)\n",
        "USE_CONTROL_SPLIT = None            # None | \"facesubset\" | \"fhsubset\" | \"both\"\n",
        "\n",
        "# Validate settings\n",
        "if USE_CONTROL_SPLIT and USE_HYBRID:\n",
        "    raise ValueError(\"Control splits require full-frame training. Set USE_HYBRID=False to use control splits.\")\n",
        "\n",
        "# ============== BUILD PATHS ==============\n",
        "if USE_HYBRID:\n",
        "    hybrid_root = Path(os.environ.get(\"HYBRID_ROOT_LOCAL\", Path(OUT_ROOT) / \"hybrid\"))\n",
        "    manifest_csv = hybrid_root / f\"manifest_{ROI_VARIANT}.csv\"\n",
        "    train_split = f\"train_{ROI_VARIANT}.csv\" if not USE_TINY_SPLIT else f\"train_small_{ROI_VARIANT}.csv\"\n",
        "    train_csv = hybrid_root / train_split\n",
        "    val_csv = hybrid_root / f\"val_{ROI_VARIANT}.csv\"\n",
        "    test_csv = hybrid_root / f\"test_{ROI_VARIANT}.csv\"\n",
        "    print(f\"ðŸ”€ Using Hybrid crops: {ROI_VARIANT}\")\n",
        "    print(f\"   hybrid_root = {hybrid_root}\")\n",
        "else:\n",
        "    manifest_csv = Path(OUT_ROOT) / \"manifests\" / \"manifest.csv\"\n",
        "    # Handle control splits for 5-run experimental plan\n",
        "    if USE_CONTROL_SPLIT:\n",
        "        control_root = Path(OUT_ROOT) / \"splits\" / \"control\"\n",
        "        train_csv = control_root / f\"train_{USE_CONTROL_SPLIT}.csv\"\n",
        "        val_csv = control_root / f\"val_{USE_CONTROL_SPLIT}.csv\"\n",
        "        test_csv = control_root / f\"test_{USE_CONTROL_SPLIT}.csv\"\n",
        "        print(f\"ðŸ“· Using full-frame images with CONTROL SPLIT: {USE_CONTROL_SPLIT}\")\n",
        "        print(f\"   (Filtered to {USE_CONTROL_SPLIT} IDs for fair comparison)\")\n",
        "    else:\n",
        "        train_split = \"train_small.csv\" if USE_TINY_SPLIT else \"train.csv\"\n",
        "        train_csv = Path(OUT_ROOT) / \"splits\" / train_split\n",
        "        val_csv = Path(OUT_ROOT) / \"splits\" / \"val.csv\"\n",
        "        test_csv = Path(OUT_ROOT) / \"splits\" / \"test.csv\"\n",
        "        print(\"ðŸ“· Using full-frame images\")\n",
        "\n",
        "# Update DATASET_ROOT for hybrid\n",
        "if USE_HYBRID:\n",
        "    _roi_root = hybrid_root\n",
        "    if str(_roi_root).startswith(\"/content/data\"):\n",
        "        import importlib\n",
        "        os.environ[\"DATASET_ROOT\"] = str(_roi_root)\n",
        "        from ddriver import config as _cfg\n",
        "        importlib.reload(_cfg)\n",
        "        print(f\"   âš¡ DATASET_ROOT = {os.environ['DATASET_ROOT']}\")\n",
        "\n",
        "print(f\"\\nðŸ“‹ Training config:\")\n",
        "print(f\"   RUN_TAG: {RUN_TAG}\")\n",
        "print(f\"   Model: {MODEL_NAME}\")\n",
        "print(f\"   Seed: {SEED}\")\n",
        "print(f\"   Epochs: {EPOCHS}, Batch: {BATCH_SIZE}, LR: {LR}\")\n",
        "if USE_CONTROL_SPLIT:\n",
        "    print(f\"   Control Split: {USE_CONTROL_SPLIT}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ðŸš‚ RUN TRAINING\n",
        "train_cmd = textwrap.dedent(f\"\"\"\n",
        "cd {PROJECT_ROOT}\n",
        "python -m src.ddriver.cli.train \\\n",
        "    --model-name {MODEL_NAME} \\\n",
        "    --epochs {EPOCHS} \\\n",
        "    --batch-size {BATCH_SIZE} \\\n",
        "    --num-workers {NUM_WORKERS} \\\n",
        "    --image-size {IMAGE_SIZE} \\\n",
        "    --lr {LR} \\\n",
        "    --weight-decay .01 \\\n",
        "    --optimizer adamw \\\n",
        "    --label-smoothing {LABEL_SMOOTHING} \\\n",
        "    --seed {SEED} \\\n",
        "    --out-tag {RUN_TAG} \\\n",
        "    --manifest-csv {manifest_csv} \\\n",
        "    --train-csv {train_csv} \\\n",
        "    --val-csv {val_csv} \\\n",
        "    --test-csv {test_csv}\n",
        "\"\"\")\n",
        "\n",
        "print(\"Running training command:\\n\", train_cmd)\n",
        "\n",
        "proc = subprocess.Popen(train_cmd, shell=True, text=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
        "\n",
        "# GPU monitor thread\n",
        "def _gpu_monitor():\n",
        "    while proc.poll() is None:\n",
        "        try:\n",
        "            stats = subprocess.check_output(\n",
        "                \"nvidia-smi --query-gpu=utilization.gpu,memory.used,memory.total --format=csv,nounits,noheader\",\n",
        "                shell=True,\n",
        "            ).decode(\"utf-8\").strip()\n",
        "            print(f\"[GPU] {stats}\")\n",
        "        except:\n",
        "            pass\n",
        "        time.sleep(5)\n",
        "\n",
        "monitor = threading.Thread(target=_gpu_monitor, daemon=True)\n",
        "monitor.start()\n",
        "\n",
        "for line in proc.stdout:\n",
        "    print(line, end=\"\")\n",
        "\n",
        "proc.wait()\n",
        "print(\"\\nâœ… Training complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“ˆ Section 5: Learning Curves Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ðŸ“ˆ Display training metrics and learning curves\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "run_base = Path(CKPT_ROOT) / \"runs\" / RUN_TAG\n",
        "all_runs = sorted(run_base.glob(\"*/\"))\n",
        "if not all_runs:\n",
        "    raise FileNotFoundError(f\"No run folders found under {run_base}\")\n",
        "latest_run = all_runs[-1]\n",
        "\n",
        "history_path = latest_run / \"history.json\"\n",
        "if not history_path.exists():\n",
        "    raise FileNotFoundError(f\"history.json not found in {latest_run}\")\n",
        "\n",
        "history = json.loads(history_path.read_text()).get(\"history\", [])\n",
        "\n",
        "print(f\"ðŸ“Š Epoch metrics for run: {latest_run.name}\")\n",
        "for record in history:\n",
        "    train_metrics = record.get(\"train\", {})\n",
        "    val_metrics = record.get(\"val\", {}) or {}\n",
        "    train_loss = train_metrics.get(\"loss\")\n",
        "    train_acc = train_metrics.get(\"accuracy\")\n",
        "    val_loss = val_metrics.get(\"loss\")\n",
        "    val_acc = val_metrics.get(\"accuracy\")\n",
        "    val_str = f\"val_loss={val_loss:.4f} acc={val_acc:.4f}\" if val_loss else \"val_loss=â€” val_acc=â€”\"\n",
        "    print(f\"  Epoch {record['epoch']:>2}: train_loss={train_loss:.4f} acc={train_acc:.4f}  {val_str}\")\n",
        "\n",
        "# Plot learning curves\n",
        "epochs = [r[\"epoch\"] for r in history]\n",
        "train_loss = [r[\"train\"][\"loss\"] for r in history]\n",
        "train_acc = [r[\"train\"][\"accuracy\"] for r in history]\n",
        "val_loss = [(r.get(\"val\") or {}).get(\"loss\") for r in history]\n",
        "val_acc = [(r.get(\"val\") or {}).get(\"accuracy\") for r in history]\n",
        "\n",
        "val_epochs = [e for e, v in zip(epochs, val_loss) if v is not None]\n",
        "val_loss_f = [v for v in val_loss if v is not None]\n",
        "val_acc_f = [v for v in val_acc if v is not None]\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4), dpi=140)\n",
        "\n",
        "axes[0].plot(epochs, train_acc, label=\"Training Accuracy\")\n",
        "if val_acc_f:\n",
        "    axes[0].plot(val_epochs, val_acc_f, label=\"Validation Accuracy\")\n",
        "axes[0].set_title(\"Accuracy Curves\")\n",
        "axes[0].set_xlabel(\"Epochs\")\n",
        "axes[0].set_ylabel(\"Accuracy\")\n",
        "axes[0].legend()\n",
        "\n",
        "axes[1].plot(epochs, train_loss, label=\"Training Loss\")\n",
        "if val_loss_f:\n",
        "    axes[1].plot(val_epochs, val_loss_f, label=\"Validation Loss\")\n",
        "axes[1].set_title(\"Loss Curves\")\n",
        "axes[1].set_xlabel(\"Epochs\")\n",
        "axes[1].set_ylabel(\"Loss\")\n",
        "axes[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "out_png = latest_run / \"learning_curves.png\"\n",
        "fig.savefig(out_png, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "print(\"âœ… Saved:\", out_png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âœ… Training Complete!\n",
        "\n",
        "**Outputs saved to Drive:**\n",
        "- `CKPT_ROOT/runs/{RUN_TAG}/{timestamp}/best.pt` â€” Best checkpoint\n",
        "- `CKPT_ROOT/runs/{RUN_TAG}/{timestamp}/history.json` â€” Training history\n",
        "- `CKPT_ROOT/runs/{RUN_TAG}/{timestamp}/learning_curves.png` â€” Curves figure\n",
        "\n",
        "**Next steps:**\n",
        "- Run **03_evaluation.ipynb** to generate predictions and metrics\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
