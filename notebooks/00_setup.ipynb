{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üöÄ 00 ‚Äî Colab Setup\n",
        "\n",
        "**Purpose:** Core environment setup for all CNNs-distracted-driving notebooks.\n",
        "\n",
        "Run this notebook **first** in any new Colab session, OR use the inline setup cells in other notebooks.\n",
        "\n",
        "**What this does:**\n",
        "1. Check GPU availability\n",
        "2. Mount Google Drive\n",
        "3. Clone/update the repo\n",
        "4. Install the package\n",
        "5. Configure environment variables\n",
        "6. Verify imports work\n",
        "\n",
        "**Optional:** Copy full dataset images to `/content` for faster I/O during training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîß 0) Quick GPU check\n",
        "!nvidia-smi || echo \"No GPU detected ‚Äî CPU runtime is okay for setup steps.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîß 1) Fixed config for your repo + Drive layout\n",
        "import os\n",
        "\n",
        "REPO_URL       = \"https://github.com/ClaudiaCPach/CNNs-distracted-driving\"\n",
        "REPO_DIRNAME   = \"CNNs-distracted-driving\"\n",
        "BRANCH         = \"main\"\n",
        "PROJECT_ROOT   = f\"/content/{REPO_DIRNAME}\"\n",
        "\n",
        "# Your persistent Google Drive base folder:\n",
        "DRIVE_PATH       = \"/content/drive/MyDrive/TFM\"\n",
        "DRIVE_DATA_ROOT  = f\"{DRIVE_PATH}/data\"\n",
        "\n",
        "# Fast ephemeral workspace inside the VM\n",
        "FAST_DATA        = \"/content/data\"\n",
        "\n",
        "# Start with Drive as the canonical dataset root\n",
        "DATASET_ROOT     = DRIVE_DATA_ROOT\n",
        "OUT_ROOT         = f\"{DRIVE_PATH}/outputs\"\n",
        "CKPT_ROOT        = f\"{DRIVE_PATH}/checkpoints\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîå 2) Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "print(\"‚úÖ Drive mounted.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üìÅ 3) Clone or update the repo\n",
        "import os, subprocess\n",
        "\n",
        "def sh(cmd):\n",
        "    print(f\"\\n$ {cmd}\")\n",
        "    rc = subprocess.call(cmd, shell=True, executable=\"/bin/bash\")\n",
        "    if rc != 0:\n",
        "        raise RuntimeError(f\"Command failed with exit code {rc}: {cmd}\")\n",
        "\n",
        "if os.path.isdir(PROJECT_ROOT):\n",
        "    print(f\"üìÅ Repo already present at {PROJECT_ROOT}. Pulling latest on branch {BRANCH}...\")\n",
        "    sh(f\"cd {PROJECT_ROOT} && git fetch origin {BRANCH} && git checkout {BRANCH} && git pull --rebase origin {BRANCH}\")\n",
        "else:\n",
        "    print(f\"‚¨áÔ∏è Cloning {REPO_URL} ‚Üí {PROJECT_ROOT}\")\n",
        "    sh(f\"git clone --branch {BRANCH} {REPO_URL} {PROJECT_ROOT}\")\n",
        "\n",
        "print(\"PROJECT_ROOT =\", PROJECT_ROOT)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üì¶ 4) Install the repo (editable) + requirements\n",
        "import os, subprocess\n",
        "\n",
        "def sh(cmd):\n",
        "    print(f\"\\n$ {cmd}\")\n",
        "    rc = subprocess.call(cmd, shell=True, executable=\"/bin/bash\")\n",
        "    if rc != 0:\n",
        "        raise RuntimeError(f\"Command failed with exit code {rc}: {cmd}\")\n",
        "\n",
        "print(\"üîÑ Upgrading pip/setuptools/wheel...\")\n",
        "sh(\"python -m pip install --upgrade pip setuptools wheel\")\n",
        "\n",
        "has_pyproject = os.path.exists(os.path.join(PROJECT_ROOT, \"pyproject.toml\"))\n",
        "if has_pyproject:\n",
        "    print(\"üì¶ Editable install from pyproject.toml ...\")\n",
        "    sh(f\"cd {PROJECT_ROOT} && pip install -e .\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No pyproject.toml found. Skipping editable install.\")\n",
        "\n",
        "req_path = os.path.join(PROJECT_ROOT, \"requirements.txt\")\n",
        "if os.path.exists(req_path):\n",
        "    print(\"üìù Installing requirements.txt...\")\n",
        "    sh(f\"pip install -r {req_path}\")\n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è No requirements.txt found ‚Äî continuing.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üå≥ 5) Configure environment for ddriver.config\n",
        "import os\n",
        "\n",
        "os.environ[\"DRIVE_PATH\"]   = DRIVE_PATH\n",
        "os.environ[\"DATASET_ROOT\"] = DATASET_ROOT\n",
        "os.environ[\"OUT_ROOT\"]     = OUT_ROOT\n",
        "os.environ[\"CKPT_ROOT\"]    = CKPT_ROOT\n",
        "os.environ[\"FAST_DATA\"]    = FAST_DATA\n",
        "\n",
        "# Write .env file for code that uses load_dotenv()\n",
        "env_text = f\"\"\"DRIVE_PATH={DRIVE_PATH}\n",
        "DATASET_ROOT={DATASET_ROOT}\n",
        "OUT_ROOT={OUT_ROOT}\n",
        "CKPT_ROOT={CKPT_ROOT}\n",
        "FAST_DATA={FAST_DATA}\n",
        "\"\"\"\n",
        "with open(os.path.join(PROJECT_ROOT, \".env\"), \"w\") as f:\n",
        "    f.write(env_text)\n",
        "\n",
        "print(\"‚úÖ Environment variables set for ddriver.config\")\n",
        "print(\"\\nSummary:\")\n",
        "for k in [\"DRIVE_PATH\",\"DATASET_ROOT\",\"OUT_ROOT\",\"CKPT_ROOT\",\"FAST_DATA\"]:\n",
        "    print(f\"{k} = {os.environ[k]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ‚úÖ 6) Import smoke test\n",
        "import sys, os\n",
        "sys.path.append(PROJECT_ROOT)\n",
        "sys.path.append(os.path.join(PROJECT_ROOT, \"src\"))\n",
        "\n",
        "try:\n",
        "    import ddriver\n",
        "    print(\"ddriver imported OK from:\", ddriver.__file__)\n",
        "    try:\n",
        "        from ddriver import config\n",
        "        print(\"Loaded ddriver.config successfully.\")\n",
        "        print(\"config.DATASET_ROOT =\", config.DATASET_ROOT)\n",
        "        print(\"config.OUT_ROOT     =\", config.OUT_ROOT)\n",
        "        print(\"config.CKPT_ROOT    =\", config.CKPT_ROOT)\n",
        "        print(\"config.FAST_DATA    =\", config.FAST_DATA)\n",
        "    except Exception as e:\n",
        "        print(\"Note: ddriver.config not imported:\", e)\n",
        "except Exception as e:\n",
        "    print(\"‚ö†Ô∏è Import failed ‚Äî check package name/setup.\")\n",
        "    print(e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚ö° Optional: Copy Full Dataset to /content for Faster I/O\n",
        "\n",
        "Run this cell to copy the original images to `/content/data` for faster training.\n",
        "Skip if you're using hybrid crops instead.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ‚ö° Copy + compress full dataset to /content/data (optional, faster I/O)\n",
        "# Re-encodes JPEGs once (quality 80, short side 320px)\n",
        "\n",
        "import importlib\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "from ddriver.data.fastcopy import CompressionSpec, copy_splits_with_compression\n",
        "\n",
        "SRC_ROOT = Path(DRIVE_DATA_ROOT) / \"auc.distracted.driver.dataset_v2\"\n",
        "DST_ROOT = Path(FAST_DATA) / \"auc.distracted.driver.dataset_v2\"\n",
        "\n",
        "split_csvs = {\n",
        "    \"train\": Path(OUT_ROOT) / \"splits\" / \"train.csv\",\n",
        "    \"val\": Path(OUT_ROOT) / \"splits\" / \"val.csv\",\n",
        "    \"test\": Path(OUT_ROOT) / \"splits\" / \"test.csv\",\n",
        "    \"train_small\": Path(OUT_ROOT) / \"splits\" / \"train_small.csv\",\n",
        "}\n",
        "\n",
        "compression_spec = CompressionSpec(\n",
        "    target_short_side=320,\n",
        "    jpeg_quality=80,\n",
        ")\n",
        "\n",
        "summary = copy_splits_with_compression(\n",
        "    split_csvs=split_csvs,\n",
        "    src_root=SRC_ROOT,\n",
        "    dst_root=DST_ROOT,\n",
        "    compression=compression_spec,\n",
        "    skip_existing=True,\n",
        ")\n",
        "\n",
        "print(f\"\\nüìâ FAST_DATA copy stats: processed {summary['processed']} of {summary['total']} files \"\n",
        "      f\"(skipped {summary['skipped']} already present).\")\n",
        "print(f\"Compressed dataset root: {summary['dst_root']}\")\n",
        "\n",
        "# Update DATASET_ROOT to point to local copy\n",
        "DATASET_ROOT = FAST_DATA\n",
        "os.environ[\"DATASET_ROOT\"] = str(DATASET_ROOT)\n",
        "try:\n",
        "    from ddriver import config as _ddriver_config\n",
        "    importlib.reload(_ddriver_config)\n",
        "    print(\"\\n‚ö° Copy complete. DATASET_ROOT now points to the local FAST_DATA copy:\")\n",
        "    print(\"   ddriver.config.DATASET_ROOT =\", _ddriver_config.DATASET_ROOT)\n",
        "except Exception as exc:\n",
        "    print(\"\\n‚ö° Copy complete. DATASET_ROOT env updated:\", exc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚úÖ Setup Complete!\n",
        "\n",
        "You can now:\n",
        "- Run **01_data_preparation.ipynb** to generate manifests or extract hybrid crops\n",
        "- Run **02_training.ipynb** to train models\n",
        "- Run **03_evaluation.ipynb** to generate predictions and metrics\n",
        "- Run **04_modality_analysis.ipynb** for per-class comparison\n",
        "- Run **05_gradcam.ipynb** for Grad-CAM visualizations\n",
        "\n",
        "Each notebook has its own inline setup cells, so you can also run them independently.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
