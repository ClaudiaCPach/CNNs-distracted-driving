{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7296b001",
   "metadata": {},
   "source": [
    "\n",
    "# ðŸš€ Colab Setup â€” **CNNs-distracted-driving** (hardcoded + config-aware)\n",
    "\n",
    "This version is **simplified and hardcoded** for your repo and URL, and it **respects your `src/ddriver/config.py`**.\n",
    "- Repo name fixed to **`CNNs-distracted-driving`**\n",
    "- Repo URL fixed to **`https://github.com/ClaudiaCPach/CNNs-distracted-driving`**\n",
    "- Uses your `config.py` convention: when running in Colab, we **set env vars** (`DRIVE_PATH`, `DATASET_ROOT`, `OUT_ROOT`, `CKPT_ROOT`, `FAST_DATA`) so your code reads correct paths via `ddriver.config`.\n",
    "- Optional `FAST_DATA` at `/content/data` for faster I/O (if you later copy data there).\n",
    "\n",
    "> Run cells **top â†’ bottom** the first time. Re-run **Update repo** to pull new commits after you push.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0fd729",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ðŸ”§ 0) (Optional) quick GPU check\n",
    "!nvidia-smi || echo \"No GPU detected â€” CPU runtime is okay for setup steps.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b7bf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ðŸ”§ 1) Fixed config for your repo + Drive layout\n",
    "REPO_URL       = \"https://github.com/ClaudiaCPach/CNNs-distracted-driving\"\n",
    "REPO_DIRNAME   = \"CNNs-distracted-driving\"   # hardcoded\n",
    "BRANCH         = \"main\"\n",
    "PROJECT_ROOT   = f\"/content/{REPO_DIRNAME}\"  # where the repo will live in Colab\n",
    "\n",
    "# Your persistent Google Drive base folder (matches your project docs):\n",
    "DRIVE_PATH     = \"/content/drive/MyDrive/TFM\"\n",
    "\n",
    "# Your dataset lives under TFM/data/auc.distracted.driver.dataset_v2 (as per your structure)\n",
    "DATASET_ROOT   = f\"{DRIVE_PATH}/data/auc.distracted.driver.dataset_v2\"\n",
    "OUT_ROOT       = f\"{DRIVE_PATH}/outputs\"\n",
    "CKPT_ROOT      = f\"{DRIVE_PATH}/checkpoints\"\n",
    "\n",
    "# Optional: a fast, ephemeral workspace inside the VM\n",
    "FAST_DATA      = \"/content/data\"   # leave as-is; you can rsync into this later for speed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbdeca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ðŸ”Œ 2) Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=False)\n",
    "print(\"âœ… Drive mounted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df094a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ðŸ“ 3) Clone or update the repo (no name inference â€” all hardcoded)\n",
    "import os, subprocess\n",
    "\n",
    "def sh(cmd):\n",
    "    print(f\"\\n$ {cmd}\")\n",
    "    rc = subprocess.call(cmd, shell=True, executable=\"/bin/bash\")\n",
    "    if rc != 0:\n",
    "        raise RuntimeError(f\"Command failed with exit code {rc}: {cmd}\")\n",
    "\n",
    "if os.path.isdir(PROJECT_ROOT):\n",
    "    print(f\"ðŸ“ Repo already present at {PROJECT_ROOT}. Pulling latest on branch {BRANCH}...\")\n",
    "    sh(f\"cd {PROJECT_ROOT} && git fetch origin {BRANCH} && git checkout {BRANCH} && git pull --rebase origin {BRANCH}\")\n",
    "else:\n",
    "    print(f\"â¬‡ï¸ Cloning {REPO_URL} â†’ {PROJECT_ROOT}\")\n",
    "    sh(f\"git clone --branch {BRANCH} {REPO_URL} {PROJECT_ROOT}\")\n",
    "\n",
    "print(\"PROJECT_ROOT =\", PROJECT_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323c4e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ðŸ“¦ 4) Install the repo (editable) + requirements (uses pyproject.toml if present)\n",
    "import os, subprocess\n",
    "\n",
    "def sh(cmd):\n",
    "    print(f\"\\n$ {cmd}\")\n",
    "    rc = subprocess.call(cmd, shell=True, executable=\"/bin/bash\")\n",
    "    if rc != 0:\n",
    "        raise RuntimeError(f\"Command failed with exit code {rc}: {cmd}\")\n",
    "\n",
    "print(\"ðŸ”„ Upgrading pip/setuptools/wheel...\")\n",
    "sh(\"python -m pip install --upgrade pip setuptools wheel\")\n",
    "\n",
    "has_pyproject = os.path.exists(os.path.join(PROJECT_ROOT, \"pyproject.toml\"))\n",
    "if has_pyproject:\n",
    "    print(\"ðŸ“¦ Editable install from pyproject.toml ...\")\n",
    "    sh(f\"cd {PROJECT_ROOT} && pip install -e .\")\n",
    "else:\n",
    "    print(\"âš ï¸ No pyproject.toml found. Skipping editable install.\")\n",
    "\n",
    "req_path = os.path.join(PROJECT_ROOT, \"requirements.txt\")\n",
    "if os.path.exists(req_path):\n",
    "    print(\"ðŸ“ Installing requirements.txt...\")\n",
    "    sh(f\"pip install -r {req_path}\")\n",
    "else:\n",
    "    print(\"â„¹ï¸ No requirements.txt found â€” continuing.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accfc73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ðŸŒ³ 5) Configure environment for your ddriver.config (Colab branch)\n",
    "# Your config.py reads env vars and falls back to sensible defaults when in Colab.\n",
    "import os\n",
    "\n",
    "os.environ[\"DRIVE_PATH\"]   = DRIVE_PATH\n",
    "os.environ[\"DATASET_ROOT\"] = DATASET_ROOT\n",
    "os.environ[\"OUT_ROOT\"]     = OUT_ROOT\n",
    "os.environ[\"CKPT_ROOT\"]    = CKPT_ROOT\n",
    "os.environ[\"FAST_DATA\"]    = FAST_DATA\n",
    "\n",
    "# Also write a .env (harmless in Colab; helpful if code calls load_dotenv())\n",
    "env_text = f\"\"\"DRIVE_PATH={DRIVE_PATH}\n",
    "DATASET_ROOT={DATASET_ROOT}\n",
    "OUT_ROOT={OUT_ROOT}\n",
    "CKPT_ROOT={CKPT_ROOT}\n",
    "FAST_DATA={FAST_DATA}\n",
    "\"\"\"\n",
    "with open(os.path.join(PROJECT_ROOT, \".env\"), \"w\") as f:\n",
    "    f.write(env_text)\n",
    "\n",
    "print(\"âœ… Environment variables set for ddriver.config\")\n",
    "print(\"\\nSummary:\")\n",
    "for k in [\"DRIVE_PATH\",\"DATASET_ROOT\",\"OUT_ROOT\",\"CKPT_ROOT\",\"FAST_DATA\"]:\n",
    "    print(f\"{k} = {os.environ[k]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27df24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ðŸ”— 6) (Optional) Symlink dataset into repo for familiar paths (scripts that assume PROJECT_ROOT/data/...)\n",
    "# Not required when using ddriver.config, but convenient for ad-hoc browsing.\n",
    "import os\n",
    "\n",
    "LOCAL_DATA_DIR = f\"{PROJECT_ROOT}/data\"\n",
    "os.makedirs(LOCAL_DATA_DIR, exist_ok=True)\n",
    "\n",
    "dataset_link = os.path.join(LOCAL_DATA_DIR, \"auc.distracted.driver.dataset_v2\")\n",
    "if not os.path.islink(dataset_link) and not os.path.exists(dataset_link):\n",
    "    try:\n",
    "        os.symlink(DATASET_ROOT, dataset_link)\n",
    "        print(f\"ðŸ”— Symlinked {dataset_link} â†’ {DATASET_ROOT}\")\n",
    "    except OSError as e:\n",
    "        print(f\"â„¹ï¸ Symlink skipped or failed: {e}\")\n",
    "else:\n",
    "    print(\"â„¹ï¸ Dataset link already exists.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cf8bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ðŸ” 7) Quick sanity checks\n",
    "import os, glob\n",
    "\n",
    "def preview_dir(path, n=10):\n",
    "    print(f\"Listing up to {n} items under: {path}\")\n",
    "    try:\n",
    "        for i, name in enumerate(sorted(os.listdir(path))):\n",
    "            print(\"  -\", name)\n",
    "            if i+1 >= n:\n",
    "                break\n",
    "    except Exception as e:\n",
    "        print(\"Could not list:\", e)\n",
    "\n",
    "print(\"\\nTop-level DATASET_ROOT:\")\n",
    "preview_dir(os.environ[\"DATASET_ROOT\"], n=10)\n",
    "\n",
    "cam1_train = os.path.join(os.environ[\"DATASET_ROOT\"], \"v2_cam1_cam2_ split_by_driver\", \"Camera 1\", \"train\")\n",
    "print(\"\\nCamera 1/train class folders (first 10):\")\n",
    "preview_dir(cam1_train, n=10)\n",
    "\n",
    "for cls in [\"c0\",\"c1\",\"c2\"]:\n",
    "    cls_dir = os.path.join(cam1_train, cls)\n",
    "    if os.path.isdir(cls_dir):\n",
    "        num_imgs = len([p for p in glob.glob(os.path.join(cls_dir, \"*\")) if os.path.isfile(p)])\n",
    "        print(f\"  â€¢ {cls}: {num_imgs} files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8155fa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# âœ… 8) Import smoke test (uses your package + config.py)\n",
    "import sys, os\n",
    "sys.path.append(PROJECT_ROOT)\n",
    "sys.path.append(os.path.join(PROJECT_ROOT, \"src\"))  # <â€” lets Python find src/ddriver\n",
    "\n",
    "try:\n",
    "    import ddriver\n",
    "    print(\"ddriver imported OK from:\", ddriver.__file__)\n",
    "    # Confirm config picks up Colab env:\n",
    "    try:\n",
    "        from ddriver import config\n",
    "        print(\"Loaded ddriver.config successfully.\")\n",
    "        # Echo the resolved paths from config (they are pathlib.Path objects)\n",
    "        print(\"config.DATASET_ROOT =\", config.DATASET_ROOT)\n",
    "        print(\"config.OUT_ROOT     =\", config.OUT_ROOT)\n",
    "        print(\"config.CKPT_ROOT    =\", config.CKPT_ROOT)\n",
    "        print(\"config.FAST_DATA    =\", config.FAST_DATA)\n",
    "    except Exception as e:\n",
    "        print(\"Note: ddriver.config not imported:\", e)\n",
    "except Exception as e:\n",
    "    print(\"âš ï¸ Import failed â€” check package name/setup.\")\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1814de",
   "metadata": {},
   "source": [
    "\n",
    "### âœ… Youâ€™re set!\n",
    "- Your repo + URL are **hardcoded**.\n",
    "- `ddriver.config` will see the Colab env vars and resolve paths there.\n",
    "- Re-run **Clone/Update** after pushing new commits.\n",
    "- Optional: copy some data into `/content/data` to use `FAST_DATA` for speed, then call `ddriver.config.dataset_dir(prefer_fast=True)` in your scripts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d0cd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Colab cell: append metrics + params to Google Sheet ----\n",
    "!pip -q install gspread\n",
    "\n",
    "import json, os\n",
    "from pathlib import Path\n",
    "import gspread\n",
    "\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "gc = gspread.authorize(gspread.auth.default())\n",
    "\n",
    "SHEET_NAME = \"TFM Logs\"   # change if needed\n",
    "WORKSHEET  = \"Sheet1\"     # or whatever tab name\n",
    "\n",
    "# Point to your latest run folder (paste it from the console printout)\n",
    "run_dir = Path(\"/Users/claudiapacheco/TFM/outputs/metrics/val_run1/2025-11-09_12-34-56\")\n",
    "\n",
    "metrics = json.loads((run_dir / \"metrics.json\").read_text())\n",
    "inputs  = json.loads((run_dir / \"inputs.json\").read_text())\n",
    "params_path = run_dir / \"params.json\"\n",
    "params = json.loads(params_path.read_text()) if params_path.exists() else {}\n",
    "\n",
    "ws = gc.open(SHEET_NAME).worksheet(WORKSHEET)\n",
    "\n",
    "row = [\n",
    "  str(run_dir),                        # Run folder\n",
    "  inputs.get(\"predictions\",\"\"),        # Predictions file\n",
    "  inputs.get(\"split_source\",\"\"),       # Split source\n",
    "  metrics[\"num_examples\"],             # Support\n",
    "  round(metrics[\"overall\"][\"accuracy\"], 4),\n",
    "  round(metrics[\"overall\"][\"macro_avg\"][\"f1\"], 4),\n",
    "  json.dumps(params, sort_keys=True)[:500],  # params preview (trim)\n",
    "]\n",
    "ws.append_row(row, value_input_option=\"USER_ENTERED\")\n",
    "print(\"Appended to Google Sheet âœ…\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
