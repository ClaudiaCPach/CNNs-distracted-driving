{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üìã 01 ‚Äî Data Preparation\n",
        "\n",
        "**Purpose:** Generate manifests, extract hybrid ROI crops, and audit quality.\n",
        "\n",
        "**Sections:**\n",
        "1. Inline Setup (run if starting fresh)\n",
        "2. Manifest & Split Generation\n",
        "3. Hybrid ROI Extraction (face, face_hands)\n",
        "4. Copy Hybrid Crops (Drive ‚Üî /content)\n",
        "5. Quality Audit & Thesis Figures\n",
        "\n",
        "**Prerequisites:** Original images exist on Google Drive at `DRIVE_DATA_ROOT/auc.distracted.driver.dataset_v2/`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Section 1: Inline Setup\n",
        "\n",
        "Run these cells if starting this notebook fresh (not coming from 00_setup.ipynb).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- INLINE SETUP (run if starting fresh) ---\n",
        "import os, subprocess, sys\n",
        "\n",
        "# Config\n",
        "REPO_URL       = \"https://github.com/ClaudiaCPach/CNNs-distracted-driving\"\n",
        "REPO_DIRNAME   = \"CNNs-distracted-driving\"\n",
        "BRANCH         = \"main\"\n",
        "PROJECT_ROOT   = f\"/content/{REPO_DIRNAME}\"\n",
        "DRIVE_PATH     = \"/content/drive/MyDrive/TFM\"\n",
        "DRIVE_DATA_ROOT = f\"{DRIVE_PATH}/data\"\n",
        "FAST_DATA      = \"/content/data\"\n",
        "DATASET_ROOT   = DRIVE_DATA_ROOT\n",
        "OUT_ROOT       = f\"{DRIVE_PATH}/outputs\"\n",
        "CKPT_ROOT      = f\"{DRIVE_PATH}/checkpoints\"\n",
        "\n",
        "# Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "# Clone/update repo\n",
        "def sh(cmd):\n",
        "    print(f\"$ {cmd}\")\n",
        "    rc = subprocess.call(cmd, shell=True, executable=\"/bin/bash\")\n",
        "    if rc != 0:\n",
        "        raise RuntimeError(f\"Command failed: {cmd}\")\n",
        "\n",
        "if os.path.isdir(PROJECT_ROOT):\n",
        "    sh(f\"cd {PROJECT_ROOT} && git pull --rebase origin {BRANCH}\")\n",
        "else:\n",
        "    sh(f\"git clone --branch {BRANCH} {REPO_URL} {PROJECT_ROOT}\")\n",
        "\n",
        "# Install\n",
        "sh(f\"pip install -q -e {PROJECT_ROOT}\")\n",
        "\n",
        "# Set env vars\n",
        "os.environ[\"DRIVE_PATH\"] = DRIVE_PATH\n",
        "os.environ[\"DATASET_ROOT\"] = DATASET_ROOT\n",
        "os.environ[\"OUT_ROOT\"] = OUT_ROOT\n",
        "os.environ[\"CKPT_ROOT\"] = CKPT_ROOT\n",
        "os.environ[\"FAST_DATA\"] = FAST_DATA\n",
        "\n",
        "sys.path.insert(0, PROJECT_ROOT)\n",
        "sys.path.insert(0, os.path.join(PROJECT_ROOT, \"src\"))\n",
        "\n",
        "print(\"‚úÖ Inline setup complete\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìã Section 2: Manifest & Split Generation\n",
        "\n",
        "Generate manifest.csv and train/val/test split CSVs. **Run once** ‚Äî results persist on Drive.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run the manifest generator\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "sys.path.insert(0, PROJECT_ROOT)\n",
        "\n",
        "manifest_cmd = f\"cd {PROJECT_ROOT} && python -m ddriver.data.manifest --write-split-lists\"\n",
        "\n",
        "print(\"üî® Generating manifest and split CSVs...\")\n",
        "print(f\"Running: {manifest_cmd}\\n\")\n",
        "\n",
        "result = subprocess.run(manifest_cmd, shell=True, capture_output=True, text=True)\n",
        "print(result.stdout)\n",
        "if result.stderr:\n",
        "    print(\"Warnings/Errors:\", result.stderr)\n",
        "\n",
        "if result.returncode == 0:\n",
        "    print(\"\\n‚úÖ Manifest and split CSVs generated successfully!\")\n",
        "    print(f\"   Manifest: {os.environ['OUT_ROOT']}/manifests/manifest.csv\")\n",
        "    print(f\"   Train: {os.environ['OUT_ROOT']}/splits/train.csv\")\n",
        "    print(f\"   Val: {os.environ['OUT_ROOT']}/splits/val.csv\")\n",
        "    print(f\"   Test: {os.environ['OUT_ROOT']}/splits/test.csv\")\n",
        "else:\n",
        "    print(f\"\\n‚ùå Error (exit code {result.returncode})\")\n",
        "    raise RuntimeError(\"Manifest generation failed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify CSVs were created\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "manifest_path = Path(os.environ['OUT_ROOT']) / \"manifests\" / \"manifest.csv\"\n",
        "train_path = Path(os.environ['OUT_ROOT']) / \"splits\" / \"train.csv\"\n",
        "val_path = Path(os.environ['OUT_ROOT']) / \"splits\" / \"val.csv\"\n",
        "test_path = Path(os.environ['OUT_ROOT']) / \"splits\" / \"test.csv\"\n",
        "\n",
        "print(\"üìä Checking CSV files...\\n\")\n",
        "for name, path in [(\"Manifest\", manifest_path), (\"Train\", train_path), (\"Val\", val_path), (\"Test\", test_path)]:\n",
        "    if path.exists():\n",
        "        df = pd.read_csv(path)\n",
        "        print(f\"‚úÖ {name}: {len(df)} rows, columns: {list(df.columns)}\")\n",
        "    else:\n",
        "        print(f\"‚ùå {name}: File not found at {path}\")\n",
        "\n",
        "if manifest_path.exists():\n",
        "    print(\"\\nüìÑ Sample from manifest (first 3 rows):\")\n",
        "    sample = pd.read_csv(manifest_path).head(3)\n",
        "    print(sample[['path', 'class_id', 'driver_id', 'camera', 'split']].to_string())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a tiny balanced subset for quick testing (20 images per class)\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from ddriver import config\n",
        "\n",
        "train_csv = Path(config.OUT_ROOT) / \"splits\" / \"train.csv\"\n",
        "train_small_csv = Path(config.OUT_ROOT) / \"splits\" / \"train_small.csv\"\n",
        "\n",
        "print(f\"Reading {train_csv}...\")\n",
        "df = pd.read_csv(train_csv)\n",
        "\n",
        "small = df.groupby(\"class_id\").head(20)\n",
        "\n",
        "print(f\"Original train.csv: {len(df)} images\")\n",
        "print(f\"Small subset: {len(small)} images ({len(small) // 10} per class)\")\n",
        "print(f\"\\nClass distribution:\")\n",
        "print(small[\"class_id\"].value_counts().sort_index())\n",
        "\n",
        "small.to_csv(train_small_csv, index=False)\n",
        "print(f\"\\n‚úÖ Saved to {train_small_csv}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîÄ Section 3: Hybrid ROI Extraction (InsightFace + MediaPipe Hands)\n",
        "\n",
        "Extract face and face+hands crops using the hybrid pipeline. **Run once per variant** ‚Äî results persist on Drive.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install extraction dependencies\n",
        "!pip -q install insightface onnxruntime mediapipe\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîÄ Hybrid ROI Extraction ‚Äî FACE variant\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "VARIANT = \"face\"  # <<<< CHANGE TO \"face_hands\" for second run\n",
        "\n",
        "# Output location (Drive for persistence)\n",
        "HYBRID_OUTPUT_ROOT = Path(OUT_ROOT) / \"hybrid\"\n",
        "\n",
        "manifest_csv = Path(OUT_ROOT) / \"manifests\" / \"manifest.csv\"\n",
        "splits_root = Path(OUT_ROOT) / \"splits\"\n",
        "\n",
        "# Auto-detect local vs Drive images\n",
        "LOCAL_DATASET_ROOT = Path(\"/content/data/auc.distracted.driver.dataset_v2\")\n",
        "DRIVE_DATASET_ROOT = Path(DATASET_ROOT)\n",
        "\n",
        "if LOCAL_DATASET_ROOT.exists() and any(LOCAL_DATASET_ROOT.iterdir()):\n",
        "    EFFECTIVE_DATASET_ROOT = LOCAL_DATASET_ROOT\n",
        "    print(f\"üöÄ Using local images from {LOCAL_DATASET_ROOT}\")\n",
        "else:\n",
        "    EFFECTIVE_DATASET_ROOT = DRIVE_DATASET_ROOT\n",
        "    print(f\"üìÅ Using images from Drive: {DRIVE_DATASET_ROOT}\")\n",
        "\n",
        "# Test mode options\n",
        "TEST_MODE = False  # Set True for quick test\n",
        "LIMIT = None  # Set to e.g. 50 for debugging\n",
        "\n",
        "sample_flag = \"\"\n",
        "limit_flag = f\"--limit {LIMIT}\" if LIMIT else \"\"\n",
        "\n",
        "extract_cmd = f\"\"\"\n",
        "cd {PROJECT_ROOT}\n",
        "python -m src.ddriver.data.hybrid_extract \\\n",
        "  --manifest {manifest_csv} \\\n",
        "  --splits-root {splits_root} \\\n",
        "  --dataset-root {EFFECTIVE_DATASET_ROOT} \\\n",
        "  --output-root {HYBRID_OUTPUT_ROOT} \\\n",
        "  --variant {VARIANT} \\\n",
        "  --min-face-conf 0.4 \\\n",
        "  --min-detection-area-frac 0.005 \\\n",
        "  --min-area-frac 0.01 \\\n",
        "  --min-aspect 0.08 \\\n",
        "  --pad-frac 0.35 \\\n",
        "  --max-area-frac 0.40 \\\n",
        "  {limit_flag} \\\n",
        "  --overwrite\n",
        "\"\"\"\n",
        "\n",
        "print(f\"Running Hybrid extraction for variant: {VARIANT}\")\n",
        "print(extract_cmd)\n",
        "proc = subprocess.Popen(extract_cmd, shell=True, text=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
        "for line in proc.stdout:\n",
        "    print(line, end=\"\")\n",
        "proc.wait()\n",
        "if proc.returncode != 0:\n",
        "    raise RuntimeError(\"Hybrid extraction failed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîÅ Regenerate Hybrid CSVs (manifest + splits) for the extracted variant\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "# VARIANT should match what you just extracted\n",
        "VARIANT = VARIANT if 'VARIANT' in globals() else 'face'\n",
        "HYBRID_OUTPUT_ROOT = HYBRID_OUTPUT_ROOT if 'HYBRID_OUTPUT_ROOT' in globals() else Path(OUT_ROOT) / 'hybrid'\n",
        "\n",
        "manifest_csv = Path(OUT_ROOT) / 'manifests' / 'manifest.csv'\n",
        "splits_root = Path(OUT_ROOT) / 'splits'\n",
        "crop_root = Path(HYBRID_OUTPUT_ROOT) / VARIANT\n",
        "meta_csv = Path(HYBRID_OUTPUT_ROOT) / f'detection_metadata_{VARIANT}.csv'\n",
        "\n",
        "def _extract_class(path_str):\n",
        "    for part in Path(path_str).parts:\n",
        "        if len(part) == 2 and part.startswith('c') and part[1].isdigit():\n",
        "            return part\n",
        "    return None\n",
        "\n",
        "def _extract_camera(path_str):\n",
        "    for part in Path(path_str).parts:\n",
        "        if part.lower().startswith('camera'):\n",
        "            return part\n",
        "    return None\n",
        "\n",
        "def _extract_filename(path_str):\n",
        "    return Path(path_str).name\n",
        "\n",
        "def _coerce_class_id(value):\n",
        "    if pd.isna(value):\n",
        "        return None\n",
        "    value_str = str(value)\n",
        "    if len(value_str) == 2 and value_str.startswith('c') and value_str[1].isdigit():\n",
        "        return value_str\n",
        "    if value_str.isdigit():\n",
        "        return f'c{int(value_str)}'\n",
        "    return None\n",
        "\n",
        "def _normalize_camera(cam):\n",
        "    if cam is None or pd.isna(cam):\n",
        "        return None\n",
        "    cam_str = str(cam).lower().replace(' ', '')\n",
        "    if cam_str in ['camera1', 'cam1']:\n",
        "        return 'cam1'\n",
        "    if cam_str in ['camera2', 'cam2']:\n",
        "        return 'cam2'\n",
        "    return cam_str\n",
        "\n",
        "print(f'üìÇ Loading original manifest: {manifest_csv}')\n",
        "orig_df = pd.read_csv(manifest_csv)\n",
        "orig_df = orig_df.rename(columns={'path': 'original_path'})\n",
        "orig_df['_filename'] = orig_df['original_path'].astype(str).map(_extract_filename)\n",
        "orig_df['_class'] = orig_df['original_path'].astype(str).map(_extract_class)\n",
        "orig_df['_camera'] = orig_df['original_path'].astype(str).map(_extract_camera).map(_normalize_camera)\n",
        "\n",
        "print(f'üîç Scanning crops: {crop_root}')\n",
        "crop_paths = list(crop_root.rglob('*.jpg'))\n",
        "crop_df = pd.DataFrame({'crop_path': [str(p) for p in crop_paths]})\n",
        "crop_df['path'] = crop_df['crop_path'].map(lambda p: str(Path(p).relative_to(HYBRID_OUTPUT_ROOT)))\n",
        "crop_df['_filename'] = crop_df['crop_path'].map(_extract_filename)\n",
        "crop_df['_class'] = crop_df['crop_path'].map(_extract_class)\n",
        "crop_df['_camera'] = crop_df['crop_path'].map(_extract_camera).map(_normalize_camera)\n",
        "\n",
        "fallback_paths = set()\n",
        "if meta_csv.exists():\n",
        "    meta_df = pd.read_csv(meta_csv)\n",
        "    meta_df = meta_df[meta_df['cropped_path'].astype(str).str.len() > 0]\n",
        "    meta_df['path'] = meta_df['cropped_path'].astype(str)\n",
        "    meta_df['_class'] = meta_df['class_id'].map(_coerce_class_id)\n",
        "    meta_df['_camera'] = meta_df['camera'].map(_normalize_camera)\n",
        "    crop_df = crop_df.merge(\n",
        "        meta_df[['path', '_class', '_camera', 'fallback_to_full']],\n",
        "        on='path', how='left', suffixes=('', '_meta'),\n",
        "    )\n",
        "    crop_df['_class'] = crop_df['_class'].fillna(crop_df['_class_meta'])\n",
        "    crop_df['_camera'] = crop_df['_camera'].fillna(crop_df['_camera_meta'])\n",
        "    crop_df = crop_df.drop(columns=['_class_meta', '_camera_meta'], errors='ignore')\n",
        "    fallback_paths = set(meta_df.loc[meta_df['fallback_to_full'] == True, 'path'].dropna().astype(str))\n",
        "    print(f'üö´ Excluding {len(fallback_paths)} fallback crops from splits')\n",
        "\n",
        "crop_df_all = crop_df.copy()\n",
        "crop_df = crop_df[~crop_df['path'].isin(fallback_paths)]\n",
        "\n",
        "merged = crop_df_all.merge(orig_df, on=['_filename', '_class', '_camera'], how='left')\n",
        "manifest_out = merged.drop(columns=['crop_path', '_filename', '_class', '_camera'], errors='ignore')\n",
        "manifest_out_path = Path(HYBRID_OUTPUT_ROOT) / f'manifest_{VARIANT}.csv'\n",
        "manifest_out.to_csv(manifest_out_path, index=False)\n",
        "print(f'‚úÖ Wrote manifest: {manifest_out_path}')\n",
        "\n",
        "for split_name in ['train', 'val', 'test']:\n",
        "    split_path = splits_root / f'{split_name}.csv'\n",
        "    split_df = pd.read_csv(split_path)\n",
        "    split_df['path'] = split_df['path'].astype(str)\n",
        "    split_df['_filename'] = split_df['path'].map(_extract_filename)\n",
        "    split_df['_class'] = split_df['path'].map(_extract_class)\n",
        "    split_df['_camera'] = split_df['path'].map(_extract_camera).map(_normalize_camera)\n",
        "\n",
        "    split_merged = split_df.merge(crop_df, on=['_filename', '_class', '_camera'], how='inner')\n",
        "    split_merged['original_path'] = split_merged['path_x']\n",
        "    split_merged['path'] = split_merged['path_y']\n",
        "    cols_to_drop = ['path_x', 'path_y', '_filename', '_class', '_camera', 'crop_path', 'fallback_to_full']\n",
        "    split_merged = split_merged.drop(columns=[c for c in cols_to_drop if c in split_merged.columns])\n",
        "\n",
        "    out_split = Path(HYBRID_OUTPUT_ROOT) / f'{split_name}_{VARIANT}.csv'\n",
        "    split_merged.to_csv(out_split, index=False)\n",
        "    print(f'‚úÖ Wrote split: {out_split} ({len(split_merged)} rows)')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Section 3b: Generate Control Splits (5-Run Plan)\n",
        "\n",
        "Generate filtered split CSVs for the experimental control runs. This creates full-frame splits filtered to the same images that have face/face+hands crops available.\n",
        "\n",
        "**Run once** after extracting both face and face_hands variants ‚Äî results persist on Drive.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üéØ Generate Control Splits for 5-Run Experimental Plan\n",
        "from pathlib import Path\n",
        "from ddriver.data.id_sets import (\n",
        "    extract_id_sets,\n",
        "    generate_control_splits,\n",
        "    save_id_sets,\n",
        "    print_id_set_summary,\n",
        ")\n",
        "\n",
        "# Paths to manifests\n",
        "manifest_full = Path(OUT_ROOT) / \"manifests\" / \"manifest.csv\"\n",
        "manifest_face = Path(OUT_ROOT) / \"hybrid\" / \"manifest_face.csv\"\n",
        "manifest_fh = Path(OUT_ROOT) / \"hybrid\" / \"manifest_face_hands.csv\"\n",
        "\n",
        "# Verify manifests exist\n",
        "missing = []\n",
        "for name, path in [(\"Full-frame\", manifest_full), (\"Face\", manifest_face), (\"Face+Hands\", manifest_fh)]:\n",
        "    if not path.exists():\n",
        "        missing.append(f\"{name}: {path}\")\n",
        "\n",
        "if missing:\n",
        "    print(\"‚ö†Ô∏è  Missing manifests (run hybrid extraction first):\")\n",
        "    for m in missing:\n",
        "        print(f\"   - {m}\")\n",
        "    raise FileNotFoundError(\"Run hybrid extraction for both face and face_hands variants first.\")\n",
        "\n",
        "# Extract ID sets from manifests\n",
        "print(\"üîç Extracting ID sets from manifests...\")\n",
        "id_sets = extract_id_sets(\n",
        "    manifest_full=manifest_full,\n",
        "    manifest_face=manifest_face,\n",
        "    manifest_fh=manifest_fh,\n",
        ")\n",
        "print_id_set_summary(id_sets)\n",
        "\n",
        "# Save ID sets for reference/auditing\n",
        "id_sets_dir = Path(OUT_ROOT) / \"splits\" / \"id_sets\"\n",
        "print(f\"\\nüíæ Saving ID sets to {id_sets_dir}...\")\n",
        "save_id_sets(id_sets, id_sets_dir)\n",
        "\n",
        "# Generate control split CSVs\n",
        "splits_root = Path(OUT_ROOT) / \"splits\"\n",
        "control_output = Path(OUT_ROOT) / \"splits\" / \"control\"\n",
        "\n",
        "print(\"\\nüîß Generating control splits...\")\n",
        "results = generate_control_splits(\n",
        "    splits_root=splits_root,\n",
        "    id_sets=id_sets,\n",
        "    output_root=control_output,\n",
        "    generate_both=True,  # Also generate S_both splits\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úÖ Control splits saved to: {control_output}\")\n",
        "print(\"\\nüìÅ Generated files:\")\n",
        "for subset_name, splits in results.items():\n",
        "    for split_name, path in splits.items():\n",
        "        print(f\"   {subset_name}/{split_name}: {path.name}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöö Section 4: Copy Hybrid Crops (Drive ‚Üî /content)\n",
        "\n",
        "Copy extracted crops to `/content` for faster training, or back to Drive for persistence.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üöö Copy Hybrid Crops between Drive ‚Üî /content\n",
        "import os, shutil, time\n",
        "from pathlib import Path\n",
        "\n",
        "HYBRID_VARIANT = \"face\"  # face | face_hands\n",
        "\n",
        "LOCAL_ROOT = Path(\"/content/data/hybrid\")\n",
        "DRIVE_ROOT = Path(OUT_ROOT) / \"hybrid\"\n",
        "\n",
        "LOCAL_VARIANT_DIR = LOCAL_ROOT / HYBRID_VARIANT\n",
        "DRIVE_VARIANT_DIR = DRIVE_ROOT / HYBRID_VARIANT\n",
        "\n",
        "def count_jpgs(p: Path) -> int:\n",
        "    if not p.exists():\n",
        "        return 0\n",
        "    return sum(1 for _ in p.rglob(\"*.jpg\"))\n",
        "\n",
        "local_count = count_jpgs(LOCAL_VARIANT_DIR)\n",
        "drive_count = count_jpgs(DRIVE_VARIANT_DIR)\n",
        "\n",
        "print(f\"üîé Local jpgs: {local_count}\")\n",
        "print(f\"üîé Drive jpgs: {drive_count}\")\n",
        "\n",
        "# Auto-detect copy direction\n",
        "if local_count > 0 and drive_count > 0:\n",
        "    raise RuntimeError(\n",
        "        \"‚ö†Ô∏è Crops exist in BOTH locations. Choose explicitly:\\n\"\n",
        "        \"  COPY_MODE = 'TO_LOCAL' or 'TO_DRIVE'\"\n",
        "    )\n",
        "\n",
        "if local_count > 0 and drive_count == 0:\n",
        "    COPY_MODE = \"TO_DRIVE\"\n",
        "elif drive_count > 0 and local_count == 0:\n",
        "    COPY_MODE = \"TO_LOCAL\"\n",
        "else:\n",
        "    raise FileNotFoundError(\"No crops found in either location!\")\n",
        "\n",
        "if COPY_MODE == \"TO_DRIVE\":\n",
        "    SRC_VARIANT_DIR = LOCAL_VARIANT_DIR\n",
        "    DST_ROOT = DRIVE_VARIANT_DIR\n",
        "    SRC_ROOT = LOCAL_ROOT\n",
        "    print(\"üì¶ Mode: Copy FROM /content TO Drive (persistence)\")\n",
        "else:\n",
        "    SRC_VARIANT_DIR = DRIVE_VARIANT_DIR\n",
        "    DST_ROOT = LOCAL_VARIANT_DIR\n",
        "    SRC_ROOT = DRIVE_ROOT\n",
        "    print(\"üì¶ Mode: Copy FROM Drive TO /content (faster training)\")\n",
        "\n",
        "DST_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Copy images\n",
        "file_count = 0\n",
        "for src_dir, _, files in os.walk(SRC_VARIANT_DIR):\n",
        "    rel_dir = Path(src_dir).relative_to(SRC_VARIANT_DIR)\n",
        "    dst_dir = DST_ROOT / rel_dir\n",
        "    dst_dir.mkdir(parents=True, exist_ok=True)\n",
        "    for fname in files:\n",
        "        if not fname.lower().endswith(\".jpg\"):\n",
        "            continue\n",
        "        src_path = Path(src_dir) / fname\n",
        "        dst_path = dst_dir / fname\n",
        "        if not dst_path.exists():\n",
        "            shutil.copy2(src_path, dst_path)\n",
        "            file_count += 1\n",
        "\n",
        "print(f\"‚úÖ Copied {file_count} jpg files\")\n",
        "\n",
        "# Copy CSVs\n",
        "csv_names = [\n",
        "    f\"manifest_{HYBRID_VARIANT}.csv\",\n",
        "    f\"train_{HYBRID_VARIANT}.csv\",\n",
        "    f\"val_{HYBRID_VARIANT}.csv\",\n",
        "    f\"test_{HYBRID_VARIANT}.csv\",\n",
        "    f\"detection_metadata_{HYBRID_VARIANT}.csv\",\n",
        "]\n",
        "\n",
        "dst_csv_root = DST_ROOT.parent if COPY_MODE == \"TO_LOCAL\" else DRIVE_ROOT\n",
        "for fname in csv_names:\n",
        "    src_csv = SRC_ROOT / fname\n",
        "    if src_csv.exists():\n",
        "        shutil.copy2(src_csv, dst_csv_root / fname)\n",
        "        print(f\"   ‚úÖ Copied {fname}\")\n",
        "\n",
        "# Update env vars for training\n",
        "os.environ[\"HYBRID_ROOT_LOCAL\"] = str(LOCAL_ROOT)\n",
        "os.environ[\"DATASET_ROOT\"] = str(LOCAL_ROOT)\n",
        "import importlib\n",
        "from ddriver import config as _cfg\n",
        "importlib.reload(_cfg)\n",
        "\n",
        "print(f\"\\n‚úÖ Copy complete!\")\n",
        "print(f\"   HYBRID_ROOT_LOCAL = {os.environ['HYBRID_ROOT_LOCAL']}\")\n",
        "print(f\"   DATASET_ROOT      = {os.environ['DATASET_ROOT']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîç Section 5: Quality Audit & Thesis Figures\n",
        "\n",
        "Analyze detection quality and generate figures for your thesis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîç Hybrid Crop Quality Audit\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "VARIANT = \"face\"  # must match the variant you extracted\n",
        "\n",
        "hybrid_root_local = Path(os.environ.get(\"HYBRID_ROOT_LOCAL\", \"\"))\n",
        "hybrid_root = hybrid_root_local if hybrid_root_local.exists() else Path(OUT_ROOT) / \"hybrid\"\n",
        "\n",
        "metadata_csv = hybrid_root / f\"detection_metadata_{VARIANT}.csv\"\n",
        "if not metadata_csv.exists():\n",
        "    raise FileNotFoundError(f\"Detection metadata not found: {metadata_csv}\")\n",
        "\n",
        "print(f\"üìÅ Loading metadata from: {metadata_csv}\")\n",
        "df = pd.read_csv(metadata_csv)\n",
        "\n",
        "n_total = len(df)\n",
        "n_fallback = df[\"fallback_to_full\"].sum()\n",
        "n_skipped = df[\"skipped\"].sum() if \"skipped\" in df.columns else 0\n",
        "n_saved = n_total - n_skipped\n",
        "n_face = (df[\"face_count\"] > 0).sum()\n",
        "n_left_hand = df[\"left_hand_detected\"].sum()\n",
        "n_right_hand = df[\"right_hand_detected\"].sum()\n",
        "n_both_hands = ((df[\"left_hand_detected\"]) & (df[\"right_hand_detected\"])).sum()\n",
        "n_any_hands = ((df[\"left_hand_detected\"]) | (df[\"right_hand_detected\"])).sum()\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"üìä HYBRID DETECTION SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Total images processed: {n_total}\")\n",
        "print(f\"   Images SAVED: {n_saved} ({100*n_saved/n_total:.1f}%)\")\n",
        "print(f\"\\nüéØ Detection rates:\")\n",
        "print(f\"   Face detected: {n_face} ({100*n_face/n_total:.1f}%)\")\n",
        "print(f\"   Left hand: {n_left_hand} ({100*n_left_hand/n_total:.1f}%)\")\n",
        "print(f\"   Right hand: {n_right_hand} ({100*n_right_hand/n_total:.1f}%)\")\n",
        "print(f\"   Both hands: {n_both_hands} ({100*n_both_hands/n_total:.1f}%)\")\n",
        "print(f\"\\n‚ö†Ô∏è  Fallback to full frame: {n_fallback} ({100*n_fallback/n_total:.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üìã Breakdown by Camera and Class\n",
        "print(\"\\nüìã BREAKDOWN BY CAMERA\")\n",
        "print(\"-\" * 80)\n",
        "camera_stats = df.groupby(\"camera\").agg({\n",
        "    \"fallback_to_full\": [\"sum\", \"mean\"],\n",
        "    \"roi_area_frac\": \"mean\",\n",
        "    \"face_count\": lambda x: (x > 0).mean(),\n",
        "}).round(3)\n",
        "camera_stats.columns = [\"fallback_count\", \"fallback_pct\", \"mean_roi_area\", \"face_rate\"]\n",
        "camera_stats[\"fallback_pct\"] = (camera_stats[\"fallback_pct\"] * 100).round(1)\n",
        "camera_stats[\"face_rate\"] = (camera_stats[\"face_rate\"] * 100).round(1)\n",
        "print(camera_stats.to_string())\n",
        "\n",
        "print(\"\\nüìã BREAKDOWN BY CLASS\")\n",
        "print(\"-\" * 80)\n",
        "class_stats = df.groupby(\"class_id\").agg({\n",
        "    \"fallback_to_full\": [\"sum\", \"mean\"],\n",
        "    \"roi_area_frac\": \"mean\",\n",
        "    \"face_count\": lambda x: (x > 0).mean(),\n",
        "}).round(3)\n",
        "class_stats.columns = [\"fallback_count\", \"fallback_pct\", \"mean_roi_area\", \"face_rate\"]\n",
        "class_stats[\"fallback_pct\"] = (class_stats[\"fallback_pct\"] * 100).round(1)\n",
        "class_stats[\"face_rate\"] = (class_stats[\"face_rate\"] * 100).round(1)\n",
        "print(class_stats.to_string())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üìä ROI Quality Distribution Histograms (thesis figure)\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "plt.rcParams.update({\"font.size\": 12})\n",
        "\n",
        "meta_face = pd.read_csv(Path(OUT_ROOT) / \"hybrid/detection_metadata_face.csv\")\n",
        "meta_fh = pd.read_csv(Path(OUT_ROOT) / \"hybrid/detection_metadata_face_hands.csv\")\n",
        "\n",
        "face_valid = meta_face[meta_face[\"fallback_to_full\"] == False].copy()\n",
        "fh_valid = meta_fh[meta_fh[\"fallback_to_full\"] == False].copy()\n",
        "\n",
        "lh_conf = fh_valid[\"left_hand_confidence\"].fillna(0).clip(lower=0)\n",
        "rh_conf = fh_valid[\"right_hand_confidence\"].fillna(0).clip(lower=0)\n",
        "fh_valid[\"any_hand_conf\"] = np.maximum(lh_conf, rh_conf)\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 9.5))\n",
        "\n",
        "# Row 1: Face-only\n",
        "axes[0, 0].hist(face_valid[\"roi_area_frac\"], bins=50, alpha=0.7, color=\"coral\", edgecolor=\"black\")\n",
        "axes[0, 0].set_xlabel(\"ROI Area Fraction\")\n",
        "axes[0, 0].set_title(\"Face-Only: ROI Area Distribution\")\n",
        "axes[0, 0].axvline(face_valid[\"roi_area_frac\"].median(), color=\"red\", linestyle=\"--\",\n",
        "                   label=f\"Median: {face_valid['roi_area_frac'].median():.3f}\")\n",
        "axes[0, 0].legend()\n",
        "\n",
        "axes[0, 1].hist(face_valid[\"roi_aspect\"], bins=50, alpha=0.7, color=\"coral\", edgecolor=\"black\")\n",
        "axes[0, 1].set_xlabel(\"ROI Aspect Ratio (W/H)\")\n",
        "axes[0, 1].set_title(\"Face-Only: Aspect Ratio Distribution\")\n",
        "\n",
        "axes[0, 2].hist(face_valid[\"face_confidence\"], bins=50, alpha=0.7, color=\"coral\", edgecolor=\"black\")\n",
        "axes[0, 2].set_xlabel(\"Face Detection Confidence\")\n",
        "axes[0, 2].set_title(\"Face-Only: Detection Confidence\")\n",
        "\n",
        "# Row 2: Face+Hands\n",
        "axes[1, 0].hist(fh_valid[\"roi_area_frac\"], bins=50, alpha=0.7, edgecolor=\"black\")\n",
        "axes[1, 0].set_xlabel(\"ROI Area Fraction\")\n",
        "axes[1, 0].set_title(\"Face+Hands: ROI Area Distribution\")\n",
        "\n",
        "axes[1, 1].hist(fh_valid[\"roi_aspect\"], bins=50, alpha=0.7, edgecolor=\"black\")\n",
        "axes[1, 1].set_xlabel(\"ROI Aspect Ratio (W/H)\")\n",
        "axes[1, 1].set_title(\"Face+Hands: Aspect Ratio Distribution\")\n",
        "\n",
        "axes[1, 2].hist(fh_valid[\"any_hand_conf\"], bins=50, alpha=0.7, edgecolor=\"black\")\n",
        "axes[1, 2].set_xlabel(\"Any-hand Confidence\")\n",
        "axes[1, 2].set_title(\"Face+Hands: Hand Detection Confidence\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(Path(OUT_ROOT) / \"metrics/crop_quality_distributions.png\", dpi=150, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "print(f\"‚úÖ Saved: {Path(OUT_ROOT) / 'metrics/crop_quality_distributions.png'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚úÖ Data Preparation Complete!\n",
        "\n",
        "**What was created (persists on Drive):**\n",
        "- `OUT_ROOT/manifests/manifest.csv` ‚Äî Full image manifest\n",
        "- `OUT_ROOT/splits/train.csv`, `val.csv`, `test.csv` ‚Äî Split CSVs\n",
        "- `OUT_ROOT/hybrid/face/` ‚Äî Face-only crops\n",
        "- `OUT_ROOT/hybrid/face_hands/` ‚Äî Face+hands crops\n",
        "- `OUT_ROOT/hybrid/*.csv` ‚Äî Hybrid manifests and splits\n",
        "- `OUT_ROOT/metrics/` ‚Äî Quality audit figures\n",
        "\n",
        "**Next steps:**\n",
        "- Run **02_training.ipynb** to train models on these crops\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
