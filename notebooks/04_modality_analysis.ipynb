{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üìà 04 ‚Äî Modality Analysis\n",
        "\n",
        "**Purpose:** Compare Full-Frame vs Face-Only vs Face+Hands model performance per class.\n",
        "\n",
        "**Sections:**\n",
        "1. Inline Setup\n",
        "2. Load Predictions from All Modalities\n",
        "3. Overall Metrics Comparison (Accuracy, Macro-F1)\n",
        "4. Per-Class F1 Comparison Table\n",
        "5. Delta Heatmap (thesis figure)\n",
        "6. Confusion Matrix Comparison (thesis figure)\n",
        "\n",
        "**Prerequisites:** Predictions exist for all modalities you want to compare (from 03_evaluation.ipynb)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- INLINE SETUP ---\n",
        "import os, subprocess, sys\n",
        "\n",
        "REPO_DIRNAME   = \"CNNs-distracted-driving\"\n",
        "PROJECT_ROOT   = f\"/content/{REPO_DIRNAME}\"\n",
        "DRIVE_PATH     = \"/content/drive/MyDrive/TFM\"\n",
        "OUT_ROOT       = f\"{DRIVE_PATH}/outputs\"\n",
        "CKPT_ROOT      = f\"{DRIVE_PATH}/checkpoints\"\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "if not os.path.isdir(PROJECT_ROOT):\n",
        "    subprocess.call(f\"git clone https://github.com/ClaudiaCPach/CNNs-distracted-driving {PROJECT_ROOT}\", shell=True)\n",
        "subprocess.call(f\"pip install -q -e {PROJECT_ROOT}\", shell=True)\n",
        "\n",
        "os.environ[\"OUT_ROOT\"] = OUT_ROOT\n",
        "os.environ[\"CKPT_ROOT\"] = CKPT_ROOT\n",
        "\n",
        "sys.path.insert(0, PROJECT_ROOT)\n",
        "sys.path.insert(0, os.path.join(PROJECT_ROOT, \"src\"))\n",
        "print(\"‚úÖ Setup complete\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìÅ Section 2: Configure Prediction Paths\n",
        "\n",
        "Set the paths to your prediction CSVs for each modality.\n",
        "\n",
        "**5-Run Experimental Plan:**\n",
        "| Run | Description | Prediction File Example |\n",
        "|-----|-------------|-------------------------|\n",
        "| 1 | Full-frame (all IDs) | `effb0_fullframe_v1_test.csv` |\n",
        "| 2 | Face ROI (natural) | `effb0_face_v1_test.csv` |\n",
        "| 3 | Face+Hands ROI (natural) | `effb0_face_hands_v1_test.csv` |\n",
        "| 4 | Full-frame (facesubset control) | `effb0_fullframe_facesubset_v1_test.csv` |\n",
        "| 5 | Full-frame (fhsubset control) | `effb0_fullframe_fhsubset_v1_test.csv` |\n",
        "\n",
        "**Key comparisons:**\n",
        "- ROI vs Full-frame: Compare Run 2/3 with Run 1\n",
        "- Control analysis: Compare Run 3 vs Run 5 (same IDs, different input)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configure prediction file paths\n",
        "from pathlib import Path\n",
        "\n",
        "# ============== PREDICTION PATHS ==============\n",
        "# Set these to match YOUR prediction files from 03_evaluation.ipynb\n",
        "# Set any path to None to exclude it from comparison\n",
        "\n",
        "# --- Natural runs (different ID sets) ---\n",
        "FULL_FRAME_PREDS = Path(OUT_ROOT) / \"preds/test/effb0_fullframe_v1_test.csv\"        # Run 1: Full-frame, all IDs\n",
        "FACE_ONLY_PREDS = Path(OUT_ROOT) / \"preds/test/effb0_face_v1_test.csv\"              # Run 2: Face ROI\n",
        "FACE_HANDS_PREDS = Path(OUT_ROOT) / \"preds/test/effb0_face_hands_v1_test.csv\"       # Run 3: Face+Hands ROI\n",
        "\n",
        "# --- Control runs (filtered to match ROI ID sets) ---\n",
        "CONTROL_FACESUBSET_PREDS = Path(OUT_ROOT) / \"preds/test/effb0_fullframe_facesubset_v1_test.csv\"  # Run 4: Full-frame, face-available IDs\n",
        "CONTROL_FHSUBSET_PREDS = Path(OUT_ROOT) / \"preds/test/effb0_fullframe_fhsubset_v1_test.csv\"      # Run 5: Full-frame, FH-available IDs\n",
        "\n",
        "CLASS_NAMES = {\n",
        "    0: \"Safe driving\", 1: \"Texting (R)\", 2: \"Phone (R)\", 3: \"Texting (L)\",\n",
        "    4: \"Phone (L)\", 5: \"Radio\", 6: \"Drinking\", 7: \"Reaching back\",\n",
        "    8: \"Hair/makeup\", 9: \"Passenger\",\n",
        "}\n",
        "\n",
        "# Verify files exist\n",
        "preds_dir = Path(OUT_ROOT) / \"preds\" / \"test\"\n",
        "print(\"Available prediction files:\")\n",
        "for f in sorted(preds_dir.glob(\"*.csv\")):\n",
        "    print(f\"  - {f.name}\")\n",
        "\n",
        "print(\"\\nüìã Configured paths:\")\n",
        "for name, path in [\n",
        "    (\"Full-frame (natural)\", FULL_FRAME_PREDS),\n",
        "    (\"Face ROI\", FACE_ONLY_PREDS),\n",
        "    (\"Face+Hands ROI\", FACE_HANDS_PREDS),\n",
        "    (\"Control (facesubset)\", CONTROL_FACESUBSET_PREDS),\n",
        "    (\"Control (fhsubset)\", CONTROL_FHSUBSET_PREDS),\n",
        "]:\n",
        "    status = \"‚úÖ\" if path and path.exists() else \"‚ùå\"\n",
        "    print(f\"  {status} {name}: {path.name if path else 'None'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Section 3: Load & Compare Overall Metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load predictions and compute metrics\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "\n",
        "def load_and_compute_metrics(pred_path, name):\n",
        "    if pred_path is None or not Path(pred_path).exists():\n",
        "        return None\n",
        "    \n",
        "    df = pd.read_csv(pred_path)\n",
        "    \n",
        "    def extract_class(path):\n",
        "        parts = Path(path).parts\n",
        "        for p in reversed(parts):\n",
        "            if p.startswith(\"c\") and len(p) == 2 and p[1].isdigit():\n",
        "                return int(p[1])\n",
        "        return -1\n",
        "    \n",
        "    df[\"true\"] = df[\"path\"].apply(extract_class)\n",
        "    df[\"pred\"] = df[\"pred_class_id\"].apply(\n",
        "        lambda x: int(x[1]) if isinstance(x, str) and x.startswith(\"c\") else int(x)\n",
        "    )\n",
        "    df = df[df[\"true\"] >= 0]\n",
        "    \n",
        "    y_true, y_pred = df[\"true\"].values, df[\"pred\"].values\n",
        "    \n",
        "    return {\n",
        "        \"accuracy\": (y_true == y_pred).mean(),\n",
        "        \"macro_f1\": f1_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
        "        \"weighted_f1\": f1_score(y_true, y_pred, average=\"weighted\", zero_division=0),\n",
        "        \"macro_precision\": precision_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
        "        \"macro_recall\": recall_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
        "        \"per_class_f1\": f1_score(y_true, y_pred, average=None, labels=range(10), zero_division=0),\n",
        "        \"n_samples\": len(df),\n",
        "    }\n",
        "\n",
        "# Load all modalities (natural runs + control runs)\n",
        "modalities = {}\n",
        "\n",
        "# Natural runs\n",
        "if FULL_FRAME_PREDS and FULL_FRAME_PREDS.exists():\n",
        "    modalities[\"Full Frame\"] = load_and_compute_metrics(FULL_FRAME_PREDS, \"full\")\n",
        "if FACE_ONLY_PREDS and FACE_ONLY_PREDS.exists():\n",
        "    modalities[\"Face Only\"] = load_and_compute_metrics(FACE_ONLY_PREDS, \"face\")\n",
        "if FACE_HANDS_PREDS and FACE_HANDS_PREDS.exists():\n",
        "    modalities[\"Face+Hands\"] = load_and_compute_metrics(FACE_HANDS_PREDS, \"face_hands\")\n",
        "\n",
        "# Control runs (for isolating filtering effect)\n",
        "if CONTROL_FACESUBSET_PREDS and CONTROL_FACESUBSET_PREDS.exists():\n",
        "    modalities[\"Ctrl-FaceSub\"] = load_and_compute_metrics(CONTROL_FACESUBSET_PREDS, \"ctrl_face\")\n",
        "if CONTROL_FHSUBSET_PREDS and CONTROL_FHSUBSET_PREDS.exists():\n",
        "    modalities[\"Ctrl-FHSub\"] = load_and_compute_metrics(CONTROL_FHSUBSET_PREDS, \"ctrl_fh\")\n",
        "\n",
        "print(f\"Loaded {len(modalities)} modalities: {list(modalities.keys())}\")\n",
        "\n",
        "# Highlight key comparison if both available\n",
        "if \"Face+Hands\" in modalities and \"Ctrl-FHSub\" in modalities:\n",
        "    print(\"\\nüéØ KEY COMPARISON: Face+Hands vs Ctrl-FHSub (same IDs, different representation)\")\n",
        "    print(f\"   Face+Hands: {modalities['Face+Hands']['accuracy']*100:.2f}% accuracy\")\n",
        "    print(f\"   Ctrl-FHSub: {modalities['Ctrl-FHSub']['accuracy']*100:.2f}% accuracy\")\n",
        "    delta = (modalities['Face+Hands']['accuracy'] - modalities['Ctrl-FHSub']['accuracy']) * 100\n",
        "    print(f\"   Œî = {delta:+.2f} pp ({'ROI helps!' if delta > 0 else 'ROI hurts' if delta < 0 else 'No difference'})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display overall metrics table\n",
        "print(\"=\" * 95)\n",
        "print(\"üìã MAIN RESULTS TABLE: Accuracy + Macro-F1 + Weighted-F1\")\n",
        "print(\"=\" * 95)\n",
        "print(f\"{'Model':<15} {'Accuracy':>10} {'Macro-F1':>10} {'Wgt-F1':>10} {'Macro-P':>10} {'Macro-R':>10} {'N':>8}\")\n",
        "print(\"-\" * 95)\n",
        "for mod_name, mod_data in modalities.items():\n",
        "    if mod_data:\n",
        "        print(f\"{mod_name:<15} {mod_data['accuracy']*100:>9.2f}% {mod_data['macro_f1']*100:>9.2f}% \"\n",
        "              f\"{mod_data['weighted_f1']*100:>9.2f}% {mod_data['macro_precision']*100:>9.2f}% \"\n",
        "              f\"{mod_data['macro_recall']*100:>9.2f}% {mod_data['n_samples']:>8d}\")\n",
        "print(\"-\" * 95)\n",
        "\n",
        "best_acc = max(modalities.items(), key=lambda x: x[1][\"accuracy\"] if x[1] else 0)\n",
        "best_f1 = max(modalities.items(), key=lambda x: x[1][\"macro_f1\"] if x[1] else 0)\n",
        "print(f\"\\nüèÜ Best Accuracy: {best_acc[0]} ({best_acc[1]['accuracy']*100:.2f}%)\")\n",
        "print(f\"üèÜ Best Macro-F1: {best_f1[0]} ({best_f1[1]['macro_f1']*100:.2f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Section 4: Per-Class F1 Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Per-class F1 comparison table with deltas (including control runs)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "table_rows = []\n",
        "for c in range(10):\n",
        "    row_data = {\"Class\": f\"c{c}\", \"Name\": CLASS_NAMES.get(c, f\"Class {c}\")}\n",
        "    \n",
        "    # Natural runs\n",
        "    f1_full = modalities.get(\"Full Frame\", {}).get(\"per_class_f1\", np.zeros(10))[c] if modalities.get(\"Full Frame\") else None\n",
        "    f1_face = modalities.get(\"Face Only\", {}).get(\"per_class_f1\", np.zeros(10))[c] if modalities.get(\"Face Only\") else None\n",
        "    f1_fh = modalities.get(\"Face+Hands\", {}).get(\"per_class_f1\", np.zeros(10))[c] if modalities.get(\"Face+Hands\") else None\n",
        "    \n",
        "    # Control runs\n",
        "    f1_ctrl_fh = modalities.get(\"Ctrl-FHSub\", {}).get(\"per_class_f1\", np.zeros(10))[c] if modalities.get(\"Ctrl-FHSub\") else None\n",
        "    \n",
        "    row_data[\"F1 Full\"] = f\"{f1_full*100:.1f}\" if f1_full is not None else \"‚Äî\"\n",
        "    row_data[\"F1 Face\"] = f\"{f1_face*100:.1f}\" if f1_face is not None else \"‚Äî\"\n",
        "    row_data[\"F1 F+H\"] = f\"{f1_fh*100:.1f}\" if f1_fh is not None else \"‚Äî\"\n",
        "    row_data[\"F1 Ctrl-FH\"] = f\"{f1_ctrl_fh*100:.1f}\" if f1_ctrl_fh is not None else \"‚Äî\"\n",
        "    \n",
        "    # Deltas\n",
        "    if f1_face is not None and f1_full is not None:\n",
        "        row_data[\"Œî Face‚àíFull\"] = f\"{(f1_face - f1_full)*100:+.1f}\"\n",
        "    else:\n",
        "        row_data[\"Œî Face‚àíFull\"] = \"‚Äî\"\n",
        "    \n",
        "    if f1_fh is not None and f1_face is not None:\n",
        "        row_data[\"Œî FH‚àíFace\"] = f\"{(f1_fh - f1_face)*100:+.1f}\"\n",
        "    else:\n",
        "        row_data[\"Œî FH‚àíFace\"] = \"‚Äî\"\n",
        "    \n",
        "    # KEY: F+H vs Ctrl-FH (same IDs, isolates ROI effect)\n",
        "    if f1_fh is not None and f1_ctrl_fh is not None:\n",
        "        row_data[\"Œî FH‚àíCtrl\"] = f\"{(f1_fh - f1_ctrl_fh)*100:+.1f}\"\n",
        "    else:\n",
        "        row_data[\"Œî FH‚àíCtrl\"] = \"‚Äî\"\n",
        "    \n",
        "    table_rows.append(row_data)\n",
        "\n",
        "enhanced_df = pd.DataFrame(table_rows)\n",
        "print(\"=\" * 120)\n",
        "print(\"üìä PER-CLASS F1 TABLE WITH DELTAS (for thesis)\")\n",
        "print(\"=\" * 120)\n",
        "print(enhanced_df.to_string(index=False))\n",
        "\n",
        "# Highlight the key column\n",
        "if \"Ctrl-FHSub\" in modalities:\n",
        "    print(\"\\nüéØ KEY COLUMN: 'Œî FH‚àíCtrl' shows ROI benefit vs full-frame on SAME IDs\")\n",
        "    print(\"   Positive = ROI representation helps for that class\")\n",
        "    print(\"   Negative = Full-frame better for that class\")\n",
        "\n",
        "# Save\n",
        "enhanced_df.to_csv(Path(OUT_ROOT) / \"metrics\" / \"perclass_f1_with_deltas.csv\", index=False)\n",
        "print(f\"\\nüíæ Saved to {Path(OUT_ROOT) / 'metrics/perclass_f1_with_deltas.csv'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Per-class F1 bar chart\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 6))\n",
        "x = np.arange(10)\n",
        "n_models = len(modalities)\n",
        "width = 0.8 / n_models\n",
        "offset = -width * (n_models - 1) / 2\n",
        "\n",
        "colors = {\"Full Frame\": \"#9B59B6\", \"Face Only\": \"#FF6B6B\", \"Face+Hands\": \"#45B7D1\"}\n",
        "\n",
        "for mod_name, mod_data in modalities.items():\n",
        "    if mod_data:\n",
        "        f1_scores = mod_data[\"per_class_f1\"] * 100\n",
        "        ax.bar(x + offset, f1_scores, width, label=mod_name, color=colors.get(mod_name, \"gray\"), edgecolor=\"white\")\n",
        "        offset += width\n",
        "\n",
        "ax.set_xlabel(\"Class\", fontsize=12)\n",
        "ax.set_ylabel(\"F1 Score (%)\", fontsize=12)\n",
        "ax.set_title(\"Per-Class F1 Score: Full-Frame vs Face-Only vs Face+Hands\", fontsize=14, fontweight=\"bold\")\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels([CLASS_NAMES.get(c, f\"c{c}\") for c in range(10)], rotation=45, ha=\"right\")\n",
        "ax.legend(loc=\"lower right\")\n",
        "ax.set_ylim(0, 105)\n",
        "ax.grid(axis=\"y\", alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "out_path = Path(OUT_ROOT) / \"metrics\" / \"perclass_f1_comparison.png\"\n",
        "plt.savefig(out_path, dpi=150, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "print(f\"üíæ Saved to {out_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Section 5: Delta Heatmap (Thesis Figure)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Delta heatmap showing F1 changes across modalities\n",
        "import seaborn as sns\n",
        "\n",
        "delta_data = []\n",
        "for c in range(10):\n",
        "    f1_full = modalities.get(\"Full Frame\", {}).get(\"per_class_f1\", np.zeros(10))[c] if modalities.get(\"Full Frame\") else 0\n",
        "    f1_face = modalities.get(\"Face Only\", {}).get(\"per_class_f1\", np.zeros(10))[c] if modalities.get(\"Face Only\") else 0\n",
        "    f1_fh = modalities.get(\"Face+Hands\", {}).get(\"per_class_f1\", np.zeros(10))[c] if modalities.get(\"Face+Hands\") else 0\n",
        "    \n",
        "    delta_data.append({\n",
        "        \"Class\": CLASS_NAMES.get(c, f\"c{c}\"),\n",
        "        \"Face ‚àí Full\": (f1_face - f1_full) * 100,\n",
        "        \"F+H ‚àí Full\": (f1_fh - f1_full) * 100,\n",
        "        \"F+H ‚àí Face\": (f1_fh - f1_face) * 100,\n",
        "    })\n",
        "\n",
        "delta_df = pd.DataFrame(delta_data)\n",
        "delta_matrix = delta_df.set_index(\"Class\")[[\"Face ‚àí Full\", \"F+H ‚àí Full\", \"F+H ‚àí Face\"]]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 10))\n",
        "sns.heatmap(delta_matrix, annot=True, fmt=\".1f\", cmap=\"RdYlGn\", center=0, vmin=-50, vmax=50, ax=ax,\n",
        "            linewidths=0.5, cbar_kws={\"label\": \"F1 Change (pp)\", \"shrink\": 0.8})\n",
        "ax.set_title(\"Per-Class F1 Changes Across Modalities\\nRed = Drop | Green = Gain\", fontsize=12, fontweight=\"bold\")\n",
        "plt.tight_layout()\n",
        "\n",
        "out_path = Path(OUT_ROOT) / \"metrics\" / \"delta_heatmap_f1_modalities.png\"\n",
        "plt.savefig(out_path, dpi=150, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "print(f\"üíæ Saved to {out_path}\")\n",
        "\n",
        "# Save CSV\n",
        "delta_matrix.to_csv(Path(OUT_ROOT) / \"metrics\" / \"delta_f1_by_class.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîç Section 6: Confusion Matrix Comparison (Thesis Figure)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Confusion matrix comparison: All modalities (natural + control)\n",
        "from sklearn.metrics import confusion_matrix, f1_score as sklearn_f1\n",
        "\n",
        "CLASS_NAMES_SHORT = [\"Safe\", \"TxtR\", \"PhR\", \"TxtL\", \"PhL\", \"Radio\", \"Drink\", \"Reach\", \"Hair\", \"Pass\"]\n",
        "\n",
        "def load_preds_for_cm(pred_path):\n",
        "    df = pd.read_csv(pred_path)\n",
        "    def extract_class(path):\n",
        "        for p in reversed(Path(path).parts):\n",
        "            if p.startswith(\"c\") and len(p) == 2 and p[1].isdigit():\n",
        "                return int(p[1])\n",
        "        return -1\n",
        "    df[\"true\"] = df[\"path\"].apply(extract_class)\n",
        "    df[\"pred\"] = df[\"pred_class_id\"].apply(lambda x: int(x[1]) if isinstance(x, str) and x.startswith(\"c\") else int(x))\n",
        "    return df[df[\"true\"] >= 0]\n",
        "\n",
        "# Load all (natural + control)\n",
        "all_runs = [\n",
        "    (\"Full Frame\", FULL_FRAME_PREDS),\n",
        "    (\"Face Only\", FACE_ONLY_PREDS),\n",
        "    (\"Face+Hands\", FACE_HANDS_PREDS),\n",
        "    (\"Ctrl-FaceSub\", CONTROL_FACESUBSET_PREDS),\n",
        "    (\"Ctrl-FHSub\", CONTROL_FHSUBSET_PREDS),\n",
        "]\n",
        "\n",
        "cms = {}\n",
        "f1s = {}\n",
        "for name, path in all_runs:\n",
        "    if path and path.exists():\n",
        "        df = load_preds_for_cm(path)\n",
        "        cm = confusion_matrix(df[\"true\"], df[\"pred\"], labels=range(10))\n",
        "        cms[name] = cm\n",
        "        f1s[name] = sklearn_f1(df[\"true\"], df[\"pred\"], average='macro')\n",
        "\n",
        "# Plot all available\n",
        "n_plots = len(cms)\n",
        "if n_plots == 0:\n",
        "    print(\"‚ö†Ô∏è No prediction files found!\")\n",
        "else:\n",
        "    ncols = min(3, n_plots)\n",
        "    nrows = (n_plots + ncols - 1) // ncols\n",
        "    fig, axes = plt.subplots(nrows, ncols, figsize=(6*ncols, 5*nrows))\n",
        "    axes = np.array(axes).flatten() if n_plots > 1 else [axes]\n",
        "    \n",
        "    colors = {\n",
        "        \"Full Frame\": \"Purples\", \"Face Only\": \"Reds\", \"Face+Hands\": \"Blues\",\n",
        "        \"Ctrl-FaceSub\": \"Oranges\", \"Ctrl-FHSub\": \"Greens\",\n",
        "    }\n",
        "    \n",
        "    for idx, (name, cm) in enumerate(cms.items()):\n",
        "        ax = axes[idx]\n",
        "        cm_norm = cm.astype(float) / cm.sum(axis=1, keepdims=True) * 100\n",
        "        cm_norm = np.nan_to_num(cm_norm)\n",
        "        sns.heatmap(cm_norm, annot=True, fmt=\".1f\", cmap=colors.get(name, \"Blues\"), ax=ax,\n",
        "                    xticklabels=CLASS_NAMES_SHORT, yticklabels=CLASS_NAMES_SHORT, vmin=0, vmax=100)\n",
        "        ax.set_title(f\"{name}\\nMacro-F1: {f1s[name]*100:.1f}%\", fontweight=\"bold\")\n",
        "        ax.set_xlabel(\"Predicted\")\n",
        "        ax.set_ylabel(\"True\")\n",
        "    \n",
        "    # Hide empty axes\n",
        "    for idx in range(n_plots, len(axes)):\n",
        "        axes[idx].set_visible(False)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    out_path = Path(OUT_ROOT) / \"metrics\" / \"confusion_matrices_all.png\"\n",
        "    plt.savefig(out_path, dpi=150, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "    print(f\"üíæ Saved to {out_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Section 7: Control Run Analysis (5-Run Comparison)\n",
        "\n",
        "This section compares ROI models against their matched full-frame controls to isolate the effect of ROI cropping vs ID filtering.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Control Run Analysis: Isolate the ROI effect\n",
        "# This answers: \"Is it the crop or just the data subset that matters?\"\n",
        "\n",
        "control_analysis_available = (\n",
        "    \"Face+Hands\" in modalities and \"Ctrl-FHSub\" in modalities\n",
        ") or (\"Face Only\" in modalities and \"Ctrl-FaceSub\" in modalities)\n",
        "\n",
        "if control_analysis_available:\n",
        "    print(\"=\" * 80)\n",
        "    print(\"üéØ CONTROL RUN ANALYSIS: Isolating ROI Effect\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    comparisons = []\n",
        "    \n",
        "    # Face+Hands vs Ctrl-FHSub (same IDs, different representation)\n",
        "    if \"Face+Hands\" in modalities and \"Ctrl-FHSub\" in modalities:\n",
        "        fh_data = modalities[\"Face+Hands\"]\n",
        "        ctrl_fh_data = modalities[\"Ctrl-FHSub\"]\n",
        "        \n",
        "        acc_delta = (fh_data[\"accuracy\"] - ctrl_fh_data[\"accuracy\"]) * 100\n",
        "        f1_delta = (fh_data[\"macro_f1\"] - ctrl_fh_data[\"macro_f1\"]) * 100\n",
        "        \n",
        "        print(\"\\nüìä Face+Hands ROI vs Full-Frame Control (same FH-available IDs):\")\n",
        "        print(f\"   Face+Hands:    Acc={fh_data['accuracy']*100:.2f}%  Macro-F1={fh_data['macro_f1']*100:.2f}%\")\n",
        "        print(f\"   Ctrl-FHSub:    Acc={ctrl_fh_data['accuracy']*100:.2f}%  Macro-F1={ctrl_fh_data['macro_f1']*100:.2f}%\")\n",
        "        print(f\"   Œî (ROI effect): Acc={acc_delta:+.2f}pp  Macro-F1={f1_delta:+.2f}pp\")\n",
        "        \n",
        "        if acc_delta > 1:\n",
        "            print(\"   ‚û°Ô∏è  ROI cropping HELPS: Face+Hands extraction provides valuable signal\")\n",
        "        elif acc_delta < -1:\n",
        "            print(\"   ‚û°Ô∏è  ROI cropping HURTS: Full-frame retains important context\")\n",
        "        else:\n",
        "            print(\"   ‚û°Ô∏è  Minimal difference: ROI extraction neither helps nor hurts much\")\n",
        "        \n",
        "        comparisons.append({\n",
        "            \"Comparison\": \"Face+Hands vs Ctrl-FHSub\",\n",
        "            \"ROI_Acc\": fh_data[\"accuracy\"] * 100,\n",
        "            \"Ctrl_Acc\": ctrl_fh_data[\"accuracy\"] * 100,\n",
        "            \"Œî_Acc_pp\": acc_delta,\n",
        "            \"ROI_F1\": fh_data[\"macro_f1\"] * 100,\n",
        "            \"Ctrl_F1\": ctrl_fh_data[\"macro_f1\"] * 100,\n",
        "            \"Œî_F1_pp\": f1_delta,\n",
        "        })\n",
        "    \n",
        "    # Face Only vs Ctrl-FaceSub\n",
        "    if \"Face Only\" in modalities and \"Ctrl-FaceSub\" in modalities:\n",
        "        face_data = modalities[\"Face Only\"]\n",
        "        ctrl_face_data = modalities[\"Ctrl-FaceSub\"]\n",
        "        \n",
        "        acc_delta = (face_data[\"accuracy\"] - ctrl_face_data[\"accuracy\"]) * 100\n",
        "        f1_delta = (face_data[\"macro_f1\"] - ctrl_face_data[\"macro_f1\"]) * 100\n",
        "        \n",
        "        print(\"\\nüìä Face ROI vs Full-Frame Control (same face-available IDs):\")\n",
        "        print(f\"   Face Only:     Acc={face_data['accuracy']*100:.2f}%  Macro-F1={face_data['macro_f1']*100:.2f}%\")\n",
        "        print(f\"   Ctrl-FaceSub:  Acc={ctrl_face_data['accuracy']*100:.2f}%  Macro-F1={ctrl_face_data['macro_f1']*100:.2f}%\")\n",
        "        print(f\"   Œî (ROI effect): Acc={acc_delta:+.2f}pp  Macro-F1={f1_delta:+.2f}pp\")\n",
        "        \n",
        "        comparisons.append({\n",
        "            \"Comparison\": \"Face vs Ctrl-FaceSub\",\n",
        "            \"ROI_Acc\": face_data[\"accuracy\"] * 100,\n",
        "            \"Ctrl_Acc\": ctrl_face_data[\"accuracy\"] * 100,\n",
        "            \"Œî_Acc_pp\": acc_delta,\n",
        "            \"ROI_F1\": face_data[\"macro_f1\"] * 100,\n",
        "            \"Ctrl_F1\": ctrl_face_data[\"macro_f1\"] * 100,\n",
        "            \"Œî_F1_pp\": f1_delta,\n",
        "        })\n",
        "    \n",
        "    # Save comparison table\n",
        "    if comparisons:\n",
        "        control_df = pd.DataFrame(comparisons)\n",
        "        out_path = Path(OUT_ROOT) / \"metrics\" / \"control_run_comparison.csv\"\n",
        "        control_df.to_csv(out_path, index=False)\n",
        "        print(f\"\\nüíæ Saved control analysis to {out_path}\")\n",
        "        print(\"\\n\" + control_df.to_string(index=False))\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Control run analysis requires both ROI and matched control predictions.\")\n",
        "    print(\"   Run experiments 4-5 (control runs) and generate their predictions first.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Section 8: Stability Analysis (Multi-Seed Comparison)\n",
        "\n",
        "Compare multiple runs of the same configuration with different random seeds to assess training stability.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Stability Analysis: Compare runs with different seeds\n",
        "# This helps determine if results are robust or just lucky initialization\n",
        "\n",
        "# ============== CONFIGURE SEED RUNS ==============\n",
        "# Add paths to prediction files from same config but different seeds\n",
        "# Format: (seed, pred_path)\n",
        "\n",
        "SEED_RUNS = {\n",
        "    \"Full Frame\": [\n",
        "        # (42, Path(OUT_ROOT) / \"preds/test/effb0_fullframe_v1_seed42_test.csv\"),\n",
        "        # (123, Path(OUT_ROOT) / \"preds/test/effb0_fullframe_v1_seed123_test.csv\"),\n",
        "        # (456, Path(OUT_ROOT) / \"preds/test/effb0_fullframe_v1_seed456_test.csv\"),\n",
        "    ],\n",
        "    \"Face+Hands\": [\n",
        "        # (42, Path(OUT_ROOT) / \"preds/test/effb0_face_hands_v1_seed42_test.csv\"),\n",
        "        # (123, Path(OUT_ROOT) / \"preds/test/effb0_face_hands_v1_seed123_test.csv\"),\n",
        "    ],\n",
        "}\n",
        "\n",
        "# ============== RUN STABILITY ANALYSIS ==============\n",
        "stability_results = []\n",
        "\n",
        "for config_name, seed_paths in SEED_RUNS.items():\n",
        "    # Filter to existing files only\n",
        "    valid_runs = [(seed, path) for seed, path in seed_paths if path.exists()]\n",
        "    \n",
        "    if len(valid_runs) < 2:\n",
        "        print(f\"‚ö†Ô∏è {config_name}: Need at least 2 seed runs for stability analysis (found {len(valid_runs)})\")\n",
        "        continue\n",
        "    \n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"üìä STABILITY ANALYSIS: {config_name} ({len(valid_runs)} seeds)\")\n",
        "    print(f\"{'='*70}\")\n",
        "    \n",
        "    seed_metrics = []\n",
        "    for seed, pred_path in valid_runs:\n",
        "        metrics = load_and_compute_metrics(pred_path, f\"{config_name}_seed{seed}\")\n",
        "        if metrics:\n",
        "            metrics[\"seed\"] = seed\n",
        "            seed_metrics.append(metrics)\n",
        "            print(f\"   Seed {seed}: Acc={metrics['accuracy']*100:.2f}%  F1={metrics['macro_f1']*100:.2f}%\")\n",
        "    \n",
        "    if len(seed_metrics) >= 2:\n",
        "        accs = [m[\"accuracy\"] * 100 for m in seed_metrics]\n",
        "        f1s = [m[\"macro_f1\"] * 100 for m in seed_metrics]\n",
        "        \n",
        "        print(f\"\\n   üìà SUMMARY:\")\n",
        "        print(f\"   Accuracy:  Œº={np.mean(accs):.2f}% ¬± œÉ={np.std(accs):.2f}%  (range: {np.min(accs):.2f}-{np.max(accs):.2f}%)\")\n",
        "        print(f\"   Macro-F1:  Œº={np.mean(f1s):.2f}% ¬± œÉ={np.std(f1s):.2f}%  (range: {np.min(f1s):.2f}-{np.max(f1s):.2f}%)\")\n",
        "        \n",
        "        # Interpret stability\n",
        "        if np.std(accs) < 0.5:\n",
        "            stability = \"Very Stable ‚úÖ\"\n",
        "        elif np.std(accs) < 1.0:\n",
        "            stability = \"Stable ‚úîÔ∏è\"\n",
        "        elif np.std(accs) < 2.0:\n",
        "            stability = \"Moderate ‚ö†Ô∏è\"\n",
        "        else:\n",
        "            stability = \"Unstable ‚ùå\"\n",
        "        \n",
        "        print(f\"   Stability: {stability}\")\n",
        "        \n",
        "        stability_results.append({\n",
        "            \"Config\": config_name,\n",
        "            \"N_Seeds\": len(seed_metrics),\n",
        "            \"Acc_Mean\": np.mean(accs),\n",
        "            \"Acc_Std\": np.std(accs),\n",
        "            \"Acc_Min\": np.min(accs),\n",
        "            \"Acc_Max\": np.max(accs),\n",
        "            \"F1_Mean\": np.mean(f1s),\n",
        "            \"F1_Std\": np.std(f1s),\n",
        "            \"Stability\": stability,\n",
        "        })\n",
        "\n",
        "# Save stability results\n",
        "if stability_results:\n",
        "    stability_df = pd.DataFrame(stability_results)\n",
        "    out_path = Path(OUT_ROOT) / \"metrics\" / \"stability_analysis.csv\"\n",
        "    stability_df.to_csv(out_path, index=False)\n",
        "    print(f\"\\nüíæ Saved stability analysis to {out_path}\")\n",
        "    print(\"\\n\" + stability_df.to_string(index=False))\n",
        "else:\n",
        "    print(\"\\nüìã To run stability analysis:\")\n",
        "    print(\"   1. Train same config with different seeds (e.g., 42, 123, 456)\")\n",
        "    print(\"   2. Generate predictions for each\")\n",
        "    print(\"   3. Add paths to SEED_RUNS dict above\")\n",
        "    print(\"   4. Re-run this cell\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìù Section 9: Thesis Summary Exporter\n",
        "\n",
        "Generate publication-ready tables in CSV and LaTeX format for your thesis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Thesis Summary Exporter: Generate LaTeX and CSV tables\n",
        "\n",
        "def generate_thesis_tables():\n",
        "    \"\"\"Generate publication-ready summary tables for thesis.\"\"\"\n",
        "    \n",
        "    # ========== TABLE 1: Main Results (5-Run Comparison) ==========\n",
        "    print(\"=\" * 80)\n",
        "    print(\"üìä TABLE 1: Main Experimental Results (5-Run Plan)\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    main_results = []\n",
        "    run_order = [\n",
        "        (\"Run 1\", \"Full Frame\", \"All IDs\", \"full-frame\"),\n",
        "        (\"Run 2\", \"Face Only\", \"Face-available\", \"face ROI\"),\n",
        "        (\"Run 3\", \"Face+Hands\", \"FH-available\", \"face+hands ROI\"),\n",
        "        (\"Run 4\", \"Ctrl-FaceSub\", \"Face-available\", \"full-frame\"),\n",
        "        (\"Run 5\", \"Ctrl-FHSub\", \"FH-available\", \"full-frame\"),\n",
        "    ]\n",
        "    \n",
        "    for run_id, mod_name, id_set, input_type in run_order:\n",
        "        if mod_name in modalities and modalities[mod_name]:\n",
        "            m = modalities[mod_name]\n",
        "            main_results.append({\n",
        "                \"Run\": run_id,\n",
        "                \"Model\": mod_name,\n",
        "                \"ID Set\": id_set,\n",
        "                \"Input\": input_type,\n",
        "                \"N\": m[\"n_samples\"],\n",
        "                \"Accuracy (%)\": f\"{m['accuracy']*100:.2f}\",\n",
        "                \"Macro-F1 (%)\": f\"{m['macro_f1']*100:.2f}\",\n",
        "                \"Precision (%)\": f\"{m['macro_precision']*100:.2f}\",\n",
        "                \"Recall (%)\": f\"{m['macro_recall']*100:.2f}\",\n",
        "            })\n",
        "    \n",
        "    main_df = pd.DataFrame(main_results)\n",
        "    print(main_df.to_string(index=False))\n",
        "    \n",
        "    # ========== TABLE 2: Control Comparison (ROI Effect) ==========\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"üìä TABLE 2: ROI Effect Analysis (Same IDs, Different Input)\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    roi_effect = []\n",
        "    comparisons = [\n",
        "        (\"Face+Hands\", \"Ctrl-FHSub\", \"Face+Hands ROI vs Full-Frame\"),\n",
        "        (\"Face Only\", \"Ctrl-FaceSub\", \"Face ROI vs Full-Frame\"),\n",
        "    ]\n",
        "    \n",
        "    for roi_name, ctrl_name, desc in comparisons:\n",
        "        if roi_name in modalities and ctrl_name in modalities:\n",
        "            roi_m = modalities[roi_name]\n",
        "            ctrl_m = modalities[ctrl_name]\n",
        "            roi_effect.append({\n",
        "                \"Comparison\": desc,\n",
        "                \"ROI Acc (%)\": f\"{roi_m['accuracy']*100:.2f}\",\n",
        "                \"Ctrl Acc (%)\": f\"{ctrl_m['accuracy']*100:.2f}\",\n",
        "                \"Œî Acc (pp)\": f\"{(roi_m['accuracy']-ctrl_m['accuracy'])*100:+.2f}\",\n",
        "                \"ROI F1 (%)\": f\"{roi_m['macro_f1']*100:.2f}\",\n",
        "                \"Ctrl F1 (%)\": f\"{ctrl_m['macro_f1']*100:.2f}\",\n",
        "                \"Œî F1 (pp)\": f\"{(roi_m['macro_f1']-ctrl_m['macro_f1'])*100:+.2f}\",\n",
        "            })\n",
        "    \n",
        "    if roi_effect:\n",
        "        roi_df = pd.DataFrame(roi_effect)\n",
        "        print(roi_df.to_string(index=False))\n",
        "    \n",
        "    # ========== SAVE CSV FILES ==========\n",
        "    out_dir = Path(OUT_ROOT) / \"metrics\" / \"thesis_tables\"\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    main_df.to_csv(out_dir / \"table1_main_results.csv\", index=False)\n",
        "    print(f\"\\nüíæ Saved: {out_dir / 'table1_main_results.csv'}\")\n",
        "    \n",
        "    if roi_effect:\n",
        "        roi_df.to_csv(out_dir / \"table2_roi_effect.csv\", index=False)\n",
        "        print(f\"üíæ Saved: {out_dir / 'table2_roi_effect.csv'}\")\n",
        "    \n",
        "    # ========== GENERATE LATEX ==========\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"üìù LATEX TABLE 1: Main Results\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    latex_main = r\"\"\"\\begin{table}[htbp]\n",
        "\\centering\n",
        "\\caption{5-Run Experimental Results: Accuracy and Macro-F1 across modalities}\n",
        "\\label{tab:main_results}\n",
        "\\begin{tabular}{llllrrr}\n",
        "\\toprule\n",
        "Run & Model & ID Set & Input & N & Accuracy (\\%) & Macro-F1 (\\%) \\\\\n",
        "\\midrule\n",
        "\"\"\"\n",
        "    for _, row in main_df.iterrows():\n",
        "        latex_main += f\"{row['Run']} & {row['Model']} & {row['ID Set']} & {row['Input']} & {row['N']} & {row['Accuracy (%)']} & {row['Macro-F1 (%)']} \\\\\\\\\\n\"\n",
        "    \n",
        "    latex_main += r\"\"\"\\bottomrule\n",
        "\\end{tabular}\n",
        "\\end{table}\n",
        "\"\"\"\n",
        "    print(latex_main)\n",
        "    \n",
        "    # Save LaTeX\n",
        "    with open(out_dir / \"table1_main_results.tex\", \"w\") as f:\n",
        "        f.write(latex_main)\n",
        "    print(f\"üíæ Saved: {out_dir / 'table1_main_results.tex'}\")\n",
        "    \n",
        "    if roi_effect:\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"üìù LATEX TABLE 2: ROI Effect\")\n",
        "        print(\"=\" * 80)\n",
        "        \n",
        "        latex_roi = r\"\"\"\\begin{table}[htbp]\n",
        "\\centering\n",
        "\\caption{ROI Effect Analysis: Comparing ROI crops vs full-frame on identical image IDs}\n",
        "\\label{tab:roi_effect}\n",
        "\\begin{tabular}{lrrrrrr}\n",
        "\\toprule\n",
        "Comparison & ROI Acc & Ctrl Acc & $\\Delta$ Acc & ROI F1 & Ctrl F1 & $\\Delta$ F1 \\\\\n",
        "\\midrule\n",
        "\"\"\"\n",
        "        for _, row in roi_df.iterrows():\n",
        "            latex_roi += f\"{row['Comparison']} & {row['ROI Acc (%)']} & {row['Ctrl Acc (%)']} & {row['Œî Acc (pp)']} & {row['ROI F1 (%)']} & {row['Ctrl F1 (%)']} & {row['Œî F1 (pp)']} \\\\\\\\\\n\"\n",
        "        \n",
        "        latex_roi += r\"\"\"\\bottomrule\n",
        "\\end{tabular}\n",
        "\\end{table}\n",
        "\"\"\"\n",
        "        print(latex_roi)\n",
        "        \n",
        "        with open(out_dir / \"table2_roi_effect.tex\", \"w\") as f:\n",
        "            f.write(latex_roi)\n",
        "        print(f\"üíæ Saved: {out_dir / 'table2_roi_effect.tex'}\")\n",
        "    \n",
        "    return main_df, roi_df if roi_effect else None\n",
        "\n",
        "# Generate tables\n",
        "main_table, roi_table = generate_thesis_tables()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate per-class F1 LaTeX table for thesis\n",
        "print(\"=\" * 80)\n",
        "print(\"üìù LATEX TABLE 3: Per-Class F1 Scores\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "out_dir = Path(OUT_ROOT) / \"metrics\" / \"thesis_tables\"\n",
        "\n",
        "# Build per-class data\n",
        "perclass_data = []\n",
        "for c in range(10):\n",
        "    row = {\"Class\": f\"c{c}\", \"Name\": CLASS_NAMES.get(c, f\"Class {c}\")}\n",
        "    \n",
        "    for mod_name in [\"Full Frame\", \"Face Only\", \"Face+Hands\", \"Ctrl-FHSub\"]:\n",
        "        if mod_name in modalities and modalities[mod_name]:\n",
        "            f1 = modalities[mod_name][\"per_class_f1\"][c] * 100\n",
        "            row[mod_name] = f\"{f1:.1f}\"\n",
        "        else:\n",
        "            row[mod_name] = \"‚Äî\"\n",
        "    \n",
        "    perclass_data.append(row)\n",
        "\n",
        "perclass_df = pd.DataFrame(perclass_data)\n",
        "\n",
        "# Generate LaTeX\n",
        "latex_perclass = r\"\"\"\\begin{table}[htbp]\n",
        "\\centering\n",
        "\\caption{Per-class F1 scores (\\%) across modalities}\n",
        "\\label{tab:perclass_f1}\n",
        "\\begin{tabular}{llrrrr}\n",
        "\\toprule\n",
        "Class & Description & Full-Frame & Face & Face+Hands & Ctrl-FH \\\\\n",
        "\\midrule\n",
        "\"\"\"\n",
        "\n",
        "for _, row in perclass_df.iterrows():\n",
        "    name_escaped = row[\"Name\"].replace(\"&\", r\"\\&\")\n",
        "    latex_perclass += f\"{row['Class']} & {name_escaped} & {row.get('Full Frame', '‚Äî')} & {row.get('Face Only', '‚Äî')} & {row.get('Face+Hands', '‚Äî')} & {row.get('Ctrl-FHSub', '‚Äî')} \\\\\\\\\\n\"\n",
        "\n",
        "latex_perclass += r\"\"\"\\bottomrule\n",
        "\\end{tabular}\n",
        "\\end{table}\n",
        "\"\"\"\n",
        "\n",
        "print(latex_perclass)\n",
        "\n",
        "# Save\n",
        "with open(out_dir / \"table3_perclass_f1.tex\", \"w\") as f:\n",
        "    f.write(latex_perclass)\n",
        "print(f\"üíæ Saved: {out_dir / 'table3_perclass_f1.tex'}\")\n",
        "\n",
        "perclass_df.to_csv(out_dir / \"table3_perclass_f1.csv\", index=False)\n",
        "print(f\"üíæ Saved: {out_dir / 'table3_perclass_f1.csv'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚úÖ Modality Analysis Complete!\n",
        "\n",
        "**Outputs saved to Drive:**\n",
        "\n",
        "üìä **Analysis Results:**\n",
        "- `OUT_ROOT/metrics/perclass_f1_with_deltas.csv` ‚Äî Per-class comparison table (all 5 runs)\n",
        "- `OUT_ROOT/metrics/perclass_f1_comparison.png` ‚Äî Bar chart\n",
        "- `OUT_ROOT/metrics/delta_heatmap_f1_modalities.png` ‚Äî Delta heatmap\n",
        "- `OUT_ROOT/metrics/confusion_matrices_all.png` ‚Äî Confusion matrices (up to 5 runs)\n",
        "- `OUT_ROOT/metrics/control_run_comparison.csv` ‚Äî Control vs ROI analysis\n",
        "- `OUT_ROOT/metrics/stability_analysis.csv` ‚Äî Multi-seed stability results (if available)\n",
        "\n",
        "üìù **Thesis Tables (LaTeX + CSV):**\n",
        "- `OUT_ROOT/metrics/thesis_tables/table1_main_results.tex` ‚Äî Main 5-run results\n",
        "- `OUT_ROOT/metrics/thesis_tables/table2_roi_effect.tex` ‚Äî ROI effect analysis\n",
        "- `OUT_ROOT/metrics/thesis_tables/table3_perclass_f1.tex` ‚Äî Per-class F1 scores\n",
        "\n",
        "**5-Run Experimental Summary:**\n",
        "| Run | Type | Comparison |\n",
        "|-----|------|------------|\n",
        "| 1 | Full Frame | Baseline (all IDs) |\n",
        "| 2 | Face ROI | ROI extraction |\n",
        "| 3 | Face+Hands ROI | ROI extraction |\n",
        "| 4 | Ctrl-FaceSub | Same IDs as Run 2 |\n",
        "| 5 | Ctrl-FHSub | Same IDs as Run 3 |\n",
        "\n",
        "**Key comparisons for thesis:**\n",
        "- Run 3 vs Run 5 ‚Üí Isolates ROI effect for face+hands (same IDs, different input)\n",
        "- Run 2 vs Run 4 ‚Üí Isolates ROI effect for face only\n",
        "\n",
        "**Stability Analysis:**\n",
        "- Add multi-seed runs to Section 8 to assess training variance\n",
        "- Report mean ¬± std for robust conclusions\n",
        "\n",
        "**Next steps:**\n",
        "- Run **05_gradcam.ipynb** for attention visualizations\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
